{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:37.941603Z",
     "start_time": "2018-04-17T04:43:37.445922Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.text import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_ids = np.load('sql_ids.npy')\n",
    "sql_itos = pickle.load(open(TMP_PATH/'sql_itos.pkl','rb'))\n",
    "sql_stoi =  collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(sql_itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([0] + [stoi[o] for o in p] + [2]) for p in tok]) # pad bos at beginning and eos at the end\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:39.590583Z",
     "start_time": "2018-04-17T04:43:39.108800Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH\n",
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:40.736137Z",
     "start_time": "2018-04-17T04:43:39.593090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>sql_plain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>586912</td>\n",
       "      <td>SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...</td>\n",
       "      <td>SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...</td>\n",
       "      <td>Repent 151-160</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This is test data for my question to make thi...</td>\n",
       "      <td></td>\n",
       "      <td>54791</td>\n",
       "      <td>CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...</td>\n",
       "      <td>-- This is test data for my question to make t...</td>\n",
       "      <td>This is test data for my question to make thin...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>611565</td>\n",
       "      <td>select Id from Comments where lower(Text) like...</td>\n",
       "      <td>select Id\\nfrom Comments \\nwhere lower(Text) l...</td>\n",
       "      <td>Accept answer</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>612812</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>Questions with most views created within 3 mon...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Most Prolific Answerers (with score), Shows t...</td>\n",
       "      <td></td>\n",
       "      <td>325114</td>\n",
       "      <td>SELECT TOP 50 OwnerUserId as [User Link], COUN...</td>\n",
       "      <td>-- Most Prolific Answerers (with score)\\n-- Sh...</td>\n",
       "      <td>Most Prolific Answers</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments description      id  \\\n",
       "0                                                 []              586912   \n",
       "1  [This is test data for my question to make thi...               54791   \n",
       "2                                                 []              611565   \n",
       "3                                                 []              612812   \n",
       "4  [Most Prolific Answerers (with score), Shows t...              325114   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...   \n",
       "1  CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...   \n",
       "2  select Id from Comments where lower(Text) like...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  SELECT TOP 50 OwnerUserId as [User Link], COUN...   \n",
       "\n",
       "                                           sql_plain  \\\n",
       "0  SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...   \n",
       "1  -- This is test data for my question to make t...   \n",
       "2  select Id\\nfrom Comments \\nwhere lower(Text) l...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  -- Most Prolific Answerers (with score)\\n-- Sh...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Repent 151-160   \n",
       "1  This is test data for my question to make thin...   \n",
       "2                                      Accept answer   \n",
       "3  Questions with most views created within 3 mon...   \n",
       "4                              Most Prolific Answers   \n",
       "\n",
       "                                                 url  \n",
       "0  http://data.stackexchange.com/stackoverflow/re...  \n",
       "1  http://data.stackexchange.com/stackoverflow/re...  \n",
       "2  http://data.stackexchange.com/stackoverflow/re...  \n",
       "3  http://data.stackexchange.com/stackoverflow/re...  \n",
       "4  http://data.stackexchange.com/stackoverflow/re...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(DATA_PATH/'train.json')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:41.264546Z",
     "start_time": "2018-04-17T04:43:40.739164Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL = dataset.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:41.773402Z",
     "start_time": "2018-04-17T04:43:41.266551Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform the text to be tokenize readily, as certain token has special meaning in SQL, ie. \".\" means the schema relation\n",
    "token_replaced = {',' : ' , ',\n",
    "                 '#' : ' # ',\n",
    "                 '@' : ' @ ',\n",
    "                 '!' : ' ! ',\n",
    "                 '.' : ' . ',\n",
    "                 '%' : ' % ',\n",
    "                 '?' : ' ? ',\n",
    "                 ')' : ' ) ',\n",
    "                 '(' : ' ( ',\n",
    "                 '=' : ' = ',\n",
    "                 '/' : ' / ',\n",
    "                 '*' : ' * '}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:42.330388Z",
     "start_time": "2018-04-17T04:43:41.777413Z"
    }
   },
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    for bereplaced, replace in token_replaced.items():        \n",
    "        x = x.replace(bereplaced, replace)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:43:43.024237Z",
     "start_time": "2018-04-17T04:43:42.332392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT p . Title , p . score , p . ViewCount , p . AnswerCount , p . CommentCount , LEN ( p . body )  as ques_size ,  p . favoritecount , p . id ,  u . reputation as user_repo , u . creationdate as user_join_date ,  datediff ( MINUTE ,  p . CreationDate ,  a . CreationDate )  as QATimeGap from posts as p ,  posts as a ,  users as u where p . id = a . parentId and p . owneruserid = u . id and a . creationdate  =   ( select min ( tau . creationdate )  from posts tau where tau . parentID = p . id group by tau . parentID )  and  (  p . title like \\' % Recommended method for handling UnsupportedEncodingException from String . getBytes ( \"UTF-8\" )  % \\' or p . title like \\' % Way to format strings with \" ? \" parameters to full string in java ?  % \\' or p . title like \\' % How to parse a string without regular expressions % \\' or p . title like \\' % How to replace string only once without regex in Java ?  % \\' or p . title like \\' % Efficiently removing specific characters  ( some punctuation )  from Strings in Java ?  % \\' or p . title like \\' % Strings are immutable - that means I should never use + =  and only StringBuffer ?  % \\' or p . title like \\' % Concatenation of Strings and characters % \\' or p . title like \\' % Java - Convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % Better template language needed % \\'  ) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL = SQL.apply(fixup)## Sanity Check\n",
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT p . Title , p . score , p . ViewCount , p . AnswerCount , p . CommentCount , LEN ( p . body )  as ques_size ,  p . favoritecount , p . id ,  u . reputation as user_repo , u . creationdate as user_join_date ,  datediff ( MINUTE ,  p . CreationDate ,  a . CreationDate )  as QATimeGap from posts as p ,  posts as a ,  users as u where p . id = a . parentId and p . owneruserid = u . id and a . creationdate  =   ( select min ( tau . creationdate )  from posts tau where tau . parentID = p . id group by tau . parentID )  and  (  p . title like \\' % Recommended method for handling UnsupportedEncodingException from String . getBytes ( \"UTF-8\" )  % \\' or p . title like \\' % Way to format strings with \" ? \" parameters to full string in java ?  % \\' or p . title like \\' % How to parse a string without regular expressions % \\' or p . title like \\' % How to replace string only once without regex in Java ?  % \\' or p . title like \\' % Efficiently removing specific characters  ( some punctuation )  from Strings in Java ?  % \\' or p . title like \\' % Strings are immutable - that means I should never use + =  and only StringBuffer ?  % \\' or p . title like \\' % Concatenation of Strings and characters % \\' or p . title like \\' % Java - Convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % Better template language needed % \\'  ) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:44:32.515367Z",
     "start_time": "2018-04-17T04:43:43.026242Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tok = Tokenizer.proc_all_mp(partition_by_cores(SQL)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:44:32.964067Z",
     "start_time": "2018-04-17T04:44:32.516876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 't_up',\n",
       " 'select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 't_up',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 't_up',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 't_up',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T04:56:20.165585Z",
     "start_time": "2018-04-17T04:56:19.610100Z"
    }
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common()]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([0] + [stoi[o] for o in p] + [2]) for p in tok]) # pad bos at beginning and eos at the end\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:16:47.256872Z",
     "start_time": "2018-04-17T05:16:46.176965Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids,sql_itos,sql_stoi = toks2ids(sql_tok,'sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:17:06.241374Z",
     "start_time": "2018-04-17T05:17:05.618718Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids_concat= []\n",
    "for i in sql_ids:\n",
    "    sql_ids_concat += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:16:19.962091Z",
     "start_time": "2018-04-17T05:16:19.503940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24594,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:00:07.696414Z",
     "start_time": "2018-04-17T05:00:07.211618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 23102\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(sql_itos)\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Three char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = sql_ids_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = sql_stoi\n",
    "indices_char = sql_itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:00.791359Z",
     "start_time": "2018-04-16T16:08:00.533157Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:00.950143Z",
     "start_time": "2018-04-16T16:08:00.793366Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 14, 104, 5, 19, 6, 122, 5, 4, 19],\n",
       " [40, 19, 6, 34, 5, 19, 6, 198, 128, 5],\n",
       " [4, 5, 19, 6, 93, 5, 19, 6, 8, 79])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c1_dat[:10],\n",
    "c2_dat[:10],\n",
    "c3_dat[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786352, 786352)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_dat),len(c2_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:20.829517Z",
     "start_time": "2018-04-16T16:08:19.253703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.492540Z",
     "start_time": "2018-04-16T16:08:20.831618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.638438Z",
     "start_time": "2018-04-16T16:08:21.494547Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 104, 5, 19, 6, 122, 5, 4, 19, 7]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_dat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.800874Z",
     "start_time": "2018-04-16T16:08:21.640443Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14, 104,   5,  19,   6, 122,   5,   4,  19,   7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first 4 inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.958322Z",
     "start_time": "2018-04-16T16:08:21.803882Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,  14, 104,   5]), array([40, 19,  6, 34]), array([ 4,  5, 19,  6]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.158868Z",
     "start_time": "2018-04-16T16:08:21.963337Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14, 104,   5,  19])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.321815Z",
     "start_time": "2018-04-16T16:08:22.161878Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((786352,), (786352,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pick a size for our hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.751514Z",
     "start_time": "2018-04-16T16:08:22.595075Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:23.229838Z",
     "start_time": "2018-04-16T16:08:23.074416Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:23.522651Z",
     "start_time": "2018-04-16T16:08:23.327119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:27.292423Z",
     "start_time": "2018-04-16T16:08:27.165101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:48.425828Z",
     "start_time": "2018-04-15T11:53:41.563928Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:50.126428Z",
     "start_time": "2018-04-15T11:53:48.428856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:50.604613Z",
     "start_time": "2018-04-15T11:53:50.128574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:00.574650Z",
     "start_time": "2018-04-15T11:53:50.608823Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b735c0345ffd4abebbcc80f3858006c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      3.168653   0.581217  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.58122])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 19 05:13:36 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 387.34                 Driver Version: 387.34                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    95W / 149W |    728MiB / 11439MiB |     73%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1446      G   /usr/lib/xorg/Xorg                            15MiB |\r\n",
      "|    0      2734      C   ...am_cnl/anaconda3/envs/fastai/bin/python   701MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:01.004095Z",
     "start_time": "2018-04-15T11:54:00.577239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:18.055368Z",
     "start_time": "2018-04-15T11:54:17.643725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??set_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.nll_loss>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:10.979726Z",
     "start_time": "2018-04-15T11:54:01.010111Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18ef92137274e3bab88b92ca549f8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.189725   0.738436  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.73844])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b9d348c6d24e80a5562ef2a94146b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.025342   0.826298  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.8263])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aebe85e93954f06936f7ca4cf6e24ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.92159    0.833474  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.83347])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd82591da4a04756adc6fa0d012f0467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.855852   0.744239  \n",
      "    1      1.794819   1.006101                                \n",
      "    2      1.75691    0.712873                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.71287])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Char3Model to fastai learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_Learner(md, SingleModel(to_gpu(m)), opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849256ff5224af39e7bb15822865c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 964/1536 [00:50<00:29, 19.25it/s, loss=6.62]"
     ]
    }
   ],
   "source": [
    "model.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34d3b1ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.sched.plot(n_skip_end = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34f09bcac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510a6ce91d1d49efa5ca0c079cfd2e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.649082   0.732169  \n",
      "    1      1.637239   0.728866                                \n",
      "    2      1.640611   0.742777                                \n",
      "    3      1.641455   0.74946                                 \n",
      "    4      1.638865   0.7533                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.7533])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(1e-5,1, cycle_len=5,use_clr_beta = (10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:50.135680Z",
     "start_time": "2018-04-16T16:08:49.997305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))    \n",
    "    return indices_char[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ['_bos_','t_up','select']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t_up'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(inp[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(inp):\n",
    "    sentence = inp\n",
    "    counter = 0\n",
    "    tmp = []\n",
    "    while \"_eos_\" not in tmp:   \n",
    "        tmp = get_next(sentence[-3:]) # always get last three\n",
    "        sentence += [tmp]\n",
    "        counter = counter+1\n",
    "        if counter> 500:\n",
    "            break\n",
    "    return sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sentence(inp):\n",
    "    sentence =''\n",
    "    captialize = True\n",
    "    for i in inp:\n",
    "        if i =='t_up':\n",
    "            captialize = True\n",
    "        else:            \n",
    "                if captialize:\n",
    "                sentence = sentence + i\n",
    "            captialize = False\n",
    "            if captialize:\n",
    "                sentence = sentence + i\n",
    "            else:\n",
    "                sentence = setence + i.upper()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=get_sentence(['_bos_','t_up','select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_bos_selecttop100idas[postlink],reputationfromuserswherelower(location)like'%<'2013-01-01'andreputation>=1000orderbyreputationdesc;_eos_\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:54.148847Z",
     "start_time": "2018-04-16T16:08:50.483440Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(['select', '*', 'from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:03.223960Z",
     "start_time": "2018-04-15T11:56:02.771920Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'join'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(['t_up','left','t_up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:07.111853Z",
     "start_time": "2018-04-15T11:56:06.665958Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:09.197401Z",
     "start_time": "2018-04-15T11:56:08.761506Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:04.330724Z",
     "start_time": "2018-04-17T05:19:03.879495Z"
    }
   },
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:10.014970Z",
     "start_time": "2018-04-17T05:19:04.640654Z"
    }
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(len(sql_ids_concat)-cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:10.756366Z",
     "start_time": "2018-04-17T05:19:10.016975Z"
    }
   },
   "outputs": [],
   "source": [
    "c_out_dat = [sql_ids_concat[j+cs] for j in range(len(sql_ids_concat)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:18.540789Z",
     "start_time": "2018-04-17T05:19:10.759373Z"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:19.093255Z",
     "start_time": "2018-04-17T05:19:18.541792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 12968,    40, ...,    19,     5,   104],\n",
       "       [12968,    40,     4, ...,     5,   104,     6],\n",
       "       [   40,     4,    14, ...,   104,     6,    19],\n",
       "       ...,\n",
       "       [    5,    79,    28, ...,   254,    31,     9],\n",
       "       [   79,    28,    21, ...,    31,     9,     4],\n",
       "       [   28,    21,     9, ...,     9,     4,   126]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:08:36.372266Z",
     "start_time": "2018-04-17T05:08:35.846902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24586, 8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:37.677780Z",
     "start_time": "2018-04-17T05:19:32.933190Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:38.134994Z",
     "start_time": "2018-04-17T05:19:37.679785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,  19,   5, ...,   4, 126,   2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:19:40.464661Z",
     "start_time": "2018-04-17T05:19:40.019467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 12968,    40,     4,    14,    19,     5,   104],\n",
       "       [12968,    40,     4,    14,    19,     5,   104,     6],\n",
       "       [   40,     4,    14,    19,     5,   104,     6,    19],\n",
       "       [    4,    14,    19,     5,   104,     6,    19,     5],\n",
       "       [   14,    19,     5,   104,     6,    19,     5,    34],\n",
       "       [   19,     5,   104,     6,    19,     5,    34,     6],\n",
       "       [    5,   104,     6,    19,     5,    34,     6,    19],\n",
       "       [  104,     6,    19,     5,    34,     6,    19,     5]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:28:24.346786Z",
     "start_time": "2018-04-17T05:28:23.868515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 19,  5, 34,  6, 19,  5, 93])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:28:38.824214Z",
     "start_time": "2018-04-17T05:28:38.260716Z"
    }
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(sql_ids_concat)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:28:39.337580Z",
     "start_time": "2018-04-17T05:28:38.825218Z"
    }
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:28:40.300103Z",
     "start_time": "2018-04-17T05:28:39.833864Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:29:25.897917Z",
     "start_time": "2018-04-17T05:29:25.454704Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "n_hidden = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T05:29:26.799422Z",
     "start_time": "2018-04-17T05:29:26.259986Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-02a92826e51b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCharLoopModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[1;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                 \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m     \u001b[1;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m         raise RuntimeError(\n\u001b[0;32m    159\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:58:39.070256Z",
     "start_time": "2018-04-15T11:57:54.655244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc371984f434afb940cd30f69e044f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.007229   1.989802  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9898024265275085]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:58:39.575117Z",
     "start_time": "2018-04-15T11:58:39.075077Z"
    }
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:59:23.830603Z",
     "start_time": "2018-04-15T11:58:39.579629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ea8495c6e341bab8d1f6dcfa8a800c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.728301   1.714505  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7145047643787454]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:10:35.111474Z",
     "start_time": "2018-04-16T16:10:34.951537Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-99771947f5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bs' is not defined"
     ]
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:00.642963Z",
     "start_time": "2018-04-16T16:14:00.496566Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            print(h.size())\n",
    "            print(c.size())\n",
    "            print(self.e(c).size())\n",
    "            print(c)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:01.665675Z",
     "start_time": "2018-04-16T16:14:00.741015Z"
    }
   },
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:02.288537Z",
     "start_time": "2018-04-16T16:14:01.665675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      "  1\n",
      "  9\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 36\n",
      " 67\n",
      " 71\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 67\n",
      " 63\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 23\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 73\n",
      " 58\n",
      " 72\n",
      " 74\n",
      "  2\n",
      "  1\n",
      " 73\n",
      " 67\n",
      " 56\n",
      " 68\n",
      " 61\n",
      " 61\n",
      " 58\n",
      " 68\n",
      " 72\n",
      "  2\n",
      "  1\n",
      " 58\n",
      " 58\n",
      " 73\n",
      " 21\n",
      " 72\n",
      " 62\n",
      " 67\n",
      " 67\n",
      " 59\n",
      " 65\n",
      " 72\n",
      " 78\n",
      " 72\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 47\n",
      "  2\n",
      " 68\n",
      " 62\n",
      " 54\n",
      " 56\n",
      " 68\n",
      " 54\n",
      " 72\n",
      "  1\n",
      " 59\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 68\n",
      " 73\n",
      " 54\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 62\n",
      " 68\n",
      " 56\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 71\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 54\n",
      " 10\n",
      " 58\n",
      " 65\n",
      " 58\n",
      " 33\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 67\n",
      " 73\n",
      " 67\n",
      " 72\n",
      " 65\n",
      " 56\n",
      " 67\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 61\n",
      " 59\n",
      " 67\n",
      " 73\n",
      " 67\n",
      " 67\n",
      " 72\n",
      " 10\n",
      " 58\n",
      "  8\n",
      "  2\n",
      " 68\n",
      " 66\n",
      " 54\n",
      " 60\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 73\n",
      " 69\n",
      " 10\n",
      " 62\n",
      " 68\n",
      " 59\n",
      " 62\n",
      " 72\n",
      " 60\n",
      " 55\n",
      " 68\n",
      "  2\n",
      " 37\n",
      "  2\n",
      " 68\n",
      " 54\n",
      " 62\n",
      "  8\n",
      " 77\n",
      " 71\n",
      " 62\n",
      " 58\n",
      " 65\n",
      " 73\n",
      " 72\n",
      " 74\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 66\n",
      " 71\n",
      " 71\n",
      " 67\n",
      " 65\n",
      " 74\n",
      " 68\n",
      " 61\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 56\n",
      " 75\n",
      " 54\n",
      " 72\n",
      "  2\n",
      " 67\n",
      " 67\n",
      " 10\n",
      " 57\n",
      " 72\n",
      " 66\n",
      " 67\n",
      " 59\n",
      " 69\n",
      " 65\n",
      " 56\n",
      " 58\n",
      "  8\n",
      " 66\n",
      " 68\n",
      " 10\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 75\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 24\n",
      " 58\n",
      " 55\n",
      " 72\n",
      " 62\n",
      " 22\n",
      " 58\n",
      " 54\n",
      " 54\n",
      " 72\n",
      " 66\n",
      " 57\n",
      "  2\n",
      " 55\n",
      "  8\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 73\n",
      " 10\n",
      " 56\n",
      " 64\n",
      " 73\n",
      " 72\n",
      " 62\n",
      " 61\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 78\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 25\n",
      " 67\n",
      "  2\n",
      " 71\n",
      " 59\n",
      " 54\n",
      " 73\n",
      "  1\n",
      "  2\n",
      "  1\n",
      "  1\n",
      " 71\n",
      " 58\n",
      " 71\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 62\n",
      "  2\n",
      " 72\n",
      " 71\n",
      " 69\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 68\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 72\n",
      " 59\n",
      " 58\n",
      " 76\n",
      " 56\n",
      " 58\n",
      " 68\n",
      " 60\n",
      " 71\n",
      " 65\n",
      " 61\n",
      " 67\n",
      " 59\n",
      " 73\n",
      " 58\n",
      " 72\n",
      " 78\n",
      " 68\n",
      " 65\n",
      " 72\n",
      " 54\n",
      "  2\n",
      " 57\n",
      " 73\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 72\n",
      " 66\n",
      " 54\n",
      " 58\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 61\n",
      " 54\n",
      "  2\n",
      "  8\n",
      " 67\n",
      " 72\n",
      " 58\n",
      " 60\n",
      " 65\n",
      " 58\n",
      " 66\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 76\n",
      " 68\n",
      " 56\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 59\n",
      " 71\n",
      " 61\n",
      " 68\n",
      " 67\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 61\n",
      " 65\n",
      " 55\n",
      " 73\n",
      " 55\n",
      " 71\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 44\n",
      " 73\n",
      " 60\n",
      "  9\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 78\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 31\n",
      "  8\n",
      " 60\n",
      " 78\n",
      " 72\n",
      " 68\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 68\n",
      " 58\n",
      " 65\n",
      " 71\n",
      " 59\n",
      " 68\n",
      " 58\n",
      " 56\n",
      " 74\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 72\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 73\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 65\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 61\n",
      " 58\n",
      " 57\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 34\n",
      " 78\n",
      " 59\n",
      " 56\n",
      " 67\n",
      "  2\n",
      " 65\n",
      " 75\n",
      " 55\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 61\n",
      " 74\n",
      "  1\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 78\n",
      " 71\n",
      " 57\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 72\n",
      " 62\n",
      " 72\n",
      " 60\n",
      " 76\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 24\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 57\n",
      " 54\n",
      " 57\n",
      " 57\n",
      " 68\n",
      " 56\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 54\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 67\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 58\n",
      " 68\n",
      " 75\n",
      " 54\n",
      " 68\n",
      " 57\n",
      " 66\n",
      " 44\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 73\n",
      " 69\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 78\n",
      " 72\n",
      " 74\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  4\n",
      " 57\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 54\n",
      "  3\n",
      " 54\n",
      " 71\n",
      " 67\n",
      " 69\n",
      " 54\n",
      " 59\n",
      " 54\n",
      "  4\n",
      " 57\n",
      " 69\n",
      " 44\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 72\n",
      "  9\n",
      " 61\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 60\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 55\n",
      " 75\n",
      " 70\n",
      "  2\n",
      " 68\n",
      " 64\n",
      " 59\n",
      "  1\n",
      " 46\n",
      " 68\n",
      " 78\n",
      " 70\n",
      " 58\n",
      " 71\n",
      " 65\n",
      " 73\n",
      " 67\n",
      " 73\n",
      "  1\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 74\n",
      " 54\n",
      " 58\n",
      " 71\n",
      " 72\n",
      " 68\n",
      " 73\n",
      "  1\n",
      " 65\n",
      " 72\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 59\n",
      "  8\n",
      "  2\n",
      " 69\n",
      " 54\n",
      " 68\n",
      " 73\n",
      " 32\n",
      " 62\n",
      " 55\n",
      " 71\n",
      " 65\n",
      " 71\n",
      " 62\n",
      "  8\n",
      " 71\n",
      "  2\n",
      " 68\n",
      "  8\n",
      " 71\n",
      " 58\n",
      " 60\n",
      " 74\n",
      " 73\n",
      " 73\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 54\n",
      " 71\n",
      " 57\n",
      " 71\n",
      " 58\n",
      " 57\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 68\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 61\n",
      " 73\n",
      " 72\n",
      "  4\n",
      "  8\n",
      " 54\n",
      " 67\n",
      " 42\n",
      " 62\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 61\n",
      " 57\n",
      " 73\n",
      " 57\n",
      " 64\n",
      " 60\n",
      " 61\n",
      " 54\n",
      " 58\n",
      " 58\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 58\n",
      "  8\n",
      "  2\n",
      "  1\n",
      "  4\n",
      " 61\n",
      " 59\n",
      " 68\n",
      " 67\n",
      "  2\n",
      " 67\n",
      " 65\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 23\n",
      " 73\n",
      " 59\n",
      "  1\n",
      " 67\n",
      " 58\n",
      " 65\n",
      " 65\n",
      "  1\n",
      " 56\n",
      " 68\n",
      " 69\n",
      " 74\n",
      " 71\n",
      " 75\n",
      "  2\n",
      " 54\n",
      " 58\n",
      " 73\n",
      " 71\n",
      " 62\n",
      " 65\n",
      " 73\n",
      " 72\n",
      " 33\n",
      "  2\n",
      " 54\n",
      " 72\n",
      "  3\n",
      " 58\n",
      " 69\n",
      " 68\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 76\n",
      " 58\n",
      "  1\n",
      " 73\n",
      " 68\n",
      " 55\n",
      " 58\n",
      " 73\n",
      " 58\n",
      " 58\n",
      " 72\n",
      "  8\n",
      " 59\n",
      " 65\n",
      " 57\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 58\n",
      " 61\n",
      " 75\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 67\n",
      "  2\n",
      " 72\n",
      " 73\n",
      " 76\n",
      " 58\n",
      " 70\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 61\n",
      " 71\n",
      "  2\n",
      " 71\n",
      " 65\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 71\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 78\n",
      " 58\n",
      " 58\n",
      "  4\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  7\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 54\n",
      " 58\n",
      " 73\n",
      " 65\n",
      " 72\n",
      "  1\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 44\n",
      " 73\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 56\n",
      "  8\n",
      " 67\n",
      " 62\n",
      "  1\n",
      " 73\n",
      " 68\n",
      " 67\n",
      " 62\n",
      " 66\n",
      " 55\n",
      "  2\n",
      " 72\n",
      " 37\n",
      " 78\n",
      " 54\n",
      " 72\n",
      " 71\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 72\n",
      " 44\n",
      "  2\n",
      " 71\n",
      " 72\n",
      " 66\n",
      " 76\n",
      " 73\n",
      "  2\n",
      " 10\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 67\n",
      " 67\n",
      "  2\n",
      " 68\n",
      "  4\n",
      " 58\n",
      " 64\n",
      "  2\n",
      " 78\n",
      " 72\n",
      " 73\n",
      "  2\n",
      " 75\n",
      " 59\n",
      " 58\n",
      " 66\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 54\n",
      " 71\n",
      "  1\n",
      " 30\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 68\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 39\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 65\n",
      " 71\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 60\n",
      " 61\n",
      " 73\n",
      " 68\n",
      " 78\n",
      " 67\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 57\n",
      " 72\n",
      "  2\n",
      "  8\n",
      " 54\n",
      " 54\n",
      " 58\n",
      " 62\n",
      " 72\n",
      " 62\n",
      " 60\n",
      " 57\n",
      " 76\n",
      " 61\n",
      " 62\n",
      " 62\n",
      "  9\n",
      " 73\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 71\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 60\n",
      "  1\n",
      " 68\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 73\n",
      " 71\n",
      " 58\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 66\n",
      " 76\n",
      "  2\n",
      " 73\n",
      " 59\n",
      " 72\n",
      "  2\n",
      " 61\n",
      " 65\n",
      " 59\n",
      " 58\n",
      " 68\n",
      " 57\n",
      " 62\n",
      " 67\n",
      " 28\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 56\n",
      " 65\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 76\n",
      " 71\n",
      " 61\n",
      " 45\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 56\n",
      " 54\n",
      " 65\n",
      " 58\n",
      " 58\n",
      " 72\n",
      " 62\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 73\n",
      " 69\n",
      "  2\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 72\n",
      " 60\n",
      " 21\n",
      " 66\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      "  8\n",
      " 67\n",
      " 54\n",
      "  2\n",
      " 60\n",
      "  2\n",
      " 65\n",
      " 78\n",
      " 66\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 61\n",
      " 68\n",
      " 62\n",
      " 57\n",
      " 72\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 65\n",
      " 71\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 43\n",
      " 66\n",
      " 57\n",
      " 67\n",
      " 61\n",
      " 71\n",
      " 66\n",
      " 72\n",
      " 54\n",
      " 22\n",
      "  1\n",
      " 56\n",
      " 60\n",
      " 74\n",
      " 71\n",
      "  2\n",
      "  2\n",
      "  4\n",
      "  2\n",
      " 33\n",
      " 68\n",
      "  1\n",
      " 67\n",
      " 60\n",
      " 57\n",
      " 58\n",
      " 56\n",
      " 59\n",
      " 56\n",
      " 60\n",
      "  2\n",
      " 58\n",
      " 68\n",
      "  2\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 58\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 54\n",
      " 76\n",
      "  2\n",
      "  2\n",
      " 56\n",
      " 61\n",
      " 58\n",
      " 58\n",
      " 74\n",
      " 73\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 66\n",
      " 62\n",
      " 67\n",
      " 58\n",
      " 74\n",
      " 72\n",
      " 74\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  1\n",
      " 66\n",
      " 58\n",
      " 58\n",
      " 67\n",
      " 73\n",
      "  1\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 23\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 73\n",
      " 62\n",
      " 57\n",
      " 57\n",
      " 55\n",
      " 68\n",
      " 22\n",
      "  2\n",
      " 54\n",
      " 62\n",
      " 73\n",
      " 67\n",
      " 74\n",
      " 68\n",
      " 65\n",
      " 78\n",
      " 54\n",
      " 65\n",
      "  2\n",
      " 57\n",
      "  2\n",
      " 56\n",
      " 55\n",
      " 56\n",
      "  2\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 74\n",
      " 62\n",
      " 73\n",
      " 61\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 72\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 68\n",
      " 67\n",
      " 54\n",
      " 61\n",
      "  2\n",
      "  1\n",
      "  2\n",
      " 72\n",
      " 56\n",
      " 39\n",
      " 67\n",
      " 68\n",
      " 60\n",
      " 68\n",
      "  2\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 76\n",
      " 58\n",
      " 58\n",
      " 72\n",
      " 75\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 67\n",
      " 57\n",
      "  2\n",
      " 39\n",
      " 69\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 57\n",
      " 68\n",
      " 57\n",
      "  8\n",
      " 69\n",
      " 58\n",
      " 71\n",
      "  9\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 57\n",
      " 65\n",
      " 68\n",
      " 58\n",
      " 69\n",
      " 74\n",
      " 57\n",
      " 71\n",
      " 60\n",
      " 73\n",
      " 58\n",
      " 54\n",
      " 66\n",
      " 56\n",
      " 72\n",
      " 76\n",
      " 58\n",
      " 78\n",
      " 74\n",
      " 54\n",
      " 59\n",
      " 73\n",
      " 67\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 65\n",
      " 74\n",
      " 54\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 55\n",
      " 78\n",
      "  8\n",
      "  2\n",
      "  1\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 78\n",
      "  1\n",
      " 29\n",
      " 58\n",
      " 65\n",
      " 72\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 72\n",
      " 56\n",
      " 33\n",
      " 76\n",
      " 61\n",
      " 61\n",
      " 72\n",
      " 74\n",
      " 57\n",
      " 61\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 58\n",
      " 58\n",
      " 54\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 55\n",
      " 59\n",
      " 57\n",
      " 78\n",
      " 71\n",
      " 22\n",
      "  8\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 65\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 73\n",
      " 60\n",
      " 72\n",
      " 73\n",
      " 73\n",
      " 45\n",
      " 58\n",
      " 61\n",
      " 54\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 12\n",
      " 62\n",
      " 65\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 75\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 71\n",
      "  2\n",
      "  8\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 76\n",
      " 65\n",
      " 74\n",
      " 55\n",
      " 62\n",
      " 61\n",
      " 54\n",
      "  7\n",
      " 57\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 74\n",
      " 21\n",
      "  2\n",
      "  2\n",
      " 66\n",
      "  8\n",
      "  2\n",
      " 71\n",
      " 54\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 54\n",
      " 54\n",
      " 58\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 68\n",
      " 68\n",
      "  8\n",
      " 68\n",
      " 67\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 72\n",
      " 73\n",
      " 67\n",
      " 54\n",
      " 76\n",
      " 73\n",
      " 78\n",
      " 58\n",
      " 73\n",
      " 68\n",
      " 72\n",
      " 75\n",
      " 61\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 61\n",
      " 66\n",
      "  2\n",
      " 57\n",
      " 68\n",
      " 54\n",
      " 62\n",
      " 67\n",
      " 62\n",
      "  2\n",
      " 68\n",
      " 38\n",
      "  2\n",
      " 73\n",
      " 55\n",
      " 56\n",
      " 68\n",
      " 62\n",
      " 73\n",
      "  1\n",
      " 74\n",
      " 68\n",
      " 62\n",
      " 67\n",
      " 72\n",
      " 62\n",
      " 61\n",
      " 74\n",
      " 54\n",
      " 76\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 60\n",
      " 62\n",
      " 73\n",
      " 65\n",
      " 71\n",
      " 76\n",
      " 57\n",
      " 61\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 57\n",
      "  1\n",
      "  9\n",
      " 68\n",
      "  5\n",
      " 74\n",
      "  1\n",
      " 67\n",
      "  2\n",
      " 33\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 68\n",
      " 71\n",
      " 67\n",
      " 56\n",
      " 56\n",
      " 71\n",
      " 61\n",
      " 66\n",
      " 58\n",
      " 31\n",
      " 73\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 67\n",
      " 68\n",
      " 71\n",
      " 56\n",
      " 68\n",
      " 60\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 71\n",
      " 73\n",
      " 66\n",
      " 54\n",
      " 65\n",
      " 66\n",
      " 61\n",
      " 73\n",
      " 58\n",
      "  1\n",
      " 72\n",
      " 68\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 61\n",
      " 57\n",
      " 33\n",
      "  2\n",
      " 69\n",
      " 66\n",
      " 62\n",
      " 65\n",
      " 73\n",
      "  2\n",
      " 68\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 62\n",
      " 74\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 66\n",
      "  8\n",
      " 58\n",
      " 76\n",
      " 58\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 78\n",
      " 70\n",
      " 60\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 69\n",
      " 54\n",
      " 62\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 74\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 60\n",
      " 54\n",
      "  2\n",
      " 24\n",
      "  2\n",
      " 51\n",
      " 72\n",
      " 60\n",
      " 59\n",
      " 67\n",
      " 71\n",
      "  1\n",
      " 57\n",
      " 74\n",
      " 71\n",
      " 65\n",
      " 65\n",
      " 62\n",
      " 56\n",
      " 68\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 73\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 67\n",
      " 68\n",
      " 75\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 65\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 54\n",
      " 68\n",
      " 56\n",
      "  9\n",
      " 54\n",
      " 58\n",
      " 72\n",
      " 73\n",
      " 60\n",
      " 54\n",
      " 58\n",
      " 58\n",
      " 13\n",
      "  2\n",
      " 71\n",
      " 67\n",
      " 57\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 54\n",
      " 40\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 61\n",
      " 67\n",
      " 62\n",
      " 74\n",
      " 58\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 71\n",
      " 66\n",
      " 65\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 59\n",
      " 58\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 56\n",
      " 67\n",
      " 69\n",
      " 66\n",
      " 68\n",
      " 72\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 75\n",
      " 62\n",
      " 54\n",
      " 73\n",
      " 68\n",
      " 54\n",
      " 65\n",
      " 54\n",
      " 61\n",
      " 59\n",
      " 73\n",
      " 71\n",
      " 57\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 62\n",
      "  8\n",
      " 58\n",
      " 38\n",
      " 60\n",
      " 68\n",
      "  2\n",
      "  1\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 67\n",
      " 54\n",
      " 10\n",
      "  2\n",
      "  1\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 54\n",
      " 73\n",
      " 60\n",
      "  2\n",
      " 73\n",
      " 71\n",
      " 71\n",
      " 61\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  8\n",
      " 67\n",
      "  2\n",
      "  1\n",
      " 62\n",
      "  2\n",
      " 54\n",
      "  9\n",
      " 66\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 75\n",
      " 76\n",
      "  1\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 62\n",
      "  2\n",
      " 72\n",
      " 69\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 72\n",
      "  2\n",
      " 69\n",
      " 65\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 72\n",
      " 26\n",
      " 60\n",
      " 58\n",
      " 60\n",
      " 67\n",
      " 61\n",
      " 68\n",
      " 58\n",
      "  8\n",
      " 65\n",
      " 65\n",
      " 76\n",
      " 72\n",
      " 10\n",
      "  2\n",
      " 62\n",
      " 60\n",
      " 62\n",
      " 73\n",
      " 69\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 54\n",
      " 78\n",
      " 73\n",
      " 57\n",
      " 62\n",
      " 65\n",
      " 72\n",
      " 57\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 58\n",
      " 38\n",
      " 68\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 69\n",
      " 67\n",
      "  8\n",
      "  2\n",
      " 65\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 74\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 54\n",
      "  4\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 39\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 56\n",
      "  2\n",
      " 60\n",
      " 62\n",
      " 54\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 61\n",
      " 42\n",
      " 71\n",
      " 58\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 73\n",
      " 13\n",
      " 66\n",
      "  8\n",
      " 65\n",
      " 60\n",
      " 67\n",
      " 65\n",
      " 54\n",
      " 59\n",
      " 64\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 65\n",
      " 62\n",
      " 68\n",
      " 66\n",
      " 58\n",
      " 54\n",
      " 57\n",
      " 69\n",
      " 65\n",
      " 73\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 62\n",
      " 68\n",
      " 65\n",
      " 59\n",
      "  2\n",
      " 68\n",
      " 68\n",
      " 72\n",
      "  9\n",
      " 66\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 62\n",
      " 56\n",
      " 73\n",
      " 73\n",
      "  2\n",
      "  1\n",
      " 71\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 74\n",
      "  2\n",
      " 69\n",
      " 60\n",
      " 54\n",
      " 62\n",
      " 75\n",
      " 55\n",
      "  3\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 54\n",
      " 62\n",
      " 74\n",
      " 73\n",
      " 58\n",
      " 54\n",
      " 54\n",
      " 73\n",
      " 56\n",
      " 58\n",
      " 69\n",
      " 59\n",
      "  2\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 68\n",
      " 65\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 68\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 74\n",
      " 76\n",
      " 73\n",
      " 66\n",
      " 72\n",
      " 60\n",
      " 73\n",
      " 73\n",
      " 58\n",
      " 67\n",
      " 66\n",
      " 58\n",
      " 67\n",
      " 72\n",
      " 54\n",
      " 62\n",
      " 67\n",
      " 61\n",
      " 65\n",
      " 58\n",
      " 61\n",
      "  8\n",
      " 68\n",
      " 60\n",
      " 75\n",
      " 55\n",
      "  1\n",
      " 69\n",
      " 68\n",
      " 54\n",
      " 59\n",
      " 73\n",
      " 72\n",
      " 58\n",
      " 54\n",
      " 56\n",
      "  2\n",
      " 58\n",
      " 69\n",
      "  9\n",
      " 71\n",
      " 72\n",
      " 71\n",
      " 68\n",
      " 60\n",
      " 73\n",
      " 43\n",
      " 66\n",
      " 78\n",
      " 57\n",
      " 62\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 61\n",
      " 68\n",
      " 72\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 25\n",
      " 61\n",
      "  8\n",
      " 10\n",
      " 10\n",
      " 57\n",
      " 76\n",
      " 78\n",
      " 54\n",
      "  2\n",
      " 61\n",
      " 73\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 71\n",
      " 54\n",
      " 68\n",
      " 58\n",
      " 62\n",
      "  8\n",
      " 78\n",
      "  1\n",
      " 67\n",
      " 62\n",
      "  2\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 73\n",
      " 71\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 74\n",
      " 58\n",
      " 59\n",
      " 54\n",
      " 73\n",
      " 58\n",
      " 76\n",
      " 67\n",
      " 56\n",
      " 68\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 78\n",
      " 55\n",
      " 72\n",
      " 68\n",
      " 72\n",
      " 74\n",
      " 61\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 69\n",
      " 68\n",
      " 78\n",
      " 58\n",
      " 57\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 56\n",
      " 56\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 58\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 75\n",
      " 30\n",
      " 58\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 57\n",
      "  1\n",
      "  2\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 68\n",
      " 68\n",
      " 61\n",
      " 73\n",
      " 60\n",
      " 61\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 72\n",
      " 76\n",
      " 58\n",
      " 66\n",
      " 60\n",
      " 68\n",
      " 67\n",
      " 68\n",
      " 66\n",
      " 73\n",
      " 67\n",
      " 68\n",
      " 65\n",
      " 54\n",
      " 72\n",
      " 60\n",
      " 65\n",
      " 66\n",
      " 73\n",
      " 59\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 62\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 16\n",
      " 54\n",
      " 69\n",
      " 56\n",
      "  2\n",
      " 60\n",
      " 67\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 68\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 75\n",
      " 71\n",
      "  1\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 57\n",
      " 62\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 62\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 72\n",
      " 62\n",
      "  9\n",
      " 54\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 59\n",
      " 58\n",
      " 58\n",
      " 71\n",
      " 73\n",
      " 62\n",
      " 54\n",
      " 68\n",
      " 69\n",
      " 58\n",
      " 59\n",
      " 67\n",
      " 78\n",
      " 78\n",
      " 54\n",
      " 62\n",
      " 61\n",
      " 78\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 66\n",
      "  2\n",
      " 51\n",
      " 73\n",
      "  2\n",
      "  8\n",
      " 37\n",
      "  3\n",
      " 64\n",
      " 62\n",
      " 25\n",
      " 61\n",
      " 72\n",
      " 78\n",
      " 68\n",
      " 71\n",
      " 23\n",
      " 56\n",
      " 39\n",
      " 71\n",
      " 59\n",
      " 58\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 73\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 58\n",
      " 57\n",
      " 74\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 72\n",
      " 58\n",
      " 65\n",
      " 66\n",
      " 73\n",
      " 47\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 68\n",
      " 65\n",
      " 62\n",
      " 71\n",
      " 55\n",
      " 73\n",
      " 54\n",
      " 66\n",
      "  2\n",
      " 65\n",
      " 72\n",
      " 54\n",
      " 71\n",
      "  4\n",
      " 66\n",
      " 62\n",
      " 62\n",
      " 76\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 71\n",
      "  8\n",
      " 61\n",
      " 57\n",
      " 68\n",
      " 76\n",
      " 66\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 56\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 68\n",
      " 67\n",
      " 61\n",
      " 58\n",
      " 57\n",
      " 54\n",
      " 62\n",
      " 68\n",
      " 57\n",
      "  1\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 68\n",
      " 21\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 69\n",
      " 43\n",
      " 71\n",
      " 73\n",
      " 73\n",
      " 54\n",
      " 67\n",
      " 67\n",
      "  2\n",
      " 78\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 60\n",
      " 78\n",
      " 57\n",
      " 54\n",
      " 73\n",
      " 68\n",
      " 71\n",
      " 73\n",
      " 71\n",
      " 73\n",
      " 59\n",
      " 72\n",
      " 72\n",
      " 68\n",
      " 56\n",
      " 72\n",
      " 67\n",
      "  1\n",
      " 75\n",
      " 54\n",
      " 59\n",
      " 67\n",
      " 59\n",
      " 61\n",
      " 61\n",
      "  8\n",
      " 54\n",
      " 71\n",
      " 67\n",
      " 62\n",
      " 65\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 25\n",
      " 72\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 68\n",
      " 61\n",
      " 60\n",
      " 68\n",
      " 16\n",
      " 58\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 62\n",
      " 65\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 65\n",
      " 65\n",
      " 76\n",
      " 65\n",
      " 68\n",
      " 59\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 10\n",
      " 69\n",
      " 58\n",
      " 61\n",
      " 72\n",
      " 65\n",
      " 25\n",
      " 72\n",
      " 66\n",
      "  8\n",
      " 62\n",
      " 68\n",
      " 59\n",
      "  2\n",
      "  2\n",
      "  9\n",
      " 68\n",
      " 55\n",
      " 67\n",
      " 54\n",
      " 62\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 61\n",
      " 56\n",
      " 56\n",
      "  2\n",
      " 61\n",
      " 57\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 67\n",
      " 55\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 62\n",
      " 74\n",
      " 73\n",
      " 57\n",
      " 57\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 58\n",
      " 60\n",
      "  2\n",
      " 71\n",
      " 72\n",
      " 73\n",
      " 61\n",
      " 61\n",
      " 71\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 62\n",
      "  4\n",
      " 10\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 62\n",
      " 71\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  1\n",
      "  2\n",
      "  2\n",
      "  2\n",
      "  1\n",
      " 54\n",
      " 58\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 75\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 76\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 75\n",
      " 68\n",
      " 72\n",
      " 76\n",
      " 59\n",
      " 76\n",
      " 58\n",
      " 70\n",
      " 72\n",
      " 74\n",
      " 72\n",
      " 65\n",
      " 71\n",
      " 73\n",
      "  2\n",
      "  1\n",
      "  1\n",
      " 67\n",
      "  1\n",
      " 61\n",
      " 44\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 74\n",
      " 61\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 66\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 64\n",
      " 44\n",
      " 58\n",
      "  2\n",
      "  2\n",
      "  2\n",
      "  1\n",
      "  8\n",
      " 73\n",
      " 74\n",
      " 56\n",
      " 73\n",
      " 71\n",
      " 64\n",
      " 59\n",
      " 57\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 56\n",
      " 56\n",
      " 66\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 59\n",
      " 65\n",
      " 68\n",
      " 62\n",
      " 61\n",
      " 72\n",
      " 54\n",
      "  2\n",
      " 61\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 59\n",
      " 54\n",
      " 58\n",
      " 72\n",
      "  8\n",
      "  2\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 56\n",
      " 74\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 69\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  1\n",
      " 59\n",
      " 73\n",
      " 54\n",
      "  1\n",
      " 54\n",
      " 66\n",
      " 30\n",
      " 69\n",
      " 71\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 78\n",
      " 10\n",
      "  1\n",
      " 54\n",
      " 61\n",
      " 61\n",
      " 65\n",
      " 72\n",
      " 67\n",
      " 62\n",
      " 67\n",
      " 76\n",
      " 54\n",
      " 39\n",
      " 67\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 62\n",
      " 13\n",
      " 73\n",
      " 58\n",
      " 67\n",
      " 72\n",
      "  4\n",
      " 74\n",
      " 74\n",
      " 57\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 54\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 59\n",
      " 57\n",
      " 67\n",
      " 66\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 62\n",
      " 73\n",
      "  2\n",
      "  5\n",
      " 65\n",
      " 58\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 56\n",
      " 68\n",
      "  2\n",
      " 68\n",
      " 60\n",
      " 73\n",
      " 62\n",
      "  1\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 62\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 77\n",
      " 75\n",
      "  2\n",
      " 58\n",
      " 61\n",
      " 59\n",
      " 73\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 62\n",
      " 58\n",
      " 62\n",
      " 61\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 73\n",
      " 68\n",
      " 73\n",
      " 59\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 73\n",
      "  2\n",
      "  8\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 56\n",
      " 65\n",
      " 67\n",
      " 72\n",
      "  1\n",
      "  2\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 72\n",
      " 56\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 73\n",
      " 10\n",
      " 56\n",
      " 14\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 29\n",
      "  1\n",
      "  2\n",
      " 67\n",
      " 42\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 73\n",
      " 57\n",
      "  9\n",
      " 68\n",
      " 42\n",
      " 78\n",
      " 73\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 37\n",
      " 61\n",
      " 58\n",
      " 61\n",
      " 72\n",
      "  2\n",
      "  8\n",
      " 71\n",
      " 66\n",
      " 73\n",
      " 72\n",
      " 68\n",
      " 75\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 61\n",
      " 64\n",
      " 60\n",
      " 54\n",
      " 59\n",
      " 72\n",
      " 68\n",
      " 74\n",
      " 62\n",
      " 68\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 65\n",
      " 58\n",
      " 58\n",
      " 74\n",
      " 57\n",
      "  9\n",
      " 68\n",
      " 57\n",
      " 73\n",
      " 68\n",
      " 73\n",
      " 73\n",
      " 62\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 75\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 30\n",
      " 61\n",
      "  2\n",
      " 75\n",
      "  2\n",
      " 68\n",
      " 71\n",
      "  2\n",
      " 66\n",
      " 72\n",
      " 74\n",
      "  1\n",
      " 76\n",
      " 61\n",
      "  8\n",
      " 60\n",
      " 72\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 73\n",
      " 72\n",
      " 73\n",
      " 44\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 73\n",
      " 60\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 58\n",
      " 54\n",
      " 71\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 61\n",
      " 60\n",
      "  1\n",
      "  2\n",
      " 66\n",
      " 61\n",
      " 68\n",
      " 69\n",
      " 68\n",
      " 71\n",
      " 54\n",
      " 72\n",
      " 57\n",
      " 76\n",
      " 58\n",
      " 56\n",
      " 54\n",
      "  2\n",
      " 74\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 60\n",
      " 71\n",
      " 65\n",
      " 60\n",
      " 65\n",
      " 68\n",
      " 78\n",
      " 37\n",
      "  2\n",
      " 76\n",
      "  2\n",
      " 73\n",
      " 59\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 10\n",
      " 72\n",
      " 73\n",
      " 56\n",
      " 69\n",
      " 59\n",
      " 58\n",
      " 58\n",
      " 75\n",
      "  2\n",
      " 65\n",
      " 78\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 67\n",
      "  2\n",
      "  1\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 68\n",
      "  1\n",
      "  1\n",
      " 68\n",
      "  2\n",
      " 67\n",
      " 60\n",
      " 58\n",
      "  2\n",
      " 56\n",
      " 59\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 73\n",
      " 73\n",
      " 68\n",
      "  8\n",
      " 67\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 61\n",
      " 69\n",
      " 73\n",
      " 58\n",
      " 69\n",
      " 60\n",
      " 65\n",
      " 57\n",
      " 72\n",
      " 55\n",
      " 73\n",
      " 69\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 54\n",
      " 69\n",
      "  2\n",
      " 72\n",
      " 61\n",
      " 73\n",
      "  2\n",
      "  2\n",
      "  1\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 62\n",
      " 56\n",
      " 67\n",
      " 69\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 57\n",
      " 72\n",
      " 62\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 65\n",
      " 62\n",
      " 58\n",
      " 67\n",
      " 72\n",
      " 65\n",
      " 68\n",
      " 62\n",
      " 56\n",
      " 56\n",
      " 65\n",
      " 58\n",
      " 62\n",
      " 60\n",
      " 66\n",
      " 58\n",
      " 73\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 65\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 68\n",
      "  2\n",
      " 74\n",
      "  1\n",
      " 65\n",
      " 74\n",
      " 62\n",
      " 68\n",
      " 61\n",
      " 54\n",
      " 76\n",
      " 67\n",
      " 58\n",
      " 75\n",
      " 58\n",
      " 33\n",
      " 65\n",
      " 56\n",
      " 78\n",
      " 73\n",
      " 54\n",
      " 72\n",
      " 58\n",
      " 67\n",
      " 69\n",
      " 76\n",
      " 69\n",
      " 68\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 29\n",
      "  2\n",
      " 68\n",
      " 44\n",
      " 25\n",
      " 62\n",
      "  2\n",
      " 61\n",
      " 72\n",
      " 54\n",
      " 58\n",
      " 54\n",
      " 62\n",
      "  2\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 59\n",
      "  2\n",
      " 64\n",
      " 71\n",
      "  8\n",
      " 67\n",
      " 73\n",
      " 73\n",
      " 71\n",
      " 78\n",
      " 74\n",
      " 72\n",
      " 62\n",
      " 58\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 67\n",
      " 67\n",
      " 66\n",
      " 54\n",
      " 73\n",
      " 71\n",
      "  8\n",
      "  1\n",
      " 73\n",
      " 73\n",
      " 56\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 69\n",
      " 54\n",
      " 61\n",
      "  2\n",
      " 56\n",
      " 68\n",
      " 65\n",
      " 54\n",
      " 59\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 65\n",
      " 72\n",
      "  2\n",
      " 69\n",
      " 71\n",
      " 65\n",
      "  2\n",
      " 54\n",
      " 56\n",
      "  2\n",
      "  2\n",
      "  4\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 58\n",
      " 78\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 56\n",
      " 61\n",
      " 65\n",
      " 39\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 62\n",
      " 67\n",
      " 13\n",
      " 61\n",
      " 67\n",
      " 56\n",
      " 61\n",
      "  2\n",
      " 65\n",
      " 67\n",
      "  4\n",
      "  2\n",
      " 62\n",
      " 75\n",
      " 73\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      "  2\n",
      " 57\n",
      " 72\n",
      " 67\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 56\n",
      " 54\n",
      " 73\n",
      " 66\n",
      " 72\n",
      " 73\n",
      "  2\n",
      " 74\n",
      " 24\n",
      "  2\n",
      " 67\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 58\n",
      " 59\n",
      " 62\n",
      " 74\n",
      " 65\n",
      " 71\n",
      " 67\n",
      "  1\n",
      " 57\n",
      " 72\n",
      "  2\n",
      " 67\n",
      " 75\n",
      "  2\n",
      " 67\n",
      " 70\n",
      " 58\n",
      " 66\n",
      " 74\n",
      " 58\n",
      "  1\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 57\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 54\n",
      "  2\n",
      " 72\n",
      " 22\n",
      " 69\n",
      " 67\n",
      " 62\n",
      "  8\n",
      " 68\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 66\n",
      " 54\n",
      " 66\n",
      " 73\n",
      " 54\n",
      " 62\n",
      " 57\n",
      " 61\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 72\n",
      " 63\n",
      " 54\n",
      "  8\n",
      " 71\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 66\n",
      " 62\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 68\n",
      " 52\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 38\n",
      "  1\n",
      " 62\n",
      "  2\n",
      " 37\n",
      "  2\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 66\n",
      " 33\n",
      "  1\n",
      " 58\n",
      " 61\n",
      " 71\n",
      " 65\n",
      " 25\n",
      " 58\n",
      " 67\n",
      " 58\n",
      " 58\n",
      " 61\n",
      "  2\n",
      "  1\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 60\n",
      " 63\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 68\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 75\n",
      " 73\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 62\n",
      " 67\n",
      " 68\n",
      "  8\n",
      " 65\n",
      " 73\n",
      " 72\n",
      "  9\n",
      " 71\n",
      " 62\n",
      " 78\n",
      " 66\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 54\n",
      " 68\n",
      " 78\n",
      " 72\n",
      " 58\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 58\n",
      " 66\n",
      " 54\n",
      " 67\n",
      " 65\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 62\n",
      " 72\n",
      " 61\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 60\n",
      " 60\n",
      " 61\n",
      " 54\n",
      "  2\n",
      " 72\n",
      " 68\n",
      " 33\n",
      " 62\n",
      " 61\n",
      "  2\n",
      " 69\n",
      " 62\n",
      " 33\n",
      "  8\n",
      " 66\n",
      " 73\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 69\n",
      "  2\n",
      " 72\n",
      " 65\n",
      " 72\n",
      " 54\n",
      " 68\n",
      " 76\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 71\n",
      " 76\n",
      " 10\n",
      " 58\n",
      " 71\n",
      " 68\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 61\n",
      " 71\n",
      " 56\n",
      " 56\n",
      " 73\n",
      " 67\n",
      " 72\n",
      "  2\n",
      " 72\n",
      " 57\n",
      " 54\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 72\n",
      " 76\n",
      "  1\n",
      "  2\n",
      " 62\n",
      " 68\n",
      " 54\n",
      " 61\n",
      "  2\n",
      "  2\n",
      " 55\n",
      " 56\n",
      "  2\n",
      "  8\n",
      " 68\n",
      " 64\n",
      " 54\n",
      " 58\n",
      " 75\n",
      " 74\n",
      " 68\n",
      " 36\n",
      " 68\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 73\n",
      "  2\n",
      " 75\n",
      " 73\n",
      " 55\n",
      " 59\n",
      " 29\n",
      " 71\n",
      " 55\n",
      " 60\n",
      " 66\n",
      " 73\n",
      " 57\n",
      " 74\n",
      " 67\n",
      " 62\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 61\n",
      " 61\n",
      " 62\n",
      " 74\n",
      "  2\n",
      " 57\n",
      " 56\n",
      "  4\n",
      " 70\n",
      " 58\n",
      " 54\n",
      " 71\n",
      " 68\n",
      " 71\n",
      " 71\n",
      " 66\n",
      " 59\n",
      "  2\n",
      " 66\n",
      " 58\n",
      " 68\n",
      " 71\n",
      " 65\n",
      " 61\n",
      " 58\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 74\n",
      " 72\n",
      " 68\n",
      " 58\n",
      " 73\n",
      " 78\n",
      " 72\n",
      " 69\n",
      " 72\n",
      "  1\n",
      "  8\n",
      " 61\n",
      " 54\n",
      " 67\n",
      " 69\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 62\n",
      " 58\n",
      " 68\n",
      " 54\n",
      " 61\n",
      " 39\n",
      " 67\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 66\n",
      " 54\n",
      " 62\n",
      " 56\n",
      " 72\n",
      "  2\n",
      " 78\n",
      " 62\n",
      " 59\n",
      " 72\n",
      " 68\n",
      " 56\n",
      " 78\n",
      "  2\n",
      " 66\n",
      " 74\n",
      "  9\n",
      "  2\n",
      " 62\n",
      " 60\n",
      " 62\n",
      " 58\n",
      " 58\n",
      " 67\n",
      " 56\n",
      " 72\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 64\n",
      " 56\n",
      "  2\n",
      " 69\n",
      " 62\n",
      " 62\n",
      " 73\n",
      " 71\n",
      " 56\n",
      " 69\n",
      " 58\n",
      " 60\n",
      " 61\n",
      " 54\n",
      " 72\n",
      " 68\n",
      " 62\n",
      " 38\n",
      " 62\n",
      " 54\n",
      " 21\n",
      " 58\n",
      " 71\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 73\n",
      " 58\n",
      " 65\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 56\n",
      " 67\n",
      " 61\n",
      " 67\n",
      " 71\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 65\n",
      " 67\n",
      " 78\n",
      " 67\n",
      " 73\n",
      "  2\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 57\n",
      " 56\n",
      "  2\n",
      " 60\n",
      "  2\n",
      " 54\n",
      " 66\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 59\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 59\n",
      " 61\n",
      "  2\n",
      " 78\n",
      " 65\n",
      " 58\n",
      " 54\n",
      " 61\n",
      " 71\n",
      " 58\n",
      " 60\n",
      " 68\n",
      " 73\n",
      " 72\n",
      " 66\n",
      " 62\n",
      " 56\n",
      " 69\n",
      " 74\n",
      " 58\n",
      " 62\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 54\n",
      " 25\n",
      "  2\n",
      " 61\n",
      " 62\n",
      " 65\n",
      "  1\n",
      "  8\n",
      " 61\n",
      " 62\n",
      " 60\n",
      " 58\n",
      " 54\n",
      " 74\n",
      " 44\n",
      " 62\n",
      "  4\n",
      " 73\n",
      " 56\n",
      " 54\n",
      " 20\n",
      " 74\n",
      " 73\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 58\n",
      "  2\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 68\n",
      " 54\n",
      " 74\n",
      " 57\n",
      " 72\n",
      " 73\n",
      " 69\n",
      " 58\n",
      " 67\n",
      " 61\n",
      " 54\n",
      "  2\n",
      " 78\n",
      " 61\n",
      " 69\n",
      "  1\n",
      " 42\n",
      " 73\n",
      " 78\n",
      " 58\n",
      " 76\n",
      " 72\n",
      "  2\n",
      " 72\n",
      " 72\n",
      " 54\n",
      " 54\n",
      " 73\n",
      " 23\n",
      "  2\n",
      " 62\n",
      " 69\n",
      "  2\n",
      " 58\n",
      " 76\n",
      "  1\n",
      " 74\n",
      "  2\n",
      " 68\n",
      " 66\n",
      "  1\n",
      " 45\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 74\n",
      " 60\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 69\n",
      "  2\n",
      " 72\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 68\n",
      " 58\n",
      " 69\n",
      " 61\n",
      " 73\n",
      "  8\n",
      " 74\n",
      " 67\n",
      "  2\n",
      " 78\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 61\n",
      " 72\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 54\n",
      " 59\n",
      " 58\n",
      " 78\n",
      " 76\n",
      " 58\n",
      " 35\n",
      " 67\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 71\n",
      " 44\n",
      " 38\n",
      " 67\n",
      " 73\n",
      " 26\n",
      " 69\n",
      " 58\n",
      " 67\n",
      " 55\n",
      "  8\n",
      " 27\n",
      " 66\n",
      " 29\n",
      " 72\n",
      " 67\n",
      " 58\n",
      " 58\n",
      " 59\n",
      " 38\n",
      "  2\n",
      "  8\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 62\n",
      " 76\n",
      " 67\n",
      " 58\n",
      " 65\n",
      " 73\n",
      " 71\n",
      " 74\n",
      " 68\n",
      " 68\n",
      " 58\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 72\n",
      " 68\n",
      " 58\n",
      " 55\n",
      " 62\n",
      " 62\n",
      " 69\n",
      " 66\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 75\n",
      "  2\n",
      " 78\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 54\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 78\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 57\n",
      "  2\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 74\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 67\n",
      " 55\n",
      " 61\n",
      " 68\n",
      " 58\n",
      " 75\n",
      " 68\n",
      "  2\n",
      " 69\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 62\n",
      " 68\n",
      " 38\n",
      "  1\n",
      " 54\n",
      " 61\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 65\n",
      "  2\n",
      " 67\n",
      " 69\n",
      " 61\n",
      "  2\n",
      " 73\n",
      " 56\n",
      " 58\n",
      " 62\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 69\n",
      " 62\n",
      " 67\n",
      " 56\n",
      " 62\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 61\n",
      " 56\n",
      "  2\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 70\n",
      "  3\n",
      " 73\n",
      " 71\n",
      " 68\n",
      " 67\n",
      " 76\n",
      " 29\n",
      " 67\n",
      " 71\n",
      " 65\n",
      " 54\n",
      " 73\n",
      " 73\n",
      " 68\n",
      " 68\n",
      " 47\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 71\n",
      " 71\n",
      " 62\n",
      " 60\n",
      " 59\n",
      "  2\n",
      " 67\n",
      " 61\n",
      " 68\n",
      " 62\n",
      " 62\n",
      " 63\n",
      " 54\n",
      " 75\n",
      " 73\n",
      " 68\n",
      " 65\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 67\n",
      " 57\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 75\n",
      " 73\n",
      " 76\n",
      "  2\n",
      " 68\n",
      "  3\n",
      " 74\n",
      "  5\n",
      "  2\n",
      " 72\n",
      " 59\n",
      "  2\n",
      " 73\n",
      " 69\n",
      "  2\n",
      "  4\n",
      " 68\n",
      "  2\n",
      " 72\n",
      " 54\n",
      " 58\n",
      " 62\n",
      " 66\n",
      "  8\n",
      " 67\n",
      " 73\n",
      " 73\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 72\n",
      " 72\n",
      " 71\n",
      " 73\n",
      " 76\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 68\n",
      " 71\n",
      "  2\n",
      " 73\n",
      " 56\n",
      " 72\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 68\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 56\n",
      " 56\n",
      " 74\n",
      " 68\n",
      " 68\n",
      " 72\n",
      " 73\n",
      " 61\n",
      "  4\n",
      " 72\n",
      " 66\n",
      " 60\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 74\n",
      "  8\n",
      " 55\n",
      " 58\n",
      " 62\n",
      "  9\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 57\n",
      " 54\n",
      " 68\n",
      " 62\n",
      " 58\n",
      " 78\n",
      " 73\n",
      " 76\n",
      " 58\n",
      "  9\n",
      " 58\n",
      " 71\n",
      " 71\n",
      " 67\n",
      " 62\n",
      " 69\n",
      " 54\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 71\n",
      " 27\n",
      " 54\n",
      " 65\n",
      "  2\n",
      " 71\n",
      " 78\n",
      " 68\n",
      " 71\n",
      " 55\n",
      " 62\n",
      "  1\n",
      " 58\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 76\n",
      " 73\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 57\n",
      " 71\n",
      " 75\n",
      " 67\n",
      "  2\n",
      " 65\n",
      " 58\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 62\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 61\n",
      " 76\n",
      " 58\n",
      " 58\n",
      " 66\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 60\n",
      " 56\n",
      "  2\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 54\n",
      " 78\n",
      " 62\n",
      " 76\n",
      " 62\n",
      " 61\n",
      " 54\n",
      " 74\n",
      " 60\n",
      " 74\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 71\n",
      " 71\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 65\n",
      " 65\n",
      " 67\n",
      " 58\n",
      " 72\n",
      " 58\n",
      " 71\n",
      "  2\n",
      " 36\n",
      " 30\n",
      " 58\n",
      " 68\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 74\n",
      "  2\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 38\n",
      " 73\n",
      "  1\n",
      "  2\n",
      " 64\n",
      " 71\n",
      " 10\n",
      " 72\n",
      " 10\n",
      "  9\n",
      " 57\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 67\n",
      " 72\n",
      "  2\n",
      " 59\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b3572e787441d8b2e5d80317245596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81654  1.78501]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa67fbb4a2f42509dbe7753bc86d9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.69008  1.69936]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RNN with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497078d15ec348149442681039df2e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.86065  1.84255]                                 \n",
      "[ 1.       1.68014  1.67387]                                 \n",
      "[ 2.       1.58828  1.59169]                                 \n",
      "[ 3.       1.52989  1.54942]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2f7bedaa34de2a40296a07387c1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46841  1.50966]                                 \n",
      "[ 1.       1.46482  1.5039 ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those the same the same the same the same th'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take non-overlapping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then create the exact same thing, offset by 1, as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
       "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
       "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
       "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
       "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
       "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
       "       [ 2, 73, 61, 58, 71, 58,  2, 67]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
       "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
       "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
       "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
       "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
       "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
       "       [73, 61, 58, 71, 58,  2, 67, 68]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725ca331d28b482e9c7a4f83f741498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.59241  2.40251]                                \n",
      "[ 1.       2.28474  2.19859]                                \n",
      "[ 2.       2.13883  2.08836]                                \n",
      "[ 3.       2.04892  2.01564]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb9aa22524d4bfd8b001d2efd10dbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.99819  2.00106]                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e141251f24d4083a6e8b2fa15dea724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.39428  2.21111]                                \n",
      "[ 1.       2.10381  2.03275]                                \n",
      "[ 2.       1.99451  1.96393]                               \n",
      "[ 3.       1.93492  1.91763]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf833e8b7ec4a3aa29dd271911f76ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.84035  1.85742]                                \n",
      "[ 1.       1.82896  1.84887]                                \n",
      "[ 2.       1.81879  1.84281]                               \n",
      "[ 3.       1.81337  1.83801]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  nietzsche.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH='data/nietzsche/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 56, 1, 493747)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e0a39ef174c72bac575be7e20579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81983  1.81247]                                 \n",
      "[ 1.       1.63097  1.66228]                                 \n",
      "[ 2.       1.54433  1.57824]                                 \n",
      "[ 3.       1.48563  1.54505]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b15bf8bcc7445e694dbcb3beb658b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.4187   1.50374]                                 \n",
      "[ 1.       1.41492  1.49391]                                 \n",
      "[ 2.       1.41001  1.49339]                                 \n",
      "[ 3.       1.40756  1.486  ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46f24bfa194e1ba9d73e22283ca6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81013  1.7969 ]                                 \n",
      "[ 1.       1.62515  1.65346]                                 \n",
      "[ 2.       1.53913  1.58065]                                 \n",
      "[ 3.       1.48698  1.54217]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    gi = F.linear(input, w_ih, b_ih)\n",
    "    gh = F.linear(hidden, w_hh, b_hh)\n",
    "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "    resetgate = F.sigmoid(i_r + h_r)\n",
    "    inputgate = F.sigmoid(i_i + h_i)\n",
    "    newgate = F.tanh(i_n + resetgate * h_n)\n",
    "    return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518384d71c345a8b145b35d4ee894fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.68409  1.67784]                                 \n",
      "[ 1.       1.49813  1.52661]                                 \n",
      "[ 2.       1.41674  1.46769]                                 \n",
      "[ 3.       1.36359  1.43818]                                 \n",
      "[ 4.       1.33223  1.41777]                                 \n",
      "[ 5.       1.30217  1.40511]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be385370c27f4b788920caf48f90aeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.22708  1.36926]                                 \n",
      "[ 1.       1.21948  1.3696 ]                                 \n",
      "[ 2.       1.22541  1.36969]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6943ca600bbf4a49a0020b2467c2ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.72032  1.64016]                                 \n",
      "[ 1.       1.62891  1.58176]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765d0d78da6647d48276a638f70aeec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.47969  1.4472 ]                                 \n",
      "[ 1.       1.51411  1.46612]                                 \n",
      "[ 2.       1.412    1.39909]                                 \n",
      "[ 3.       1.53689  1.48337]                                 \n",
      "[ 4.       1.47375  1.43169]                                 \n",
      "[ 5.       1.39828  1.37963]                                 \n",
      "[ 6.       1.34546  1.35795]                                 \n",
      "[ 7.       1.51999  1.47165]                                 \n",
      "[ 8.       1.48992  1.46146]                                 \n",
      "[ 9.       1.45492  1.42829]                                 \n",
      "[ 10.        1.42027   1.39028]                              \n",
      "[ 11.        1.3814    1.36539]                              \n",
      "[ 12.        1.33895   1.34178]                              \n",
      "[ 13.        1.30737   1.32871]                              \n",
      "[ 14.        1.28244   1.31518]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4394818ec37f4b419397628b7cc8b815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46053  1.43462]                                 \n",
      "[ 1.       1.51537  1.47747]                                 \n",
      "[ 2.       1.39208  1.38293]                                 \n",
      "[ 3.       1.53056  1.49371]                                 \n",
      "[ 4.       1.46812  1.43389]                                 \n",
      "[ 5.       1.37624  1.37523]                                 \n",
      "[ 6.       1.3173   1.34022]                                 \n",
      "[ 7.       1.51783  1.47554]                                 \n",
      "[ 8.       1.4921   1.45785]                                 \n",
      "[ 9.       1.44843  1.42215]                                 \n",
      "[ 10.        1.40948   1.40858]                              \n",
      "[ 11.        1.37098   1.36648]                              \n",
      "[ 12.        1.32255   1.33842]                              \n",
      "[ 13.        1.28243   1.31106]                              \n",
      "[ 14.        1.25031   1.2918 ]                              \n",
      "[ 15.        1.49236   1.45316]                              \n",
      "[ 16.        1.46041   1.43622]                              \n",
      "[ 17.        1.45043   1.4498 ]                              \n",
      "[ 18.        1.43331   1.41297]                              \n",
      "[ 19.        1.43841   1.41704]                              \n",
      "[ 20.        1.41536   1.40521]                              \n",
      "[ 21.        1.39829   1.37656]                              \n",
      "[ 22.        1.37001   1.36891]                              \n",
      "[ 23.        1.35469   1.35909]                              \n",
      "[ 24.        1.32202   1.34228]                              \n",
      "[ 25.        1.29972   1.32256]                              \n",
      "[ 26.        1.28007   1.30903]                              \n",
      "[ 27.        1.24503   1.29125]                              \n",
      "[ 28.        1.22261   1.28316]                              \n",
      "[ 29.        1.20563   1.27397]                              \n",
      "[ 30.        1.18764   1.27178]                              \n",
      "[ 31.        1.18114   1.26694]                              \n",
      "[ 32.        1.44344   1.42405]                              \n",
      "[ 33.        1.43344   1.41616]                              \n",
      "[ 34.        1.4346    1.40442]                              \n",
      "[ 35.        1.42152   1.41359]                              \n",
      "[ 36.        1.42072   1.40835]                              \n",
      "[ 37.        1.41732   1.40498]                              \n",
      "[ 38.        1.41268   1.395  ]                              \n",
      "[ 39.        1.40725   1.39433]                              \n",
      "[ 40.        1.40181   1.39864]                              \n",
      "[ 41.        1.38621   1.37549]                              \n",
      "[ 42.        1.3838    1.38587]                              \n",
      "[ 43.        1.37644   1.37118]                              \n",
      "[ 44.        1.36287   1.36211]                              \n",
      "[ 45.        1.35942   1.36145]                              \n",
      "[ 46.        1.34712   1.34924]                              \n",
      "[ 47.        1.32994   1.34884]                              \n",
      "[ 48.        1.32788   1.33387]                              \n",
      "[ 49.        1.31553   1.342  ]                              \n",
      "[ 50.        1.30088   1.32435]                              \n",
      "[ 51.        1.28446   1.31166]                              \n",
      "[ 52.        1.27058   1.30807]                              \n",
      "[ 53.        1.26271   1.29935]                              \n",
      "[ 54.        1.24351   1.28942]                              \n",
      "[ 55.        1.23119   1.2838 ]                              \n",
      "[ 56.        1.2086    1.28364]                              \n",
      "[ 57.        1.19742   1.27375]                              \n",
      "[ 58.        1.18127   1.26758]                              \n",
      "[ 59.        1.17475   1.26858]                              \n",
      "[ 60.        1.15349   1.25999]                              \n",
      "[ 61.        1.14718   1.25779]                              \n",
      "[ 62.        1.13174   1.2524 ]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those the skemps), or\n",
      "imaginates, though they deceives. it should so each ourselvess and new\n",
      "present, step absolutely for the\n",
      "science.\" the contradity and\n",
      "measuring, \n",
      "the whole!\n",
      "\n",
      "293. perhaps, that every life a values of blood\n",
      "of\n",
      "intercourse when it senses there is unscrupulus, his very rights, and still impulse, love?\n",
      "just after that thereby how made with the way anything, and set for harmless philos\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
