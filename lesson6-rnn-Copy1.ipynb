{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:22.031502Z",
     "start_time": "2018-04-20T13:24:20.341743Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.text import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:22.184704Z",
     "start_time": "2018-04-20T13:24:22.031502Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH\n",
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:22.501489Z",
     "start_time": "2018-04-20T13:24:22.187655Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids = np.load(TMP_PATH/'sql_ids.npy')\n",
    "sql_itos = pickle.load(open(TMP_PATH/'sql_itos.pkl','rb'))\n",
    "sql_stoi =  collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(sql_itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:46:57.834035Z",
     "start_time": "2018-04-20T15:46:57.580504Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_random(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    p = to_np(p)[0]\n",
    "    pi = p.argsort()[-10:]\n",
    "    i = np.random.choice(pi, p=softmax_np(p[pi]))\n",
    "    return indices_char[i]\n",
    "\n",
    "def softmax_np (nparray):\n",
    "    ans = np.exp(nparray)\n",
    "    return ans/ans.sum()\n",
    "\n",
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    p = to_np(p)\n",
    "    \n",
    "    return indices_char[i]\n",
    "\n",
    "def get_sentence(inp):\n",
    "    sentence = inp\n",
    "    counter = 0\n",
    "    tmp = []\n",
    "    while \"_eos_\" not in tmp:   \n",
    "        tmp = get_next(sentence[-8:]) # always get last three\n",
    "        sentence += [tmp]\n",
    "        counter = counter+1\n",
    "        if counter> 500:\n",
    "            break\n",
    "    return sentence\n",
    "        \n",
    "\n",
    "def get_sentence_random(inp):\n",
    "    sentence = inp\n",
    "    counter = 0\n",
    "    tmp = []\n",
    "    while \"_eos_\" not in tmp:   \n",
    "        tmp = get_next_random(sentence[-8:]) # always get last three\n",
    "        sentence += [tmp]\n",
    "        counter = counter+1\n",
    "        if counter> 500:\n",
    "            break\n",
    "    return sentence\n",
    "        \n",
    "\n",
    "def show_sentence(inp):\n",
    "    sentence =''\n",
    "    captialize = False\n",
    "    for i in inp:\n",
    "        if i =='t_up':\n",
    "            captialize = True\n",
    "        else:            \n",
    "            if captialize:\n",
    "                sentence = sentence + \" \" + i.upper()       \n",
    "           \n",
    "            else:\n",
    "                sentence = sentence +\" \" + i\n",
    "            captialize = False\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:22.664928Z",
     "start_time": "2018-04-20T13:24:22.519540Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH\n",
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:46:30.127445Z",
     "start_time": "2018-04-20T09:46:29.215818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>sql_plain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>586912</td>\n",
       "      <td>SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...</td>\n",
       "      <td>SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...</td>\n",
       "      <td>Repent 151-160</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This is test data for my question to make thi...</td>\n",
       "      <td></td>\n",
       "      <td>54791</td>\n",
       "      <td>CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...</td>\n",
       "      <td>-- This is test data for my question to make t...</td>\n",
       "      <td>This is test data for my question to make thin...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>611565</td>\n",
       "      <td>select Id from Comments where lower(Text) like...</td>\n",
       "      <td>select Id\\nfrom Comments \\nwhere lower(Text) l...</td>\n",
       "      <td>Accept answer</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>612812</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>Questions with most views created within 3 mon...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Most Prolific Answerers (with score), Shows t...</td>\n",
       "      <td></td>\n",
       "      <td>325114</td>\n",
       "      <td>SELECT TOP 50 OwnerUserId as [User Link], COUN...</td>\n",
       "      <td>-- Most Prolific Answerers (with score)\\n-- Sh...</td>\n",
       "      <td>Most Prolific Answers</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments description      id  \\\n",
       "0                                                 []              586912   \n",
       "1  [This is test data for my question to make thi...               54791   \n",
       "2                                                 []              611565   \n",
       "3                                                 []              612812   \n",
       "4  [Most Prolific Answerers (with score), Shows t...              325114   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...   \n",
       "1  CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...   \n",
       "2  select Id from Comments where lower(Text) like...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  SELECT TOP 50 OwnerUserId as [User Link], COUN...   \n",
       "\n",
       "                                           sql_plain  \\\n",
       "0  SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...   \n",
       "1  -- This is test data for my question to make t...   \n",
       "2  select Id\\nfrom Comments \\nwhere lower(Text) l...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  -- Most Prolific Answerers (with score)\\n-- Sh...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Repent 151-160   \n",
       "1  This is test data for my question to make thin...   \n",
       "2                                      Accept answer   \n",
       "3  Questions with most views created within 3 mon...   \n",
       "4                              Most Prolific Answers   \n",
       "\n",
       "                                                 url  \n",
       "0  http://data.stackexchange.com/stackoverflow/re...  \n",
       "1  http://data.stackexchange.com/stackoverflow/re...  \n",
       "2  http://data.stackexchange.com/stackoverflow/re...  \n",
       "3  http://data.stackexchange.com/stackoverflow/re...  \n",
       "4  http://data.stackexchange.com/stackoverflow/re...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(DATA_PATH/'train.json')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:46:30.281529Z",
     "start_time": "2018-04-20T09:46:30.129451Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL = dataset.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:46:30.449476Z",
     "start_time": "2018-04-20T09:46:30.284535Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform the text to be tokenize readily, as certain token has special meaning in SQL, ie. \".\" means the schema relation\n",
    "token_replaced = {',' : ' , ',\n",
    "                 '#' : ' # ',\n",
    "                 '@' : ' @ ',\n",
    "                 '!' : ' ! ',\n",
    "                 '.' : ' . ',\n",
    "                 '%' : ' % ',\n",
    "                 '?' : ' ? ',\n",
    "                 ')' : ' ) ',\n",
    "                 '(' : ' ( ',\n",
    "                 '=' : ' = ',\n",
    "                 '/' : ' / ',\n",
    "                 '*' : ' * '}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:59.624879Z",
     "start_time": "2018-04-20T09:48:59.459900Z"
    }
   },
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    for bereplaced, replace in token_replaced.items():        \n",
    "        x = x.replace(bereplaced, replace).lower() # CASE insentive for SQL\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:49:00.891078Z",
     "start_time": "2018-04-20T09:49:00.487372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select p . title , p . score , p . viewcount , p . answercount , p . commentcount , len ( p . body )  as ques_size ,  p . favoritecount , p . id ,  u . reputation as user_repo , u . creationdate as user_join_date ,  datediff ( minute ,  p . creationdate ,  a . creationdate )  as qatimegap from posts as p ,  posts as a ,  users as u where p . id = a . parentid and p . owneruserid = u . id and a . creationdate  =   ( select min ( tau . creationdate )  from posts tau where tau . parentid = p . id group by tau . parentid )  and  (  p . title like \\' % recommended method for handling unsupportedencodingexception from string . getbytes ( \"utf-8\" )  % \\' or p . title like \\' % way to format strings with \" ? \" parameters to full string in java ?  % \\' or p . title like \\' % how to parse a string without regular expressions % \\' or p . title like \\' % how to replace string only once without regex in java ?  % \\' or p . title like \\' % efficiently removing specific characters  ( some punctuation )  from strings in java ?  % \\' or p . title like \\' % strings are immutable - that means i should never use + =  and only stringbuffer ?  % \\' or p . title like \\' % concatenation of strings and characters % \\' or p . title like \\' % java - convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % better template language needed % \\'  ) '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL = SQL.apply(fixup)## Sanity Check\n",
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:57:19.254858Z",
     "start_time": "2018-04-20T09:57:19.100398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select p . title , p . score , p . viewcount , p . answercount , p . commentcount , len ( p . body )  as ques_size ,  p . favoritecount , p . id ,  u . reputation as user_repo , u . creationdate as user_join_date ,  datediff ( minute ,  p . creationdate ,  a . creationdate )  as qatimegap from posts as p ,  posts as a ,  users as u where p . id = a . parentid and p . owneruserid = u . id and a . creationdate  =   ( select min ( tau . creationdate )  from posts tau where tau . parentid = p . id group by tau . parentid )  and  (  p . title like \\' % recommended method for handling unsupportedencodingexception from string . getbytes ( \"utf-8\" )  % \\' or p . title like \\' % way to format strings with \" ? \" parameters to full string in java ?  % \\' or p . title like \\' % how to parse a string without regular expressions % \\' or p . title like \\' % how to replace string only once without regex in java ?  % \\' or p . title like \\' % efficiently removing specific characters  ( some punctuation )  from strings in java ?  % \\' or p . title like \\' % strings are immutable - that means i should never use + =  and only stringbuffer ?  % \\' or p . title like \\' % concatenation of strings and characters % \\' or p . title like \\' % java - convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % better template language needed % \\'  ) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:07:49.654515Z",
     "start_time": "2018-04-20T10:07:49.336330Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SQL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6da356755e44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msql_tok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproc_all_mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition_by_cores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSQL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SQL' is not defined"
     ]
    }
   ],
   "source": [
    "sql_tok = Tokenizer.proc_all_mp(partition_by_cores(SQL)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:57:58.239916Z",
     "start_time": "2018-04-20T09:57:58.075470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:57:58.407173Z",
     "start_time": "2018-04-20T09:57:58.241920Z"
    }
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common()]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([0] + [stoi[o] for o in p] + [2]) for p in tok]) # pad bos at beginning and eos at the end\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:57:59.312786Z",
     "start_time": "2018-04-20T09:57:58.409179Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids,sql_itos,sql_stoi = toks2ids(sql_tok,'sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:28.915235Z",
     "start_time": "2018-04-20T13:24:28.706566Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids_concat= []\n",
    "for i in sql_ids:\n",
    "    sql_ids_concat += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:29.450650Z",
     "start_time": "2018-04-20T13:24:29.315674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24594,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:29.716287Z",
     "start_time": "2018-04-20T13:24:29.568876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 23125\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(sql_itos)\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:30.662420Z",
     "start_time": "2018-04-20T13:24:30.519043Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = sql_ids_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:30.822847Z",
     "start_time": "2018-04-20T13:24:30.664425Z"
    }
   },
   "outputs": [],
   "source": [
    "char_indices = sql_stoi\n",
    "indices_char = sql_itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a size for our hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:30.963219Z",
     "start_time": "2018-04-20T13:24:30.824852Z"
    }
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Char3Model to fastai learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:31.104716Z",
     "start_time": "2018-04-20T13:24:30.964223Z"
    }
   },
   "outputs": [],
   "source": [
    "cs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:34.623098Z",
     "start_time": "2018-04-20T13:24:31.106721Z"
    }
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(len(sql_ids_concat)-cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:35.023450Z",
     "start_time": "2018-04-20T13:24:34.623098Z"
    }
   },
   "outputs": [],
   "source": [
    "c_out_dat = [sql_ids_concat[j+cs] for j in range(len(sql_ids_concat)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:40.968436Z",
     "start_time": "2018-04-20T13:24:35.025754Z"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:41.113823Z",
     "start_time": "2018-04-20T13:24:40.973451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  13,  18,   4, 102],\n",
       "       [ 13,  18,   4, 102,   5],\n",
       "       [ 18,   4, 102,   5,  18],\n",
       "       ...,\n",
       "       [ 27,  20,   8, 252,  30],\n",
       "       [ 20,   8, 252,  30,   8],\n",
       "       [  8, 252,  30,   8, 124]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:41.252838Z",
     "start_time": "2018-04-20T13:24:41.115831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146779, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.062747Z",
     "start_time": "2018-04-20T13:24:41.255847Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.202960Z",
     "start_time": "2018-04-20T13:24:45.064591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  18,   4, ...,   8, 124,   2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.346451Z",
     "start_time": "2018-04-20T13:24:45.204967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  13,  18,   4, 102],\n",
       "       [ 13,  18,   4, 102,   5],\n",
       "       [ 18,   4, 102,   5,  18],\n",
       "       [  4, 102,   5,  18,   4],\n",
       "       [102,   5,  18,   4,  33]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.475797Z",
     "start_time": "2018-04-20T13:24:45.348458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 18,  4, 33,  5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.684353Z",
     "start_time": "2018-04-20T13:24:45.477803Z"
    }
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(sql_ids_concat)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:45.908003Z",
     "start_time": "2018-04-20T13:24:45.686357Z"
    }
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:46.060825Z",
     "start_time": "2018-04-20T13:24:45.912960Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)          \n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:49.538867Z",
     "start_time": "2018-04-20T13:24:46.062822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce 930M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "model = RNN_Learner(md, SingleModel(to_gpu(m)), opt_fn=opt_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:34:38.195318Z",
     "start_time": "2018-04-20T10:34:38.029868Z"
    }
   },
   "outputs": [],
   "source": [
    "# it = iter(md.trn_dl)\n",
    "# *xs,yt = next(it)\n",
    "# t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:48:25.791860Z",
     "start_time": "2018-04-20T10:34:38.197327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466b4a2ed7f3463492cb63c82413879f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.165478   3.135849  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1358491721754476]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(1e-3,1, cycle_len=1,use_clr_beta = (10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T11:13:53.299129Z",
     "start_time": "2018-04-20T11:13:53.077797Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('tmp1')\n",
    "model.load('tmp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T11:22:42.677344Z",
     "start_time": "2018-04-20T11:13:53.302136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b508ce907be4f158e7398de2edd7f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 541/839 [08:49<04:51,  1.02it/s, loss=11.2]"
     ]
    }
   ],
   "source": [
    "model.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T11:22:43.410251Z",
     "start_time": "2018-04-20T11:22:42.679350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T11:33:19.511985Z",
     "start_time": "2018-04-20T11:22:43.412218Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf9cacd59c4c57a19a49f5fd0635e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/839 [00:05<09:44,  1.42it/s, loss=3.1]   \n",
      "  1%|          | 10/839 [00:07<09:40,  1.43it/s, loss=3.12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\tqdm\\_monitor.py\", line 63, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.91034    2.919186  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.919185948091741]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(1e-4,1, cycle_len=1,use_clr_beta = (10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T11:33:19.707277Z",
     "start_time": "2018-04-20T11:33:19.513991Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('tmp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:24:49.719411Z",
     "start_time": "2018-04-20T13:24:49.538867Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load('tmp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T13:34:48.376177Z",
     "start_time": "2018-04-20T13:24:49.721418Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bee3d8b3894740a8a4883b0194714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.242579   2.22189   \n",
      "  0%|          | 0/839 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at c:\\pytorch\\torch\\lib\\thc\\generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fc46bb7c6128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_clr_beta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\NokChan\\Documents\\SQL_Generator\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NokChan\\Documents\\SQL_Generator\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[1;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, all_val, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[1;32m--> 199\u001b[1;33m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, all_val=all_val, **kwargs)\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NokChan\\Documents\\SQL_Generator\\fastai\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, all_val, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NokChan\\Documents\\SQL_Generator\\fastai\\model.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, xs, y, epoch)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Gradient clipping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainable_params_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at c:\\pytorch\\torch\\lib\\thc\\generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "model.fit(1e-3,1, cycle_len=2,use_clr_beta = (10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:45:03.450411Z",
     "start_time": "2018-04-20T15:45:03.305559Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:45:11.929970Z",
     "start_time": "2018-04-20T15:45:08.738981Z"
    }
   },
   "outputs": [],
   "source": [
    "a=get_sentence(['select','*','from','where','users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:45:12.913685Z",
     "start_time": "2018-04-20T15:45:11.929970Z"
    }
   },
   "outputs": [],
   "source": [
    "b=get_sentence_random(['select','*','from','where','users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:45:17.786135Z",
     "start_time": "2018-04-20T15:45:17.636571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' select * from where users . i d = posts . i d = posttags . postid = tags . postid inner join posttags pt on pt . tagid = postid and v . postid = a . parentid where u . displayname > 0 group by tagname order by upvotes , count ( * ) over ( order by count ( * ) from posts a where a . parentid = posts . i d , posts . i d ) , p . displayname , p . body as [ post link ] , reputation from posthistory _eos_'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_sentence(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:45:20.827054Z",
     "start_time": "2018-04-20T15:45:20.697116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' select * from where users . i d = # # userid # # and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1 and p . posttypeid = 1'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:42:09.931426Z",
     "start_time": "2018-04-20T09:42:09.779487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" SELECT * FROM where customer LIKE ' % < % ' or LOWER ( location ) LIKE ' % india % ' ORDER by reputation DESC ; _eos_\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:34:29.066580Z",
     "start_time": "2018-04-20T09:34:05.542Z"
    }
   },
   "outputs": [],
   "source": [
    "get_next(['select', '*', 'from'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RNN with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497078d15ec348149442681039df2e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.86065  1.84255]                                 \n",
      "[ 1.       1.68014  1.67387]                                 \n",
      "[ 2.       1.58828  1.59169]                                 \n",
      "[ 3.       1.52989  1.54942]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2f7bedaa34de2a40296a07387c1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46841  1.50966]                                 \n",
      "[ 1.       1.46482  1.5039 ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those the same the same the same the same th'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take non-overlapping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then create the exact same thing, offset by 1, as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
       "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
       "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
       "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
       "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
       "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
       "       [ 2, 73, 61, 58, 71, 58,  2, 67]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
       "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
       "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
       "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
       "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
       "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
       "       [73, 61, 58, 71, 58,  2, 67, 68]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725ca331d28b482e9c7a4f83f741498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.59241  2.40251]                                \n",
      "[ 1.       2.28474  2.19859]                                \n",
      "[ 2.       2.13883  2.08836]                                \n",
      "[ 3.       2.04892  2.01564]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb9aa22524d4bfd8b001d2efd10dbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.99819  2.00106]                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e141251f24d4083a6e8b2fa15dea724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.39428  2.21111]                                \n",
      "[ 1.       2.10381  2.03275]                                \n",
      "[ 2.       1.99451  1.96393]                               \n",
      "[ 3.       1.93492  1.91763]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf833e8b7ec4a3aa29dd271911f76ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.84035  1.85742]                                \n",
      "[ 1.       1.82896  1.84887]                                \n",
      "[ 2.       1.81879  1.84281]                               \n",
      "[ 3.       1.81337  1.83801]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  nietzsche.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH='data/nietzsche/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 56, 1, 493747)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e0a39ef174c72bac575be7e20579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81983  1.81247]                                 \n",
      "[ 1.       1.63097  1.66228]                                 \n",
      "[ 2.       1.54433  1.57824]                                 \n",
      "[ 3.       1.48563  1.54505]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b15bf8bcc7445e694dbcb3beb658b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.4187   1.50374]                                 \n",
      "[ 1.       1.41492  1.49391]                                 \n",
      "[ 2.       1.41001  1.49339]                                 \n",
      "[ 3.       1.40756  1.486  ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46f24bfa194e1ba9d73e22283ca6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81013  1.7969 ]                                 \n",
      "[ 1.       1.62515  1.65346]                                 \n",
      "[ 2.       1.53913  1.58065]                                 \n",
      "[ 3.       1.48698  1.54217]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    gi = F.linear(input, w_ih, b_ih)\n",
    "    gh = F.linear(hidden, w_hh, b_hh)\n",
    "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "    resetgate = F.sigmoid(i_r + h_r)\n",
    "    inputgate = F.sigmoid(i_i + h_i)\n",
    "    newgate = F.tanh(i_n + resetgate * h_n)\n",
    "    return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518384d71c345a8b145b35d4ee894fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.68409  1.67784]                                 \n",
      "[ 1.       1.49813  1.52661]                                 \n",
      "[ 2.       1.41674  1.46769]                                 \n",
      "[ 3.       1.36359  1.43818]                                 \n",
      "[ 4.       1.33223  1.41777]                                 \n",
      "[ 5.       1.30217  1.40511]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be385370c27f4b788920caf48f90aeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.22708  1.36926]                                 \n",
      "[ 1.       1.21948  1.3696 ]                                 \n",
      "[ 2.       1.22541  1.36969]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6943ca600bbf4a49a0020b2467c2ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.72032  1.64016]                                 \n",
      "[ 1.       1.62891  1.58176]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765d0d78da6647d48276a638f70aeec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.47969  1.4472 ]                                 \n",
      "[ 1.       1.51411  1.46612]                                 \n",
      "[ 2.       1.412    1.39909]                                 \n",
      "[ 3.       1.53689  1.48337]                                 \n",
      "[ 4.       1.47375  1.43169]                                 \n",
      "[ 5.       1.39828  1.37963]                                 \n",
      "[ 6.       1.34546  1.35795]                                 \n",
      "[ 7.       1.51999  1.47165]                                 \n",
      "[ 8.       1.48992  1.46146]                                 \n",
      "[ 9.       1.45492  1.42829]                                 \n",
      "[ 10.        1.42027   1.39028]                              \n",
      "[ 11.        1.3814    1.36539]                              \n",
      "[ 12.        1.33895   1.34178]                              \n",
      "[ 13.        1.30737   1.32871]                              \n",
      "[ 14.        1.28244   1.31518]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4394818ec37f4b419397628b7cc8b815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46053  1.43462]                                 \n",
      "[ 1.       1.51537  1.47747]                                 \n",
      "[ 2.       1.39208  1.38293]                                 \n",
      "[ 3.       1.53056  1.49371]                                 \n",
      "[ 4.       1.46812  1.43389]                                 \n",
      "[ 5.       1.37624  1.37523]                                 \n",
      "[ 6.       1.3173   1.34022]                                 \n",
      "[ 7.       1.51783  1.47554]                                 \n",
      "[ 8.       1.4921   1.45785]                                 \n",
      "[ 9.       1.44843  1.42215]                                 \n",
      "[ 10.        1.40948   1.40858]                              \n",
      "[ 11.        1.37098   1.36648]                              \n",
      "[ 12.        1.32255   1.33842]                              \n",
      "[ 13.        1.28243   1.31106]                              \n",
      "[ 14.        1.25031   1.2918 ]                              \n",
      "[ 15.        1.49236   1.45316]                              \n",
      "[ 16.        1.46041   1.43622]                              \n",
      "[ 17.        1.45043   1.4498 ]                              \n",
      "[ 18.        1.43331   1.41297]                              \n",
      "[ 19.        1.43841   1.41704]                              \n",
      "[ 20.        1.41536   1.40521]                              \n",
      "[ 21.        1.39829   1.37656]                              \n",
      "[ 22.        1.37001   1.36891]                              \n",
      "[ 23.        1.35469   1.35909]                              \n",
      "[ 24.        1.32202   1.34228]                              \n",
      "[ 25.        1.29972   1.32256]                              \n",
      "[ 26.        1.28007   1.30903]                              \n",
      "[ 27.        1.24503   1.29125]                              \n",
      "[ 28.        1.22261   1.28316]                              \n",
      "[ 29.        1.20563   1.27397]                              \n",
      "[ 30.        1.18764   1.27178]                              \n",
      "[ 31.        1.18114   1.26694]                              \n",
      "[ 32.        1.44344   1.42405]                              \n",
      "[ 33.        1.43344   1.41616]                              \n",
      "[ 34.        1.4346    1.40442]                              \n",
      "[ 35.        1.42152   1.41359]                              \n",
      "[ 36.        1.42072   1.40835]                              \n",
      "[ 37.        1.41732   1.40498]                              \n",
      "[ 38.        1.41268   1.395  ]                              \n",
      "[ 39.        1.40725   1.39433]                              \n",
      "[ 40.        1.40181   1.39864]                              \n",
      "[ 41.        1.38621   1.37549]                              \n",
      "[ 42.        1.3838    1.38587]                              \n",
      "[ 43.        1.37644   1.37118]                              \n",
      "[ 44.        1.36287   1.36211]                              \n",
      "[ 45.        1.35942   1.36145]                              \n",
      "[ 46.        1.34712   1.34924]                              \n",
      "[ 47.        1.32994   1.34884]                              \n",
      "[ 48.        1.32788   1.33387]                              \n",
      "[ 49.        1.31553   1.342  ]                              \n",
      "[ 50.        1.30088   1.32435]                              \n",
      "[ 51.        1.28446   1.31166]                              \n",
      "[ 52.        1.27058   1.30807]                              \n",
      "[ 53.        1.26271   1.29935]                              \n",
      "[ 54.        1.24351   1.28942]                              \n",
      "[ 55.        1.23119   1.2838 ]                              \n",
      "[ 56.        1.2086    1.28364]                              \n",
      "[ 57.        1.19742   1.27375]                              \n",
      "[ 58.        1.18127   1.26758]                              \n",
      "[ 59.        1.17475   1.26858]                              \n",
      "[ 60.        1.15349   1.25999]                              \n",
      "[ 61.        1.14718   1.25779]                              \n",
      "[ 62.        1.13174   1.2524 ]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those the skemps), or\n",
      "imaginates, though they deceives. it should so each ourselvess and new\n",
      "present, step absolutely for the\n",
      "science.\" the contradity and\n",
      "measuring, \n",
      "the whole!\n",
      "\n",
      "293. perhaps, that every life a values of blood\n",
      "of\n",
      "intercourse when it senses there is unscrupulus, his very rights, and still impulse, love?\n",
      "just after that thereby how made with the way anything, and set for harmless philos\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
