{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T08:46:32.277663Z",
     "start_time": "2018-04-16T08:46:24.501615Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T08:46:40.289454Z",
     "start_time": "2018-04-16T08:46:40.285444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:56:07.749904Z",
     "start_time": "2018-04-16T09:56:07.745890Z"
    }
   },
   "outputs": [],
   "source": [
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T08:46:41.847285Z",
     "start_time": "2018-04-16T08:46:41.199808Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>sql_plain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>586912</td>\n",
       "      <td>SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...</td>\n",
       "      <td>SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...</td>\n",
       "      <td>Repent 151-160</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This is test data for my question to make thi...</td>\n",
       "      <td></td>\n",
       "      <td>54791</td>\n",
       "      <td>CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...</td>\n",
       "      <td>-- This is test data for my question to make t...</td>\n",
       "      <td>This is test data for my question to make thin...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>611565</td>\n",
       "      <td>select Id from Comments where lower(Text) like...</td>\n",
       "      <td>select Id\\nfrom Comments \\nwhere lower(Text) l...</td>\n",
       "      <td>Accept answer</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>612812</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>DECLARE @From DATETIME = convert(DATETIME, '##...</td>\n",
       "      <td>Questions with most views created within 3 mon...</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Most Prolific Answerers (with score), Shows t...</td>\n",
       "      <td></td>\n",
       "      <td>325114</td>\n",
       "      <td>SELECT TOP 50 OwnerUserId as [User Link], COUN...</td>\n",
       "      <td>-- Most Prolific Answerers (with score)\\n-- Sh...</td>\n",
       "      <td>Most Prolific Answers</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments description      id  \\\n",
       "0                                                 []              586912   \n",
       "1  [This is test data for my question to make thi...               54791   \n",
       "2                                                 []              611565   \n",
       "3                                                 []              612812   \n",
       "4  [Most Prolific Answerers (with score), Shows t...              325114   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...   \n",
       "1  CREATE TABLE #CustomerDB ( ID int NOT NULL, NA...   \n",
       "2  select Id from Comments where lower(Text) like...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  SELECT TOP 50 OwnerUserId as [User Link], COUN...   \n",
       "\n",
       "                                           sql_plain  \\\n",
       "0  SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...   \n",
       "1  -- This is test data for my question to make t...   \n",
       "2  select Id\\nfrom Comments \\nwhere lower(Text) l...   \n",
       "3  DECLARE @From DATETIME = convert(DATETIME, '##...   \n",
       "4  -- Most Prolific Answerers (with score)\\n-- Sh...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Repent 151-160   \n",
       "1  This is test data for my question to make thin...   \n",
       "2                                      Accept answer   \n",
       "3  Questions with most views created within 3 mon...   \n",
       "4                              Most Prolific Answers   \n",
       "\n",
       "                                                 url  \n",
       "0  http://data.stackexchange.com/stackoverflow/re...  \n",
       "1  http://data.stackexchange.com/stackoverflow/re...  \n",
       "2  http://data.stackexchange.com/stackoverflow/re...  \n",
       "3  http://data.stackexchange.com/stackoverflow/re...  \n",
       "4  http://data.stackexchange.com/stackoverflow/re...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(DATA_PATH/'train.json')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:21:07.324252Z",
     "start_time": "2018-04-16T09:21:07.321243Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL = dataset['sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:21:11.558927Z",
     "start_time": "2018-04-16T09:21:11.554915Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform the text to be tokenize readily\n",
    "token_replaced = {',' : ' , ',\n",
    "                 '#' : ' # ',\n",
    "                 '@' : ' @ ',\n",
    "                 '!' : ' ! ',\n",
    "                 '.' : ' . ',\n",
    "                 '%' : ' % ',\n",
    "                 '?' : ' ? '}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:21:11.917173Z",
     "start_time": "2018-04-16T09:21:11.913199Z"
    }
   },
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    for bereplaced, replace in token_replaced.items():        \n",
    "        x = x.replace(bereplaced, replace)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:21:12.278869Z",
     "start_time": "2018-04-16T09:21:12.272851Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform the text to be tokenize readily, as certain token has special meaning in SQL, ie. \".\" means the schema relation\n",
    "token_replaced = {',' : ' , ',\n",
    "                 '#' : ' # ',\n",
    "                 '@' : ' @ ',\n",
    "                 '!' : ' ! ',\n",
    "                 '.' : ' . ',\n",
    "                 '%' : ' % ',\n",
    "                 '?' : ' ? ',\n",
    "                 ')' : ' ) ',\n",
    "                 '(' : ' ( ',\n",
    "                 '=' : ' = ',\n",
    "                 '/' : ' / ',\n",
    "                 '*' : ' * '}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:21:12.916046Z",
     "start_time": "2018-04-16T09:21:12.745125Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL = SQL.apply(fixup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:23:18.652690Z",
     "start_time": "2018-04-16T09:23:18.649680Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sanity Check\n",
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:23:30.898552Z",
     "start_time": "2018-04-16T09:23:30.894540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE  # CustomerDB  (  ID int NOT NULL ,  NAME nvarchar ( 50 )  NULL ,  COMPANY nvarchar ( 50 )  NULL ,  ADDR1 nvarchar ( 50 )  NULL ,   )  INSERT INTO  # CustomerDB ( ID ,  NAME ,  COMPANY ,  ADDR1 )  VALUES  ( 16242 , 'TOM E' , 'Company A' , '101 First RD' )  ,   ( 16241 , 'RONALD J' , 'Company B' , '12 Tenth AVE' )  ,   ( 16235 , 'KENNETH H' , '' , '12 Tenth AVE' )  ,   ( 16238 , 'MICHAEL H' , 'Company C' , '12 Tenth AVE' )  ,   ( 16243 , 'ANTONIO D' , 'Company D' , '264 Long ST STE 5' )  ,   ( 16237 , 'MICHAEL B' , 'Company E' , '264 Long ST STE 5' )  ,   ( 16234 , 'WALTER L' , 'Company F' , '73 North RD' )  ,   ( 16236 , 'CARL O' , 'Company G' , '73 North RD' )  ,   ( 16239 , 'MICHAEL S' , 'Company H' , '73 North RD' )  ,   ( 16240 , 'MICHAEL I' , 'Company I' , '73 North RD' )  SELECT c1 . id ,  c1 . name ,  c1 . company ,  c1 . addr1 FROM  # CustomerDB c1 LEFT OUTER JOIN  # CustomerDB c2 ON  ( c1 . addr1 =  c2 . addr1 )  GROUP BY c1 . addr1 ,  c1 . id ,  c1 . name ,  c1 . company HAVING COUNT ( * )  < =  3\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:23:29.594501Z",
     "start_time": "2018-04-16T09:23:29.590526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select a . month ,  total ,  unanswered ,  cast ( cast ( unanswered*1 . 0/total*100 as decimal ( 5 , 1 )  )  as varchar ( 5 )  )  + ' % ' as PercentUnanswered from  ( select Convert ( varchar ( 6 )  ,  creationdate ,  112 )  as month ,  count ( * )  as total from posts where posttypeid  =  1 group by Convert ( varchar ( 6 )  ,  creationdate ,  112 )  )  a ,   ( select Convert ( varchar ( 6 )  ,  creationdate ,  112 )  as month ,  count ( * )  as unanswered from posts where postTypeID  =  1 and id not in  (  select distinct ParentId from posts where PostTypeId  =  2 )  group by Convert ( varchar ( 6 )  ,  creationdate ,  112 )  )  b where a . month  =  b . month order by a . month\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:29:25.699548Z",
     "start_time": "2018-04-16T09:28:41.143004Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tok = Tokenizer.proc_all_mp(partition_by_cores(SQL)) \n",
    "# sql_tok = Tokenizer.proc_all_mp(partition_by_cores(SQL.iloc[:10])) # For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:25:42.935413Z",
     "start_time": "2018-04-16T09:25:42.922594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 't_up',\n",
       " 'select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 't_up',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 't_up',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 't_up',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:29:25.719602Z",
     "start_time": "2018-04-16T09:29:25.701554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in sql_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:30:00.419389Z",
     "start_time": "2018-04-16T09:30:00.411369Z"
    }
   },
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in sql_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:30:01.243459Z",
     "start_time": "2018-04-16T09:30:01.145183Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tok = np.array(sql_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:30:25.602058Z",
     "start_time": "2018-04-16T09:30:25.578995Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle.dump(sql_tok, (DATA_PATH/'SQL_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:30:45.546189Z",
     "start_time": "2018-04-16T09:30:45.527136Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tok = pickle.load((DATA_PATH/'sql_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:30:53.989155Z",
     "start_time": "2018-04-16T09:30:53.984141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5081,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:56:25.229692Z",
     "start_time": "2018-04-16T09:56:25.214651Z"
    }
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:56:32.523549Z",
     "start_time": "2018-04-16T09:56:32.469873Z"
    }
   },
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(sql_tok,'sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:27.637500Z",
     "start_time": "2018-04-16T09:59:27.631440Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T09:59:28.196607Z",
     "start_time": "2018-04-16T09:59:28.182570Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids,sql_itos,sql_stoi = load_ids('sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:00:01.684716Z",
     "start_time": "2018-04-16T10:00:01.679200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['select',\n",
       "  'i',\n",
       "  'd',\n",
       "  'from',\n",
       "  'comments',\n",
       "  'where',\n",
       "  'lower',\n",
       "  '(',\n",
       "  'text',\n",
       "  ')',\n",
       "  'like',\n",
       "  \"'\",\n",
       "  '%',\n",
       "  'accept',\n",
       "  '%',\n",
       "  'answer',\n",
       "  '%',\n",
       "  \"'\",\n",
       "  'order',\n",
       "  'by',\n",
       "  'len',\n",
       "  '(',\n",
       "  'text',\n",
       "  ')',\n",
       "  'asc',\n",
       "  '_eos_'],\n",
       " 2342)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sql_itos[o] for o in sql_ids[0]], len(sql_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:16:19.198658Z",
     "start_time": "2018-04-16T10:16:19.193646Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:16:19.494729Z",
     "start_time": "2018-04-16T10:16:19.416995Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:16:19.721673Z",
     "start_time": "2018-04-16T10:16:19.712644Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:16:20.109459Z",
     "start_time": "2018-04-16T10:16:20.106451Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T10:16:20.728722Z",
     "start_time": "2018-04-16T10:16:20.712638Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fr_vecd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-8e013d495201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeq2SeqRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr_vecd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr_itos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_fr_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0men_vecd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0men_itos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_en_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menlen_90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN_Learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq2seq_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fr_vecd' is not defined"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  State Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text base on Inference and state machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
