{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:06.618307Z",
     "start_time": "2018-04-23T09:33:06.237272Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.text import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:06.965516Z",
     "start_time": "2018-04-23T09:33:06.620318Z"
    }
   },
   "outputs": [],
   "source": [
    "# from fsm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:07.310567Z",
     "start_time": "2018-04-23T09:33:06.967522Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH\n",
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:07.814526Z",
     "start_time": "2018-04-23T09:33:07.312072Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids = np.load(TMP_PATH/'sql_ids.npy')\n",
    "sql_itos = pickle.load(open(TMP_PATH/'sql_itos.pkl','rb'))\n",
    "sql_stoi =  collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(sql_itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:39:13.062325Z",
     "start_time": "2018-04-23T09:39:12.758442Z"
    }
   },
   "outputs": [],
   "source": [
    "# fsm = Rule_Parse_FSM()\n",
    "# get_next_random(\"select userid from users where \".split())\n",
    "# get_next_random_fsm(\"select userid from users where \".split(), fsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:39:13.586123Z",
     "start_time": "2018-04-23T09:39:13.230367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>sql</th>\n",
       "      <th>sql_plain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>586912</td>\n",
       "      <td>SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...</td>\n",
       "      <td>SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...</td>\n",
       "      <td>Repent 151-160</td>\n",
       "      <td>http://data.stackexchange.com/stackoverflow/re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comments description      id  \\\n",
       "0       []              586912   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  SELECT p.Title,p.score,p.ViewCount,p.AnswerCou...   \n",
       "\n",
       "                                           sql_plain           title  \\\n",
       "0  SELECT \\np.Title,p.score,p.ViewCount,p.AnswerC...  Repent 151-160   \n",
       "\n",
       "                                                 url  \n",
       "0  http://data.stackexchange.com/stackoverflow/re...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(DATA_PATH/'train.json')\n",
    "dataset.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:39:13.936630Z",
     "start_time": "2018-04-23T09:39:13.587125Z"
    }
   },
   "outputs": [],
   "source": [
    "# get_next_random(\"select userid from users where \".split())\n",
    "\n",
    "SQL = dataset.sql\n",
    "SQL = SQL.str.lower() # Pad space around non character string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = SQL.str.replace('(\\W)', r' \\1 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    select   p . title , p . score , p . viewcount...\n",
       "1    create   table    # customerdb    (    id   in...\n",
       "Name: sql, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Weird Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp =[\"id userid normal ac hed wed theyd  itd ID WED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'd',\n",
       "  'userid',\n",
       "  'normal',\n",
       "  'ac',\n",
       "  'he',\n",
       "  'd',\n",
       "  'we',\n",
       "  'd',\n",
       "  'they',\n",
       "  'd',\n",
       "  'it',\n",
       "  'd',\n",
       "  'i',\n",
       "  'd',\n",
       "  't_up',\n",
       "  'we',\n",
       "  'd']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer.proc_all(tmp,lang='en') ## Seems confirm Jeremy's Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_split(x):\n",
    "    return x.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_all_mp(ss):\n",
    "        ncpus = num_cpus()//2\n",
    "        with ProcessPoolExecutor(ncpus) as e:\n",
    "            return list(e.map(lambda_split, ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.25 s, sys: 2.57 s, total: 9.82 s\n",
      "Wall time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "%time tmp = proc_all_mp(SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 173 ms, sys: 36.1 ms, total: 209 ms\n",
      "Wall time: 208 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time [i.split() for i in SQL]\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 40.3 ms, total: 174 ms\n",
      "Wall time: 173 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time SQL.apply(lambda x : x.split())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 18.8 ms, total: 178 ms\n",
      "Wall time: 178 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time SQL.str.split()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:39:14.666474Z",
     "start_time": "2018-04-23T09:39:14.281573Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select p . title , p . score , p . viewcount , p . answercount , p . commentcount , len ( p . body ) as ques_size , p . favoritecount , p . id , u . reputation as user_repo , u . creationdate as user_join_date , datediff ( minute , p . creationdate , a . creationdate ) as qatimegap from posts as p , posts as a , users as u where p . id = a . parentid and p . owneruserid = u . id and a . creationdate = ( select min ( tau . creationdate ) from posts tau where tau . parentid = p . id group by tau . parentid ) and ( p . title like \\' % recommended method for handling unsupportedencodingexception from string . getbytes ( \" utf - 8 \" ) % \\' or p . title like \\' % way to format strings with \" ? \" parameters to full string in java ? % \\' or p . title like \\' % how to parse a string without regular expressions % \\' or p . title like \\' % how to replace string only once without regex in java ? % \\' or p . title like \\' % efficiently removing specific characters ( some punctuation ) from strings in java ? % \\' or p . title like \\' % strings are immutable - that means i should never use + = and only stringbuffer ? % \\' or p . title like \\' % concatenation of strings and characters % \\' or p . title like \\' % java - convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % better template language needed % \\' )'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok = SQL.str.split()\n",
    "\" \".join(sql_tok[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up SQL that are too long/short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens=[len(i) for i in sql_tok]\n",
    "lens= np.array(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([316, 308,  24, 178,  44,  52,  84,  99, 190,  38])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83.80332601447508, 1, 863, 79.63395093587785)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.mean(),lens.min(),lens.max(),lens.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.66122, 0.8905 , 0.95857, 0.98248, 0.99435, 0.99829, 0.99955, 0.9998 , 0.99992, 1.     ]),\n",
       " array([  1. ,  87.2, 173.4, 259.6, 345.8, 432. , 518.2, 604.4, 690.6, 776.8, 863. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54bdfeae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens,cumulative=True,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out  1239 sentences\n"
     ]
    }
   ],
   "source": [
    "tmp = len(sql_tok)\n",
    "sql_tok = [i for i in sql_tok if len(i)>=4 and len(i)< int(lens.mean()+ 2*lens.std())] # Roughly 95% data\n",
    "print('Filter out ', tmp - len(sql_tok), \"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:39:14.670488Z",
     "start_time": "2018-04-23T09:39:13.883Z"
    }
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common()] ## Avoid rare tokens\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([0] + [stoi[o] for o in p] + [2]) for p in tok]) # pad bos at beginning and eos at the end\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:57:59.312786Z",
     "start_time": "2018-04-20T09:57:58.409179Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids,sql_itos,sql_stoi = toks2ids(sql_tok,'sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:14.241166Z",
     "start_time": "2018-04-23T09:33:13.828035Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_ids_concat= []\n",
    "for i in sql_ids:\n",
    "    sql_ids_concat += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16288"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sql_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:14.711970Z",
     "start_time": "2018-04-23T09:33:14.346007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23355,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T09:33:15.036560Z",
     "start_time": "2018-04-23T09:33:14.713978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 16288\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(sql_itos)\n",
    "print('total words:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=16\n",
    "\n",
    "\n",
    "c_in_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(0, len(sql_ids_concat)-cs-1, cs)]\n",
    "c_out_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(1, len(sql_ids_concat)-cs, cs)]\n",
    "\n",
    "xs = np.stack(c_in_dat)\n",
    "ys = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106545, 16), (106545, 16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape,ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  12,  11,  13, 103,  19,  90,   6, 104,   7,  35,   8,  22, 497,  22, 123],\n",
       "       [ 22,   8,  24,  18, 121,   6, 104,   7, 114,   2,   0,  76,  31,  13, 146,   9],\n",
       "       [140,   6, 146,   5,   8,  14,  14, 237, 125, 194,  39, 330,  39, 100,  14,  14]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,  11,  13, 103,  19,  90,   6, 104,   7,  35,   8,  22, 497,  22, 123,  22],\n",
       "       [  8,  24,  18, 121,   6, 104,   7, 114,   2,   0,  76,  31,  13, 146,   9, 140],\n",
       "       [  6, 146,   5,   8,  14,  14, 237, 125, 194,  39, 330,  39, 100,  14,  14,   8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)\n",
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=256\n",
    "n_fac=128\n",
    "dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn1 = nn.GRU(n_fac, n_hidden, num_layers=2, dropout=dropout, bidirectional=False)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h1.size(1) != bs: self.init_hidden(bs)\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h1 = self.rnn1(inp, self.h1)\n",
    "        self.h1 = repackage_var(h1)\n",
    "        #pdb.set_trace()\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)\n",
    "    \n",
    "    def init_hidden(self, bs): \n",
    "        self.h1 = V(torch.zeros(2, bs, n_hidden))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU_Bidir(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn1 = nn.GRU(n_fac, n_hidden, num_layers=2, dropout=dropout, bidirectional=True)\n",
    "        self.l_out = nn.Linear(n_hidden*2, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h1.size(1) != bs: self.init_hidden(bs)\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h1 = self.rnn1(inp, self.h1)\n",
    "        self.h1 = repackage_var(h1)\n",
    "        #pdb.set_trace()\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)\n",
    "    \n",
    "    def init_hidden(self, bs): \n",
    "        self.h1 = V(torch.zeros(4, bs, n_hidden))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([sql_stoi[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    p = to_np(p)[0]\n",
    "    i = np.argmax(p[-1,:,:])\n",
    "    \n",
    "    return sql_itos[i]\n",
    "\n",
    "def get_next_random(inp, n):\n",
    "    idxs = T(np.array([sql_stoi[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    p = to_np(p[-1,:,:])[0]\n",
    "    pi = p.argsort()[-n:] # Sample the 10 most possible token only\n",
    "    i = np.random.choice(pi, p=softmax_np(p[pi]))\n",
    "    return sql_itos[i]\n",
    "\n",
    "def softmax_np (nparray):\n",
    "    ans = np.exp(nparray)\n",
    "    return ans/ans.sum()\n",
    "\n",
    "\n",
    "def get_sentence(inp):\n",
    "    sentence = inp\n",
    "    counter = 0\n",
    "    tmp = []\n",
    "    while \"_eos_\" not in tmp:   \n",
    "        tmp = get_next(sentence[-cs:]) \n",
    "        sentence += [tmp]\n",
    "        counter = counter+1\n",
    "        if counter> 200:\n",
    "            break\n",
    "    return sentence\n",
    "\n",
    "def get_sentence_random(inp, n):\n",
    "    sentence = inp\n",
    "    counter = 0\n",
    "    tmp = []\n",
    "    while \"_eos_\" not in tmp:   \n",
    "        tmp = get_next_random(sentence[-cs:], n) \n",
    "        sentence += [tmp]\n",
    "        counter = counter+1\n",
    "        if counter> 100:\n",
    "            break\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case():\n",
    "    sample = ['update','select','delete','insert']\n",
    "    \n",
    "#     for i in sample:\n",
    "#         print('Input:', i, 'output:', i + \" \" + get_next(i))       \n",
    "#     for i in sample:\n",
    "#         print('Input:', i, 'output:', \" \".join(get_sentence([i])))    \n",
    "        \n",
    "    print('For Random Generation, sample 10 most possible tokens')\n",
    "    \n",
    "                    \n",
    "    for i in sample:\n",
    "        print('Input:', i, 'output:', \" \".join(get_sentence_random([i], 10)))  \n",
    "        print()\n",
    "        \n",
    "    print('Sample 5 most possible tokens')\n",
    "                    \n",
    "    for i in sample:\n",
    "        print('Input:', i, 'output:', \" \".join(get_sentence_random([i], 5)))  \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    targ = targ.view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hidden: 256 n_fac: 128 dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('n_hidden:',n_hidden,'n_fac:',n_fac,'dropout:',dropout)\n",
    "            \n",
    "m = CharSeqStatefulGRU_Bidir(len(sql_itos), n_fac, bs=bs)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.crit = nll_loss_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targs):\n",
    "    preds = torch.max(preds.view(-1,len(sql_itos)), dim=1)[1]\n",
    "    targs = targs.transpose(0,1).contiguous().view(-1)\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5640adfd5ccb4125b117312bed645165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.524841   0.430644   0.937227  \n",
      "    1      0.442224   0.444568   0.939864                    \n",
      "    2      0.43317    0.454402   0.94437                     \n",
      "    3      0.319061   0.401509   0.949789                    \n",
      "    4      0.251494   0.368262   0.952705                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.36826]), 0.9527047644672022]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 1, cycle_len=5,use_clr_beta = (5,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_bidir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Generation, sample 10 most possible tokens\n",
      "Input: update output: update toptenusers store store be be update jumps store store toptenusers toptenusers search_type_id toptenusers update toptenusers store toptenusers top10reptotal store store be larger than 181965 store store toptenusers toptenusers cologne toptenusers toptenusers toptenusers be values 15 when posttime be larger than float declare @ toptenusers toptenusers cologne ) person_id decimal ( 15 15 when 90 subcatgroup open than float declare @ toptenusers toptenusers values ( person_id decimal ( 15 15 when 90 subcatgroup open than float declare @ toptenusers toptenusers values ( person_id decimal ( 15 15 when 90 subcatgroup open than float declare @ toptenusers toptenusers values ( person_id decimal (\n",
      "\n",
      "Input: select output: select 15 select count ( select distinct 1 select count * * ) select distinct pt . postid as [ post link ] , 1 select count ( * ) from posttags pt . postid as [ post link ] , p . count ( * ) from posttags pt . postid as [ post link ] , p . id , * ) from posttags pt . postid as [ post link ] , p . id , * ) from posttags pt . postid as [ post link ] , p . id , * ) from posttags pt .\n",
      "\n",
      "Input: delete output: delete postid delete delete delete delete an to provide an to provide provide provide provide provide provide | rate than delete delete provide an to provide an to provide cross apply provide provide provide | rate than delete delete provide an to provide an to provide cross apply provide provide provide | rate than delete delete provide an to provide an to provide cross apply provide provide provide | rate than delete delete you an to provide an to provide cross apply provide provide provide | rate than open datetime2 delete an to to an to provide cross apply provide provide provide\n",
      "\n",
      "Input: insert output: insert into جزائر جزائر insert into preceding insert into preceding insert into insert into insert insert into insert into @ جزائر insert into preceding insert into preceding insert into preceding into insert into into into into @ جزائر جزائر into @ insert into preceding insert into preceding into insert into into into into @ جزائر جزائر into @ insert into preceding insert into preceding into insert into into into into @ جزائر جزائر into @ insert into preceding insert into preceding into insert into into into into @ جزائر جزائر into @ insert into preceding insert into preceding into insert into into\n",
      "\n",
      "Sample 5 most possible tokens\n",
      "Input: update output: update into update update update update update update update update update update update update update update update update into update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update update\n",
      "\n",
      "Input: select output: select update select top 100 count ( * ) from posts where owneruserid = 3001761 select distinct userid as [ user link ] from users ) from posts where owneruserid = 3001761 select distinct userid as [ user link ] from users ) from posts where owneruserid = 3001761 select distinct userid as [ user link ] from users ) from posts where owneruserid = 3001761 select distinct userid as [ user link ] from users ) from posts where owneruserid = 3001761 and distinct userid as [ user link ] from users ) from posts where owneruserid = 3001761 and userid\n",
      "\n",
      "Input: delete output: delete ( delete , delete ) delete delete delete delete delete delete delete delete delete delete delete delete ( delete , delete ) delete delete delete delete delete delete delete delete delete delete delete delete ( delete , delete ) delete delete delete delete delete delete delete delete delete delete delete delete ( delete , delete ) delete delete delete delete delete delete delete delete delete delete delete delete ( delete , 4000 ) delete delete delete delete delete delete delete delete delete delete delete delete ( delete , 4000 ) delete delete delete delete delete delete delete delete delete delete delete\n",
      "\n",
      "Input: insert output: insert delete insert insert insert into # insert insert into insert into insert into insert into insert into delete into # insert into # userid insert into insert into insert into insert into insert into delete into # insert into # userid insert into insert into insert into insert into preceding into delete into # insert into # userid # # insert into @ endoflastyear insert into preceding into delete into # insert into # userid # # insert into @ reasons insert into preceding into delete into # insert into # userid # # insert into @ reasons insert into preceding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(len(sql_itos), n_fac, bs=bs)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.crit = nll_loss_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics =[accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc825af35384922bebc0f378b87fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      4.151299   4.041293   0.252928  \n",
      "    1      3.643026   3.583236   0.336171                   \n",
      "    2      2.462626   2.295749   0.53197                    \n",
      "    3      2.187626   2.114319   0.558994                   \n",
      "    4      2.035453   2.025491   0.571048                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.02549]), 0.5710484629784132]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 1, cycle_len=5,use_clr_beta = (5,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_singledir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('model_singledir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_bos_'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_random(['_eos_'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Generation, sample 10 most possible tokens\n",
      "Input: update output: update null order by p . creationdate desc _eos_\n",
      "\n",
      "Input: select output: select count ( postid ) as num , tags from posts where owneruserid = @ userid _eos_\n",
      "\n",
      "Input: delete output: delete ' order by reputation desc ; _eos_\n",
      "\n",
      "Input: insert output: insert into # customer , @ top10reptotal int , up int , down int set @ enddate = 1 and posts . communityowneddate is null and p . closeddate is null and p . answercount = 0 and p . score ) < 200 and p . creationdate > = dateadd ( month , 0 ) order by reputation desc ) as [ # ] , id as [ user link ] , reputation from users where lower ( location ) like ' % india % ' or upper ( location select ' http : / / stackoverflow . com / questions\n",
      "\n",
      "Sample 5 most possible tokens\n",
      "Input: update output: update ? 1 # # ; with cte as ( select count ( * ) from votes v inner join posts a on q . id = q . owneruserid where lower ( location ) like ' % india ' or upper ( location ) like ' % sg ' ) order by reputation desc _eos_\n",
      "\n",
      "Input: select output: select * from ( select row_number ( ) over ( order by reputation desc ) as [ # ] , id as [ user link ] , reputation from users where lower ( location ) like ' % india % ' or upper ( location ) like ' % ind ' order by reputation desc ; _eos_\n",
      "\n",
      "Input: delete output: delete ' _eos_\n",
      "\n",
      "Input: insert output: insert into @ sitedbname ( ( ) over ( partition by postid ) from posthistory where posthistorytypeid = 10 and posts . creationdate < ' 2010 - 01 - 01 00 : 00 : 00 ' group by u . id , u . displayname having count ( * ) > 0 order by reputation desc ) as [ # ] , id [ user link ] , reputation , location from users where lower ( location ) like lower ( ' % جزائر % ' ) and posttypeid = 1 and posts = ' answer ' , ' unsung hero '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a418e59700747ce8e04df59e558c39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      2.016179   2.012666   0.572656  \n",
      "    1      1.983365   1.992622   0.576059                   \n",
      "    2      1.955467   1.982495   0.577872                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.98249]), 0.5778719783724543]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-3, 1, cycle_len=3,use_clr_beta = (5,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_singledir_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Generation, sample 10 most possible tokens\n",
      "Input: update output: update # # and q . acceptedanswerid = q . id and v . votetypeid = 3 group by tagname order by score asc _eos_\n",
      "\n",
      "Input: select output: select p . viewcount as float ) / cast ( score + ( upvotes / datediff ( minute , creationdate , getdate ( ) ) as ' # # userid # # and p . tags like ' % < code > = ' android ' ) group by t . tagname order by count ( * ) desc ; _eos_\n",
      "\n",
      "Input: delete output: delete ' _eos_\n",
      "\n",
      "Input: insert output: insert into @ products values ( 2 , 3 , 2 ) and score > = 0 and p . closeddate is null group by year ( p . creationdate ) , month ( p . creationdate ) , p . creationdate , 112 ) from comments c where p . closeddate is null and closeddate is null order by score asc _eos_\n",
      "\n",
      "Sample 5 most possible tokens\n",
      "Input: update output: update # # select * from posts where posttypeid = 2 and communityowneddate is null order by reputation desc _eos_\n",
      "\n",
      "Input: select output: select top 10 * from comments where userid in ( 1 , 3 ) , 0 , 4 , ' name5 ' , ' electorate ' as groups union all select 2 , 2 union all select 2 , 3 , 3 ) as x group by tagname order by count ( * ) desc _eos_\n",
      "\n",
      "Input: delete output: delete ' , ' r ' ) ; declare @ userid as int = @ userid and myanswer . posttypeid = 2 and a . score = 1 and a . posttypeid = 2 and q . owneruserid = @ userid and q . owneruserid = q . id and a . owneruserid = # # userid # # select count ( * ) as count from posts p where p . posttypeid = 1 and p . tags like ' % < windows - phone > % ' and p . tags like ' % < windows - phone - protocols\n",
      "\n",
      "Input: insert output: insert ( location ) like n ' % india % ' or lower ( location ) like ' % india % ' order by reputation desc ; _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "<U4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-65eaa119e725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'from'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-ac5149b0df02>\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36mVV\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mVV\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVV_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36mmap_over\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36mVV_\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mVV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVV\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmap_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVV_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36mcreate_variable\u001b[0;34m(x, volatile, requires_grad)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIS_TORCH_04\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SQL_Generator/fastai/core.py\u001b[0m in \u001b[0;36mT\u001b[0;34m(a, half, cuda)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHalfTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhalf\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: <U4"
     ]
    }
   ],
   "source": [
    "get_next(['from'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrow Jason's Pre-processing https://gist.github.com/jasonjmcghee/bf65447cdb55280e0c942441218e226a and plug into my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('data')\n",
    "SENLIDB = DATA_PATH\n",
    "\n",
    "with open(SENLIDB/'train.json') as data_file:    \n",
    "    senlidb_train = json.load(data_file)\n",
    "    \n",
    "# with open(SENLIDB/'test.json') as data_file:    \n",
    "#     senlidb_test = json.load(data_file)\n",
    "\n",
    "def buildDataFrames(senlidb):\n",
    "    sqls, titles, descriptions = zip(*[(o[\"sql\"], o[\"title\"], o[\"description\"]) for i,o in enumerate(senlidb)])\n",
    "    return pd.DataFrame({\"sql\": sqls, \"title\": titles, \"description\": descriptions}, columns={\"title\", \"description\", \"sql\"})\n",
    "\n",
    "df_trn = buildDataFrames(senlidb_train)\n",
    "# df_test = buildDataFrames(senlidb_test)\n",
    "\n",
    "TMP_PATH = DATA/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "df_trn.to_csv(str(TMP_PATH/'train.csv'), index=False)\n",
    "# df_test.to_csv(str(TMP_PATH/'test.csv'), index=False)\n",
    "\n",
    "df_trn = pd.read_csv(str(TMP_PATH/'train.csv')).fillna('')\n",
    "# df_test = pd.read_csv(str(TMP_PATH/'test.csv')).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.shape\n",
    "\n",
    "df_lm = pd.concat([df_trn], axis=0)\n",
    "\n",
    "trn_texts, val_texts = sklearn.model_selection.train_test_split(df_lm, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_keywords = ['ADD', 'EXTERNAL', 'PROCEDURE', 'ALL', 'FETCH', 'PUBLIC', 'ALTER', 'FILE', 'RAISERROR', 'AND', 'FILLFACTOR', 'READ', 'ANY', 'FOR', 'READTEXT', 'AS', 'FOREIGN', 'RECONFIGURE', 'ASC', 'FREETEXT', 'REFERENCES', 'AUTHORIZATION', 'FREETEXTTABLE', 'REPLICATION', 'BACKUP', 'FROM', 'RESTORE', 'BEGIN', 'FULL', 'RESTRICT', 'BETWEEN', 'FUNCTION', 'RETURN', 'BREAK', 'GOTO', 'REVERT', 'BROWSE', 'GRANT', 'REVOKE', 'BULK', 'GROUP', 'RIGHT', 'BY', 'HAVING', 'ROLLBACK', 'CASCADE', 'HOLDLOCK', 'ROWCOUNT', 'CASE', 'IDENTITY', 'ROWGUIDCOL', 'CHECK', 'IDENTITY', 'INSERT', 'RULE', 'CHECKPOINT', 'IDENTITYCOL', 'SAVE', 'CLOSE', 'IF', 'SCHEMA', 'CLUSTERED', 'IN', 'SECURITYAUDIT', 'COALESCE', 'INDEX', 'SELECT', 'COLLATE', 'INNER', 'SEMANTICKEYPHRASETABLE', 'COLUMN', 'INSERT', 'SEMANTICSIMILARITYDETAILSTABLE', 'COMMIT', 'INTERSECT', 'SEMANTICSIMILARITYTABLE', 'COMPUTE', 'INTO', 'SESSION', 'USER', 'CONSTRAINT', 'IS', 'SET', 'CONTAINS', 'JOIN', 'SETUSER', 'CONTAINSTABLE', 'KEY', 'SHUTDOWN', 'CONTINUE', 'KILL', 'SOME', 'CONVERT', 'LEFT', 'STATISTICS', 'CREATE', 'LIKE', 'SYSTEM', 'USER', 'CROSS', 'LINENO', 'TABLE', 'CURRENT', 'LOAD', 'TABLESAMPLE', 'CURRENT', 'DATE', 'MERGE', 'TEXTSIZE', 'CURRENT', 'TIME', 'NATIONAL', 'THEN', 'CURRENT', 'TIMESTAMP', 'NOCHECK', 'TO', 'CURRENT', 'USER', 'NONCLUSTERED', 'TOP', 'CURSOR', 'NOT', 'TRAN', 'DATABASE', 'NULL', 'TRANSACTION', 'DBCC', 'NULLIF', 'TRIGGER', 'DEALLOCATE', 'OF', 'TRUNCATE', 'DECLARE', 'OFF', 'TRY', 'CONVERT', 'DEFAULT', 'OFFSETS', 'TSEQUAL', 'DELETE', 'ON', 'UNION', 'DENY', 'OPEN', 'UNIQUE', 'DESC', 'OPENDATASOURCE', 'UNPIVOT', 'DISK', 'OPENQUERY', 'UPDATE', 'DISTINCT', 'OPENROWSET', 'UPDATETEXT', 'DISTRIBUTED', 'OPENXML', 'USE', 'DOUBLE', 'OPTION', 'USER', 'DROP', 'OR', 'VALUES', 'DUMP', 'ORDER', 'VARYING', 'ELSE', 'OUTER', 'VIEW', 'END', 'OVER', 'WAITFOR', 'ERRLVL', 'PERCENT', 'WHEN', 'ESCAPE', 'PIVOT', 'WHERE', 'EXCEPT', 'PLAN', 'WHILE', 'EXEC', 'PRECISION', 'WITH', 'EXECUTE', 'PRIMARY', 'WITHIN', 'GROUP', 'EXISTS', 'PRINT', 'WRITETEXT', 'EXIT', 'PROC']\n",
    "\n",
    "functions = [\"ASCII\", \"CHAR\", \"CHARINDEX\", \"CONCAT\", \"DATALENGTH\", \"LEFT\", \"LEN\", \"LOWER\", \"LTRIM\", \"NCHAR\", \"PATINDEX\", \"REPLACE\", \"RIGHT\", \"RTRIM\", \"SPACE\", \"STR\", \"STUFF\", \"SUBSTRING\", \"UPPER\", \"ABS\", \"AVG\", \"CEILING\", \"COUNT\", \"FLOOR\", \"MAX\", \"MIN\", \"RAND\", \"ROUND\", \"SIGN\", \"SUM\", \"CURRENT_TIMESTAMP\", \"DATEADD\", \"DATEDIFF\", \"DATENAME\", \"DATEPART\", \"DAY\", \"GETDATE\", \"GETUTCDATE\", \"MONTH\", \"YEAR\", \"CAST\", \"CONVERT\", \"COALESCE\", \"CURRENT_USER\", \"ISDATE\", \"ISNULL\", \"ISNUMERIC\", \"NULLIF\", \"SESSION_USER\", \"SESSIONPROPERTY\", \"SYSTEM_USER\", \"USER_NAME\", \"CAST\"]\n",
    "functions_lower = [f.lower() for f in functions]\n",
    "\n",
    "sql_keywords_lower = [keyword.lower() for keyword in sql_keywords]\n",
    "\n",
    "symbols = \",()='\\\";{}*!^&+-<>:~`|?\"\n",
    "\n",
    "BOS = 'xbos'  # beginning-of-statement\n",
    "EOS = 'xeos'  # end-of-statement\n",
    "SCHEMA = 'xschema'\n",
    "LITERAL = 'xliteral'\n",
    "\n",
    "vocab = sql_keywords_lower + list(symbols) + functions_lower + [SCHEMA, LITERAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_and_fix(df, i):\n",
    "    sql = df.at[df.index[i],'sql']\n",
    "    if not isinstance(sql, str):\n",
    "        sql = ' ; '.join(sql)\n",
    "    sql_stripped = sql.lower().strip()\n",
    "    sql_symbols = sql_stripped\n",
    "    \n",
    "    # Put spaces around symbols\n",
    "    for symbol in symbols:\n",
    "        sql_symbols = f\" {symbol} \".join(re.split(f\"\\{symbol}|\\{symbol} | \\{symbol}| \\{symbol} \", sql_symbols))\n",
    "\n",
    "    # Swap out blocks like [Foo Bar] for xschema\n",
    "    sql_symbols = re.sub(\"\\[[^\\[\\]]*\\]\", SCHEMA, sql_symbols)\n",
    "\n",
    "    sql_split = [x for x in sql_symbols.split(\" \")  if len(x)]\n",
    "    if len(sql_split) > 1:\n",
    "        for i, word in enumerate(sql_split):\n",
    "            is_number = re.match(r\"\\d+\", word)\n",
    "            is_literal = re.match(r\"^('|\\\")\", word)\n",
    "            if word not in vocab and not is_number and not is_literal:\n",
    "                sql_split[i] = SCHEMA\n",
    "            elif is_number or is_literal:\n",
    "                sql_split[i] = LITERAL\n",
    "    return \" \".join(sql_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8167"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_texts(df, n_lbls=2):\n",
    "    labels = df.iloc[:,range(n_lbls)].values\n",
    "    texts = [f'{BOS} ' + get_sql_and_fix(df, i) + f' ; {EOS}' for i in range(1, df.shape[0])]\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "trn_texts.at[trn_texts.index[102], 'sql']\n",
    "\n",
    "get_sql_and_fix(trn_texts, 102)\n",
    "\n",
    "trn_texts.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SENLIDB/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "trn_tok, trn_labels = get_texts(trn_texts, 2)\n",
    "\n",
    "test_tok, test_labels = get_texts(val_texts, 2)\n",
    "\n",
    "np.save(SENLIDB/'tmp'/'tok_trn.npy', trn_tok)\n",
    "np.save(SENLIDB/'tmp'/'tok_val.npy', test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_trn = np.load(SENLIDB/'tmp'/'tok_trn.npy')\n",
    "tok_test = np.load(SENLIDB/'tmp'/'tok_val.npy')\n",
    "\n",
    "freq = Counter(p for o in tok_trn for p in o if p in vocab)\n",
    "freq.most_common(25)\n",
    "\n",
    "itos = [o for o,c in freq.most_common(len(vocab)) if o in vocab]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_test])\n",
    "\n",
    "trn_lm.shape\n",
    "\n",
    "val_lm.shape\n",
    "\n",
    "np.save(SENLIDB/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(SENLIDB/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(SENLIDB/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this directly if you have run the previous cell at least once before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 22133)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_lm = np.load(SENLIDB/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(SENLIDB/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(SENLIDB/'tmp'/'itos.pkl', 'rb'))\n",
    "\n",
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(start=\"xbos select\"):\n",
    "    tok = Tokenizer()\n",
    "    s = [tok.spacy_tok(start)]\n",
    "    tok_arr = np.array([[stoi[o] for o in p] for p in s])\n",
    "    output = start.split(\" \")[1].upper()\n",
    "    while True:\n",
    "        tok_idx = get_next(tok_arr)\n",
    "        word = itos[tok_idx]\n",
    "        if word in sql_keywords_lower:\n",
    "            word = word.upper()\n",
    "        output += \" \" + word\n",
    "        tok_arr = np.reshape(np.append(tok_arr[0][1:],[tok_idx]),(1,2))\n",
    "        if word == \";\": break\n",
    "    return output\n",
    "\n",
    "def get_next(token):\n",
    "    probs = learn.model(*VV(token))\n",
    "    return to_np(torch.multinomial(probs[0][-1].exp(), 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_ids_concat = np.concatenate(trn_lm) # Hook to match Jason code\n",
    "sql_itos = itos\n",
    "sql_stoi = stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=16\n",
    "c_in_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(0, len(sql_ids_concat)-cs-1, cs)]\n",
    "c_out_dat = [[sql_ids_concat[i+j] for i in range(cs)] for j in range(1, len(sql_ids_concat)-cs, cs)]\n",
    "\n",
    "xs = np.stack(c_in_dat)\n",
    "ys = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)\n",
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden= 256\n",
    "n_fac=64\n",
    "dropout=0.5\n",
    "bidir=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hidden: 256 n_fac: 64 bidir: False dropout: 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0eb98985c6748a2a77c993eaf4272c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.242543   1.174477   0.666363  \n",
      "    1      1.177888   1.152642   0.668173                   \n",
      "    2      1.172578   1.122859   0.675143                   \n",
      "    3      1.128307   1.091885   0.681611                   \n",
      "    4      1.094723   1.063962   0.687846                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.06396]), 0.6878460207263428]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('n_hidden:',n_hidden,'n_fac:',n_fac,'bidir:',bidir,'dropout:',dropout)\n",
    "            \n",
    "m = CharSeqStatefulGRU(len(sql_itos), n_fac, bs=bs)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.crit = nll_loss_seq\n",
    "learn.metrics = [accuracy]\n",
    "learn.fit(1e-2, 1, cycle_len=5,use_clr_beta = (5,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT dateadd ( day , datediff ( day , xliteral , xschema ) , xliteral ) - xliteral ) * xliteral + xschema - xschema ) + xschema AS xschema FROM xschema xschema LEFT JOIN xschema xschema ON xschema = xschema WHERE xschema IN ( xliteral , xliteral ) AND xschema = xschema FETCH xschema FROM xschema xschema WHERE xschema LIKE xliteral xschema < xliteral + xschema END AS xschema , count ( xschema ) AS xschema FROM xschema GROUP BY xschema , xschema ORDER BY xliteral AS xschema FROM xschema GROUP BY xschema ORDER BY count DESC ;\n",
      "\n",
      "SELECT xschema , sum ( CASE WHEN xschema = xliteral THEN xliteral ELSE xliteral END ) , count ( * ) FROM xschema ) ) = xliteral ORDER BY sum ( xschema ) DESC ;\n",
      "\n",
      "SELECT TOP xliteral xschema , xschema , xschema : xliteral + cast ( xschema AS xschema ) ) + xliteral xschema xliteral AS xschema FROM xschema AS xschema LEFT JOIN ( SELECT xschema , xschema AS xschema , xschema ORDER BY xschema DESC , COALESCE ( xschema , xschema ) AS xschema FROM xschema xschema JOIN xschema xschema ON xschema = xschema INNER JOIN xschema xschema ON xschema = xschema GROUP BY xschema DESC ) , xliteral xschema xliteral , xliteral xliteral xliteral , xliteral UNION ALL SELECT xliteral xliteral - xliteral + xliteral xschema xliteral END AS xschema , sum ( CASE WHEN xschema < = xliteral THEN xliteral ELSE xliteral END ) AS xschema FROM xschema , xliteral xschema xliteral ) WHERE xschema = xschema AND xschema = xliteral THEN xliteral WHEN xschema - xliteral xliteral : xliteral : xliteral xliteral , xliteral xschema xliteral ) , xschema DESC , xschema DESC ;\n",
      "\n",
      "SELECT TOP xliteral xschema FROM xschema GROUP BY xschema ORDER BY xschema DESC ) SELECT * = sum ( xschema ( xschema IN ( xliteral , xliteral GROUP BY xschema ) AS xschema ON xschema = xschema JOIN xschema AS xschema ON xschema = xschema WHERE xschema = xliteral GROUP BY xschema ORDER BY count ( * ) DESC ;\n",
      "\n",
      "SELECT TOP xliteral xschema , xschema ;\n",
      "\n",
      "UPDATE xschema SET xschema = ( SELECT count ( xschema ) FROM xschema WHERE xschema = xliteral AND xschema LIKE xliteral xschema < xschema > xschema xliteral ) DECLARE xschema TABLE ( xschema xschema , xschema xschema ( xliteral ) = dateadd ( xschema , xliteral , getdate ( ) ) AND datediff ( day , xschema , getdate ( ) ) > = xliteral WHERE lower ( xschema ) LIKE xliteral xschema xliteral OR lower ( xschema ) LIKE xliteral xschema xliteral OR lower ( xschema ) LIKE xliteral xschema xliteral OR lower ( xschema ) LIKE xliteral xschema xliteral ;\n",
      "\n",
      "UPDATE xschema SET xschema = xschema ;\n",
      "\n",
      "UPDATE xschema SET xschema = xliteral xliteral - xliteral - xliteral xliteral } ) AS xschema ( xschema ) AS xschema , sum ( xschema ) AS xschema FROM xschema xschema INNER JOIN xschema xschema ON xschema = xschema AND xschema xschema xliteral ) THEN xliteral ELSE xliteral END ) AS xliteral xschema xliteral , count ( * ) xschema FROM xschema xschema INNER JOIN xschema ( SELECT count ( xliteral ) , xliteral ) xschema , sum ( CASE WHEN xschema < = xliteral THEN - xliteral END ) DESC ;\n",
      "\n",
      "UPDATE xschema AND xschema NOT LIKE xschema ) OR ( xschema LIKE xliteral xschema < xschema > xschema xliteral OR xschema LIKE xliteral xschema < xschema > = xliteral ORDER BY xschema DESC ;\n",
      "\n",
      "UPDATE xschema SELECT xschema ;\n",
      "\n",
      "DELETE , xschema xschema > = xschema ) , xschema ) * xliteral , xliteral xschema xliteral , xschema xliteral , xliteral xschema xliteral , xliteral xschema xliteral ) AS xschema , xschema ) AS xschema , ( SELECT count ( * ) FROM xschema xschema WHERE xschema NOT IN ( xliteral , xliteral ) AND xschema = xschema AND xschema = xschema GROUP BY xschema , xschema ) SELECT xschema , xschema xschema , xschema , xschema FROM xschema AND xschema > xliteral GROUP BY CASE WHEN xschema = xliteral GROUP BY xschema , xschema , DATE ) xschema INNER JOIN xschema xschema ON xschema = xschema INNER JOIN xschema xschema ON ( xschema = xschema ) WHERE xschema = xschema AND xschema = xliteral ;\n",
      "\n",
      "DELETE - xschema xliteral AND xschema IN ( xliteral xschema xliteral , xliteral xschema xliteral , xliteral xschema xschema xliteral , xliteral xliteral - xliteral - xliteral xliteral : xliteral xliteral , xliteral xliteral xliteral , xliteral xschema , xschema xschema , xschema xschema , xschema xschema , xschema xschema , xschema xschema , count ( * ) , sum ( CASE WHEN datediff ( day , xschema , xschema ) < xliteral - xschema > xliteral ORDER BY xschema DESC ;\n",
      "\n",
      "SELECT xliteral , sum ( CASE WHEN xschema = xliteral AND xschema = xliteral THEN xliteral ELSE xliteral END ) AS xschema FROM xschema AS xschema JOIN ( SELECT xschema AS xschema , xschema , xschema FROM xschema xschema INNER JOIN xschema xschema ON xschema = xschema INNER JOIN xschema xschema ON xschema = xschema AND xschema LIKE ( xliteral xschema xliteral OR xschema = xschema AND xschema = xschema GROUP BY xschema , datepart ( year , xschema ) ORDER BY month ( xschema ) , xschema ORDER BY datepart ( xschema , xschema ) DESC ;\n",
      "\n",
      "INSERT xschema SELECT count ( * ) FROM xschema xschema NOT NULL , xschema xschema NOT NULL DEFAULT getdate ( ) ) AND NOT EXISTS ( SELECT xliteral FROM xschema WHERE xschema LIKE xliteral xschema xliteral ORDER BY xschema DESC ;\n",
      "\n",
      "DELETE + xliteral xschema xliteral ) AND xschema = xliteral GROUP BY xschema ORDER BY xschema DESC ) xschema ON xschema = xschema WHERE xschema IN ( xliteral xschema xliteral , xliteral xschema xliteral ) AND xschema < xliteral ORDER BY xschema DESC ;\n",
      "\n",
      "DELETE , count ( xschema ) FROM xschema xschema WHERE xschema LIKE xliteral xschema - xschema - xschema xliteral ) ) SELECT xschema FROM xschema ORDER BY count DESC ;\n",
      "\n",
      "INSERT INTO xschema ( xschema ON xschema = xschema AND xschema BETWEEN xliteral xliteral - xliteral - xliteral xliteral AND xliteral xliteral - xliteral - xliteral xliteral : xliteral : xliteral count ( DISTINCT xschema ) ASC ;\n",
      "\n",
      "DELETE ;\n",
      "\n",
      "INSERT INTO xschema ( xschema , xschema , xschema ) VALUES ( xliteral , xliteral xschema xliteral ) INSERT xschema SELECT DISTINCT xschema , substring ( xschema , xliteral , xliteral , xliteral ) AS xliteral xschema xliteral , ( CASE WHEN xschema > = xliteral THEN xliteral WHEN xliteral THEN xliteral , xliteral ) ORDER BY xschema DESC ;\n",
      "\n",
      "UPDATE xschema SET xschema = xschema CREATE TABLE ( xschema xschema PRIMARY KEY CLUSTERED CLUSTERED ( xschema ( xschema ) AS xschema , xschema AS xschema , xschema AS xschema AS xschema FROM xschema , xschema , xschema WHERE xschema = xschema AND xschema IN ( xliteral , xliteral ) AND xschema IS NULL GROUP BY xschema ORDER BY count ( * ) DESC ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(generate_sql(\"xbox select\"))\n",
    "    print()\n",
    "\n",
    "for i in range(5):\n",
    "    print(generate_sql(\"xbos update\"))\n",
    "    print()\n",
    "\n",
    "for i in range(10):\n",
    "    cmd = random.choice([\"select\", \"update\", \"insert\", \"delete\"])\n",
    "    print(generate_sql(f\"xbos {cmd}\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
