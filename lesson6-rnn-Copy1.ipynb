{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:21:34.762730Z",
     "start_time": "2018-04-16T16:21:33.175608Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.text import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:19:24.378696Z",
     "start_time": "2018-04-16T16:19:24.200204Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "DATA_PATH\n",
    "TMP_PATH = DATA_PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:19:57.951615Z",
     "start_time": "2018-04-16T16:19:57.171030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 24594\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_json(DATA_PATH/'train.json')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:20:54.072997Z",
     "start_time": "2018-04-16T16:20:53.917575Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform the text to be tokenize readily, as certain token has special meaning in SQL, ie. \".\" means the schema relation\n",
    "token_replaced = {',' : ' , ',\n",
    "                 '#' : ' # ',\n",
    "                 '@' : ' @ ',\n",
    "                 '!' : ' ! ',\n",
    "                 '.' : ' . ',\n",
    "                 '%' : ' % ',\n",
    "                 '?' : ' ? ',\n",
    "                 ')' : ' ) ',\n",
    "                 '(' : ' ( ',\n",
    "                 '=' : ' = ',\n",
    "                 '/' : ' / ',\n",
    "                 '*' : ' * '}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:20:54.420943Z",
     "start_time": "2018-04-16T16:20:54.273533Z"
    }
   },
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    for bereplaced, replace in token_replaced.items():        \n",
    "        x = x.replace(bereplaced, replace)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:21:06.356456Z",
     "start_time": "2018-04-16T16:21:06.006865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT p . Title , p . score , p . ViewCount , p . AnswerCount , p . CommentCount , LEN ( p . body )  as ques_size ,  p . favoritecount , p . id ,  u . reputation as user_repo , u . creationdate as user_join_date ,  datediff ( MINUTE ,  p . CreationDate ,  a . CreationDate )  as QATimeGap from posts as p ,  posts as a ,  users as u where p . id = a . parentId and p . owneruserid = u . id and a . creationdate  =   ( select min ( tau . creationdate )  from posts tau where tau . parentID = p . id group by tau . parentID )  and  (  p . title like \\' % Recommended method for handling UnsupportedEncodingException from String . getBytes ( \"UTF-8\" )  % \\' or p . title like \\' % Way to format strings with \" ? \" parameters to full string in java ?  % \\' or p . title like \\' % How to parse a string without regular expressions % \\' or p . title like \\' % How to replace string only once without regex in Java ?  % \\' or p . title like \\' % Efficiently removing specific characters  ( some punctuation )  from Strings in Java ?  % \\' or p . title like \\' % Strings are immutable - that means I should never use + =  and only StringBuffer ?  % \\' or p . title like \\' % Concatenation of Strings and characters % \\' or p . title like \\' % Java - Convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % Better template language needed % \\'  ) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL = SQL.apply(fixup)## Sanity Check\n",
    "SQL.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:33:27.053922Z",
     "start_time": "2018-04-16T16:33:26.736732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        SELECT p . Title , p . score , p . ViewCount ,...\n",
       "1        CREATE TABLE  # CustomerDB  (  ID int NOT NULL...\n",
       "2        select Id from Comments where lower ( Text )  ...\n",
       "3        DECLARE  @ From DATETIME  =  convert ( DATETIM...\n",
       "4        SELECT TOP 50 OwnerUserId as [User Link] ,  CO...\n",
       "5        SELECT Id AS [Post Link] ,  Tags ,  Score FROM...\n",
       "6        select top 100 p . Id as [Post Link] ,  max ( ...\n",
       "7        SELECT TOP 100 q . OwnerUserId AS [User Link] ...\n",
       "8        with bounty_questions as  (  select max ( 1 . ...\n",
       "9        select count (  *  )  from votes v inner join ...\n",
       "10       Select ntile ( 10 )  over  ( Order by DateDiff...\n",
       "11       SELECT Id ,  TagName INTO  # MyTags FROM Tags ...\n",
       "12       DECLARE  @ userID numeric  =   #  # UserID #  ...\n",
       "13       WITH data AS  ( SELECT Rank (  )  OVER  ( PART...\n",
       "14       DECLARE  @ lti3_start_date AS datetime  =   ( ...\n",
       "15       select dateadd ( month ,  datediff ( month ,  ...\n",
       "16       SELECT Users . Id as [User Link] ,  Count (  *...\n",
       "17       select top 100 u . id as [User Link] ,  u . re...\n",
       "18       CREATE TABLE  # Customer (  AccountId int prim...\n",
       "19       select  (  select count (  *  )  from Posts wh...\n",
       "20       select i . Id ,  i . CreationDate ,  i . Title...\n",
       "21            SELECT P . Id FROM POSTS AS P ,  USERS AS U1\n",
       "22       WITH TotalRep AS  (  SELECT P . OwnerUserID , ...\n",
       "23       select top 10 p . Id [Post Link] from Posts p ...\n",
       "24       SELECT TOP 20 Posts . Id as [Post Link] ,  Com...\n",
       "25       SELECT PostId AS [Post Link] ,  'http: /  / st...\n",
       "26       SELECT answer . OwnerUserId As [User Link] ,  ...\n",
       "27       declare  @ user_id int  =   #  # UserId:int # ...\n",
       "28       SELECT  *  FROM Users WHERE  ( Age  =  39 and ...\n",
       "29       select top ( 100 )  p . Id ,  p2 . Id ,  p2 . ...\n",
       "                               ...                        \n",
       "24564    SELECT p . Title ,  p . Id ,  p . Score ,  a ....\n",
       "24565    SELECT TOP 10 Body FROM Posts WHERE OwnerUserI...\n",
       "24566    select DATENAME ( yyyy ,  p . LastActivityDate...\n",
       "24567    SELECT DATEPART ( week , CreationDate )  ,  CA...\n",
       "24568    DECLARE  @ Last30 datetime  =  '12 / 15 / 2012...\n",
       "24569    DECLARE  @ tagcond nvarchar ( 25 )   =  concat...\n",
       "24570    SELECT TOP 10 Posts . Id ,  ParentId ,  Count ...\n",
       "24571    select title ,  id as [Post Link] ,  tags ,  c...\n",
       "24572    SELECT mine . name AS [Badge Name] ,  user_cou...\n",
       "24573    SELECT t2 . tagname AS TagName ,  count (  *  ...\n",
       "24574    SELECT tuser . Score FROM users us JOIN  ( SEL...\n",
       "24575    SELECT  *  FROM VoteTypes select top 20 count ...\n",
       "24576    select  *  ,  count (  *  )  from  (  select C...\n",
       "24577    SELECT body , Id ,  COUNT (  *  )  AS numOccur...\n",
       "24578    SELECT u . Id AS [User Link] ,  Count (  *  ) ...\n",
       "24579    DECLARE  @ UserId int  =   #  # UserId #  #  S...\n",
       "24580    select posts .  *  from posts where posts . ta...\n",
       "24581    select top 1 id ,  postid ,  [text] from PostH...\n",
       "24582    select u . Id as [User Link] ,  u . CreationDa...\n",
       "24583    SELECT type . Name AS [Review Type] ,  COUNT (...\n",
       "24584    SELECT  *  FROM dbo . Users WHERE CONVERT ( TI...\n",
       "24585    SELECT  *  FROM Tags WHERE ExcerptPostId IS NU...\n",
       "24586    DECLARE  @ QtnsUser int  =   #  # QtnsUser #  ...\n",
       "24587    select Id+1 as [Id of deleted post] ,  Creatio...\n",
       "24588    SELECT POSTID As [Post Link] ,  USERID As [Use...\n",
       "24589    select top 5 p . PostTypeId ,  pt . Name ,  p ...\n",
       "24590                          select cast  ( 1 as bit ) 1\n",
       "24591    SELECT ROW_NUMBER (  )  OVER ( ORDER BY tuser ...\n",
       "24592    SELECT DisplayName ,  Age ,  Reputation ,  Web...\n",
       "24593    select top 20 count ( v . postid )  as 'Vote c...\n",
       "Name: sql, Length: 24594, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1' + SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:22:36.475373Z",
     "start_time": "2018-04-16T16:21:35.905877Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tok = Tokenizer.proc_all_mp(partition_by_cores(SQL)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:37:04.333847Z",
     "start_time": "2018-04-16T16:37:04.054047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 't_up',\n",
       " 'select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 't_up',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 't_up',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 't_up',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:37:48.782874Z",
     "start_time": "2018-04-16T16:37:48.492617Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in sql_tok:\n",
    "    i.append('<EOS>')\n",
    "    i.insert(0,'<BOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:37:49.270907Z",
     "start_time": "2018-04-16T16:37:48.993429Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS>',\n",
       " ' ',\n",
       " 't_up',\n",
       " 'select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 't_up',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 't_up',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 't_up',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:37:57.712806Z",
     "start_time": "2018-04-16T16:37:57.004443Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle.dump(sql_tok, (DATA_PATH/'SQL_tok.pkl').open('wb'))\n",
    "sql_tok = pickle.load((DATA_PATH/'sql_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:43:16.531928Z",
     "start_time": "2018-04-16T16:43:16.239134Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS>',\n",
       " ' ',\n",
       " 't_up',\n",
       " 'select',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'score',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'viewcount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'answercount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'commentcount',\n",
       " ',',\n",
       " 't_up',\n",
       " 'len',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'body',\n",
       " ')',\n",
       " 'as',\n",
       " 'ques_size',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'favoritecount',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'reputation',\n",
       " 'as',\n",
       " 'user_repo',\n",
       " ',',\n",
       " 'u',\n",
       " '.',\n",
       " 'creationdate',\n",
       " 'as',\n",
       " 'user_join_date',\n",
       " ',',\n",
       " 'datediff',\n",
       " '(',\n",
       " 't_up',\n",
       " 'minute',\n",
       " ',',\n",
       " 'p',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'as',\n",
       " 'qatimegap',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'p',\n",
       " ',',\n",
       " 'posts',\n",
       " 'as',\n",
       " 'a',\n",
       " ',',\n",
       " 'users',\n",
       " 'as',\n",
       " 'u',\n",
       " 'where',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " '=',\n",
       " 'a',\n",
       " '.',\n",
       " 'parentid',\n",
       " 'and',\n",
       " 'p',\n",
       " '.',\n",
       " 'owneruserid',\n",
       " '=',\n",
       " 'u',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'and',\n",
       " 'a',\n",
       " '.',\n",
       " 'creationdate',\n",
       " '=',\n",
       " '(',\n",
       " 'select',\n",
       " 'min',\n",
       " '(',\n",
       " 'tau',\n",
       " '.',\n",
       " 'creationdate',\n",
       " ')',\n",
       " 'from',\n",
       " 'posts',\n",
       " 'tau',\n",
       " 'where',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " '=',\n",
       " 'p',\n",
       " '.',\n",
       " 'i',\n",
       " 'd',\n",
       " 'group',\n",
       " 'by',\n",
       " 'tau',\n",
       " '.',\n",
       " 'parentid',\n",
       " ')',\n",
       " 'and',\n",
       " '(',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'recommended',\n",
       " 'method',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'unsupportedencodingexception',\n",
       " 'from',\n",
       " 'string',\n",
       " '.',\n",
       " 'getbytes',\n",
       " '(',\n",
       " '\"',\n",
       " 't_up',\n",
       " 'utf-8',\n",
       " '\"',\n",
       " ')',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'way',\n",
       " 'to',\n",
       " 'format',\n",
       " 'strings',\n",
       " 'with',\n",
       " '\"',\n",
       " '?',\n",
       " '\"',\n",
       " 'parameters',\n",
       " 'to',\n",
       " 'full',\n",
       " 'string',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'parse',\n",
       " 'a',\n",
       " 'string',\n",
       " 'without',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'how',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'string',\n",
       " 'only',\n",
       " 'once',\n",
       " 'without',\n",
       " 'regex',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'efficiently',\n",
       " 'removing',\n",
       " 'specific',\n",
       " 'characters',\n",
       " '(',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " ')',\n",
       " 'from',\n",
       " 'strings',\n",
       " 'in',\n",
       " 'java',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'strings',\n",
       " 'are',\n",
       " 'immutable',\n",
       " '-',\n",
       " 'that',\n",
       " 'means',\n",
       " 'i',\n",
       " 'should',\n",
       " 'never',\n",
       " 'use',\n",
       " '+',\n",
       " '=',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stringbuffer',\n",
       " '?',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'concatenation',\n",
       " 'of',\n",
       " 'strings',\n",
       " 'and',\n",
       " 'characters',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'java',\n",
       " '-',\n",
       " 'convert',\n",
       " 'integer',\n",
       " 'to',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'function',\n",
       " 'to',\n",
       " 'remove',\n",
       " 'duplicate',\n",
       " 'characters',\n",
       " 'in',\n",
       " 'a',\n",
       " 'string',\n",
       " '%',\n",
       " \"'\",\n",
       " 'or',\n",
       " 'p',\n",
       " '.',\n",
       " 'title',\n",
       " 'like',\n",
       " \"'\",\n",
       " '%',\n",
       " 'better',\n",
       " 'template',\n",
       " 'language',\n",
       " 'needed',\n",
       " '%',\n",
       " \"'\",\n",
       " ')',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:39:40.080777Z",
     "start_time": "2018-04-16T16:39:39.790329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS>   t_up select p . title , p . score , p . viewcount , p . answercount , p . commentcount , t_up len ( p . body ) as ques_size , p . favoritecount , p . i d , u . reputation as user_repo , u . creationdate as user_join_date , datediff ( t_up minute , p . creationdate , a . creationdate ) as qatimegap from posts as p , posts as a , users as u where p . i d = a . parentid and p . owneruserid = u . i d and a . creationdate = ( select min ( tau . creationdate ) from posts tau where tau . parentid = p . i d group by tau . parentid ) and ( p . title like \\' % recommended method for handling unsupportedencodingexception from string . getbytes ( \" t_up utf-8 \" ) % \\' or p . title like \\' % way to format strings with \" ? \" parameters to full string in java ? % \\' or p . title like \\' % how to parse a string without regular expressions % \\' or p . title like \\' % how to replace string only once without regex in java ? % \\' or p . title like \\' % efficiently removing specific characters ( some punctuation ) from strings in java ? % \\' or p . title like \\' % strings are immutable - that means i should never use + = and only stringbuffer ? % \\' or p . title like \\' % concatenation of strings and characters % \\' or p . title like \\' % java - convert integer to string % \\' or p . title like \\' % function to remove duplicate characters in a string % \\' or p . title like \\' % better template language needed % \\' ) <EOS>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sql_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:00:21.265729Z",
     "start_time": "2018-04-16T16:58:59.575258Z"
    }
   },
   "outputs": [],
   "source": [
    "# To make all queries become one big chunk of text\n",
    "sql_queries = ''\n",
    "\n",
    "for query in sql_tok:\n",
    "    sql_queries += ' '.join(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:00:21.560232Z",
     "start_time": "2018-04-16T17:00:21.268737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9872518"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sql_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:00:21.967898Z",
     "start_time": "2018-04-16T17:00:21.563241Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(sql_queries, (DATA_PATH/'sql_queries.pkl').open('wb'))\n",
    "sql_queries = pickle.load((DATA_PATH/'sql_queries.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:02:11.667577Z",
     "start_time": "2018-04-16T17:02:10.486086Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Œ¥', 1),\n",
       " ('—ã', 1),\n",
       " ('€å', 1),\n",
       " ('ÿ™', 1),\n",
       " ('Ÿá', 1),\n",
       " ('‚úì', 1),\n",
       " ('·ªá', 1),\n",
       " ('„Åã', 1),\n",
       " ('Ôºü', 1),\n",
       " ('—é', 1),\n",
       " ('—ó', 1),\n",
       " ('—å', 1),\n",
       " ('‚Ç¨', 1),\n",
       " ('Â∫¶', 1),\n",
       " ('„ÄÖ', 1),\n",
       " ('Âàù', 1),\n",
       " ('„Åò', 1),\n",
       " ('„Åì', 1),\n",
       " ('„Çì', 1),\n",
       " ('„Å°', 1),\n",
       " ('„Å§', 1),\n",
       " ('„ÇÇ', 1),\n",
       " ('„Å£', 1),\n",
       " ('Áñ≤', 1),\n",
       " ('„Çå', 1),\n",
       " ('Êßò', 1),\n",
       " ('„Åß', 1),\n",
       " ('ÎåÄ', 1),\n",
       " ('ÎØº', 1),\n",
       " ('üòâ', 1),\n",
       " ('üò¢', 1),\n",
       " ('üòá', 1),\n",
       " ('üòè', 1),\n",
       " ('üòä', 1),\n",
       " ('üòÉ', 1),\n",
       " ('üòï', 1),\n",
       " ('üòö', 1),\n",
       " ('üòò', 1),\n",
       " ('üòé', 1),\n",
       " ('üòå', 1),\n",
       " ('üòû', 1),\n",
       " ('ÂÖ®', 1),\n",
       " ('ÈÉ®', 1),\n",
       " ('Êåá', 1),\n",
       " ('Â∞é', 1),\n",
       " ('Âõû', 1),\n",
       " ('Á≠î', 1),\n",
       " ('„Éô', 1),\n",
       " ('„Çπ', 1),\n",
       " ('„Éà', 1),\n",
       " ('„Ç¢', 1),\n",
       " ('„É≥', 1),\n",
       " ('„Çµ', 1),\n",
       " ('„Éº', 1),\n",
       " ('„Äê', 1),\n",
       " ('¬ø', 1),\n",
       " ('ÏõÉ', 1),\n",
       " ('Ïò∑', 1),\n",
       " ('‚ò∫', 1),\n",
       " ('‚òπ', 1),\n",
       " ('‚úî', 1),\n",
       " ('–º', 1),\n",
       " ('—Ü', 1),\n",
       " ('ŸÜ', 2),\n",
       " ('üçå', 2),\n",
       " ('—Ö', 2),\n",
       " ('üîê', 2),\n",
       " ('‚ô¶', 2),\n",
       " ('Â§±', 2),\n",
       " ('Á§º', 2),\n",
       " ('„ÇÅ', 2),\n",
       " ('„ÅØ', 2),\n",
       " ('‰∏ñ', 2),\n",
       " ('Ë©±', 2),\n",
       " ('„Çä', 2),\n",
       " ('Ïùè', 2),\n",
       " ('¬Ø', 2),\n",
       " ('Ìïú', 2),\n",
       " ('Íµ≠', 2),\n",
       " ('ƒÅ', 2),\n",
       " ('ƒì', 2),\n",
       " ('ƒ´', 2),\n",
       " ('≈ç', 2),\n",
       " ('≈´', 2),\n",
       " ('√¢', 2),\n",
       " ('√Æ', 2),\n",
       " ('√¥', 2),\n",
       " ('üòÇ', 2),\n",
       " ('„Åü', 2),\n",
       " ('Ëá¥', 2),\n",
       " ('Ë£ú', 2),\n",
       " ('Ë∂≥', 2),\n",
       " ('Ë≥á', 2),\n",
       " ('Êñô', 2),\n",
       " ('È†Ç', 2),\n",
       " ('„Åë', 2),\n",
       " ('—è', 3),\n",
       " ('‚Ñ¢', 3),\n",
       " ('≈Ç', 3),\n",
       " ('‚ùå', 3),\n",
       " ('„Å´', 3),\n",
       " ('≈ü', 3),\n",
       " ('√™', 3),\n",
       " ('≈æ', 3),\n",
       " ('Êéà', 3),\n",
       " ('ƒ±', 3),\n",
       " ('·îï', 3),\n",
       " ('·ñ∫', 3),\n",
       " ('·òé', 3),\n",
       " ('·ïä', 3),\n",
       " ('–¥', 4),\n",
       " ('√£', 4),\n",
       " ('≈°', 4),\n",
       " ('√ª', 4),\n",
       " ('„ÉÑ', 4),\n",
       " ('‚Äì', 4),\n",
       " ('–±', 4),\n",
       " ('„Å™', 4),\n",
       " ('\\u200b', 4),\n",
       " ('…£', 4),\n",
       " ('√≠', 4),\n",
       " ('„Åî', 4),\n",
       " ('„Åè', 4),\n",
       " ('„Å†', 4),\n",
       " ('„Åï', 4),\n",
       " ('„Åà', 4),\n",
       " ('√∫', 5),\n",
       " ('–ø', 5),\n",
       " ('–≤', 5),\n",
       " ('√ß', 5),\n",
       " ('√±', 5),\n",
       " ('œÉ', 6),\n",
       " ('–µ', 6),\n",
       " ('–∫', 6),\n",
       " ('‚Ä∞', 6),\n",
       " ('È°ò', 6),\n",
       " ('‚Ä¶', 7),\n",
       " ('—Ç', 7),\n",
       " ('„Å¶', 7),\n",
       " ('Êïô', 7),\n",
       " ('–Ω', 8),\n",
       " ('≈Ñ', 8),\n",
       " ('–ª', 8),\n",
       " ('ÿ¨', 9),\n",
       " ('ÿ≤', 9),\n",
       " ('ÿ¶', 9),\n",
       " ('–∏', 9),\n",
       " ('„Åä', 10),\n",
       " ('ÿ±', 11),\n",
       " ('√°', 11),\n",
       " ('„Åô', 11),\n",
       " ('ÿß', 12),\n",
       " ('√∂', 12),\n",
       " ('—Å', 12),\n",
       " ('√§', 12),\n",
       " ('„Åó', 12),\n",
       " ('„Åæ', 12),\n",
       " ('–æ', 13),\n",
       " ('„ÅÑ', 13),\n",
       " ('—Ä', 15),\n",
       " ('—É', 15),\n",
       " ('‚òÖ', 15),\n",
       " ('\\n', 16),\n",
       " ('√†', 16),\n",
       " ('Œº', 18),\n",
       " ('√≥', 18),\n",
       " ('–∞', 23),\n",
       " ('√©', 26),\n",
       " ('~', 27),\n",
       " ('√º', 40),\n",
       " ('}', 52),\n",
       " ('Ãá', 66),\n",
       " ('`', 74),\n",
       " ('{', 82),\n",
       " ('$', 96),\n",
       " ('\\\\', 127),\n",
       " ('&', 178),\n",
       " ('|', 387),\n",
       " ('^', 396),\n",
       " ('!', 874),\n",
       " ('z', 1870),\n",
       " ('?', 2064),\n",
       " ('\"', 4006),\n",
       " (':', 5683),\n",
       " ('8', 6352),\n",
       " ('7', 6515),\n",
       " ('9', 7531),\n",
       " ('+', 8153),\n",
       " ('6', 8581),\n",
       " (';', 8643),\n",
       " ('/', 9684),\n",
       " ('x', 10305),\n",
       " ('4', 11825),\n",
       " ('3', 14262),\n",
       " ('5', 14733),\n",
       " ('*', 15564),\n",
       " ('-', 16019),\n",
       " ('@', 17912),\n",
       " ('j', 21618),\n",
       " ('%', 24328),\n",
       " ('B', 24594),\n",
       " ('E', 24594),\n",
       " ('q', 25290),\n",
       " (']', 26050),\n",
       " ('[', 26096),\n",
       " ('2', 33888),\n",
       " ('k', 37551),\n",
       " ('#', 38238),\n",
       " ('O', 49188),\n",
       " ('S', 49188),\n",
       " ('v', 54613),\n",
       " ('<', 58334),\n",
       " ('1', 58802),\n",
       " ('b', 59065),\n",
       " ('=', 61673),\n",
       " ('f', 62161),\n",
       " ('>', 63054),\n",
       " ('0', 65167),\n",
       " ('h', 80032),\n",
       " ('g', 83064),\n",
       " ('y', 84838),\n",
       " (\"'\", 90787),\n",
       " ('w', 91005),\n",
       " ('(', 98963),\n",
       " (')', 98969),\n",
       " ('m', 121105),\n",
       " (',', 125960),\n",
       " ('.', 143166),\n",
       " ('l', 162204),\n",
       " ('c', 212782),\n",
       " ('_', 214739),\n",
       " ('d', 303616),\n",
       " ('i', 322674),\n",
       " ('n', 361281),\n",
       " ('r', 366033),\n",
       " ('u', 376448),\n",
       " ('a', 408122),\n",
       " ('p', 432776),\n",
       " ('o', 436609),\n",
       " ('s', 486978),\n",
       " ('e', 642129),\n",
       " ('t', 744501),\n",
       " (' ', 2347463)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for p in sql_queries)\n",
    "sorted(freq.items(), key=lambda pair: pair[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:03:33.182078Z",
     "start_time": "2018-04-16T17:03:32.905831Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'B',\n",
       " 'E',\n",
       " 'O',\n",
       " 'S',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '¬Ø',\n",
       " '¬ø',\n",
       " '√†',\n",
       " '√°',\n",
       " '√¢',\n",
       " '√£',\n",
       " '√§',\n",
       " '√ß',\n",
       " '√©',\n",
       " '√™',\n",
       " '√≠',\n",
       " '√Æ',\n",
       " '√±',\n",
       " '√≥',\n",
       " '√¥',\n",
       " '√∂',\n",
       " '√∫',\n",
       " '√ª',\n",
       " '√º',\n",
       " 'ƒÅ',\n",
       " 'ƒì',\n",
       " 'ƒ´',\n",
       " 'ƒ±',\n",
       " '≈Ç',\n",
       " '≈Ñ',\n",
       " '≈ç',\n",
       " '≈ü',\n",
       " '≈°',\n",
       " '≈´',\n",
       " '≈æ',\n",
       " '…£',\n",
       " 'Ãá',\n",
       " 'Œ¥',\n",
       " 'Œº',\n",
       " 'œÉ',\n",
       " '–∞',\n",
       " '–±',\n",
       " '–≤',\n",
       " '–¥',\n",
       " '–µ',\n",
       " '–∏',\n",
       " '–∫',\n",
       " '–ª',\n",
       " '–º',\n",
       " '–Ω',\n",
       " '–æ',\n",
       " '–ø',\n",
       " '—Ä',\n",
       " '—Å',\n",
       " '—Ç',\n",
       " '—É',\n",
       " '—Ö',\n",
       " '—Ü',\n",
       " '—ã',\n",
       " '—å',\n",
       " '—é',\n",
       " '—è',\n",
       " '—ó',\n",
       " 'ÿ¶',\n",
       " 'ÿß',\n",
       " 'ÿ™',\n",
       " 'ÿ¨',\n",
       " 'ÿ±',\n",
       " 'ÿ≤',\n",
       " 'ŸÜ',\n",
       " 'Ÿá',\n",
       " '€å',\n",
       " '·îï',\n",
       " '·ïä',\n",
       " '·ñ∫',\n",
       " '·òé',\n",
       " '·ªá',\n",
       " '\\u200b',\n",
       " '‚Äì',\n",
       " '‚Ä¶',\n",
       " '‚Ä∞',\n",
       " '‚Ç¨',\n",
       " '‚Ñ¢',\n",
       " '‚òÖ',\n",
       " '‚òπ',\n",
       " '‚ò∫',\n",
       " '‚ô¶',\n",
       " '‚úì',\n",
       " '‚úî',\n",
       " '‚ùå',\n",
       " '„ÄÖ',\n",
       " '„Äê',\n",
       " '„ÅÑ',\n",
       " '„Åà',\n",
       " '„Åä',\n",
       " '„Åã',\n",
       " '„Åè',\n",
       " '„Åë',\n",
       " '„Åì',\n",
       " '„Åî',\n",
       " '„Åï',\n",
       " '„Åó',\n",
       " '„Åò',\n",
       " '„Åô',\n",
       " '„Åü',\n",
       " '„Å†',\n",
       " '„Å°',\n",
       " '„Å£',\n",
       " '„Å§',\n",
       " '„Å¶',\n",
       " '„Åß',\n",
       " '„Å™',\n",
       " '„Å´',\n",
       " '„ÅØ',\n",
       " '„Åæ',\n",
       " '„ÇÅ',\n",
       " '„ÇÇ',\n",
       " '„Çä',\n",
       " '„Çå',\n",
       " '„Çì',\n",
       " '„Ç¢',\n",
       " '„Çµ',\n",
       " '„Çπ',\n",
       " '„ÉÑ',\n",
       " '„Éà',\n",
       " '„Éô',\n",
       " '„É≥',\n",
       " '„Éº',\n",
       " '‰∏ñ',\n",
       " 'ÂÖ®',\n",
       " 'Âàù',\n",
       " 'Âõû',\n",
       " 'Â§±',\n",
       " 'Â∞é',\n",
       " 'Â∫¶',\n",
       " 'Êåá',\n",
       " 'Êéà',\n",
       " 'Êïô',\n",
       " 'Êñô',\n",
       " 'Êßò',\n",
       " 'Áñ≤',\n",
       " 'Á§º',\n",
       " 'Á≠î',\n",
       " 'Ëá¥',\n",
       " 'Ë£ú',\n",
       " 'Ë©±',\n",
       " 'Ë≥á',\n",
       " 'Ë∂≥',\n",
       " 'ÈÉ®',\n",
       " 'È†Ç',\n",
       " 'È°ò',\n",
       " 'Íµ≠',\n",
       " 'ÎåÄ',\n",
       " 'ÎØº',\n",
       " 'Ïò∑',\n",
       " 'ÏõÉ',\n",
       " 'Ïùè',\n",
       " 'Ìïú',\n",
       " 'Ôºü',\n",
       " 'üçå',\n",
       " 'üîê',\n",
       " 'üòÇ',\n",
       " 'üòÉ',\n",
       " 'üòá',\n",
       " 'üòâ',\n",
       " 'üòä',\n",
       " 'üòå',\n",
       " 'üòé',\n",
       " 'üòè',\n",
       " 'üòï',\n",
       " 'üòò',\n",
       " 'üòö',\n",
       " 'üòû',\n",
       " 'üò¢']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T17:03:24.596765Z",
     "start_time": "2018-04-16T17:03:24.201374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 244\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(sql_queries)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:07:58.942645Z",
     "start_time": "2018-04-16T16:07:58.812290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:07:59.316640Z",
     "start_time": "2018-04-16T16:07:59.165231Z"
    }
   },
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* will be the data we use from now on - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:07:59.760873Z",
     "start_time": "2018-04-16T16:07:59.537249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:07:59.907270Z",
     "start_time": "2018-04-16T16:07:59.762878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:00.791359Z",
     "start_time": "2018-04-16T16:08:00.533157Z"
    }
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:00.950143Z",
     "start_time": "2018-04-16T16:08:00.793366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([40, 30, 29, 1, 40, 43, 31, 61, 2, 74],\n",
       " [42, 25, 1, 43, 40, 33, 2, 54, 44, 73],\n",
       " [29, 27, 1, 45, 39, 38, 73, 73, 71, 61])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c1_dat[:10],\n",
    "c2_dat[:10],\n",
    "c3_dat[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:20.829517Z",
     "start_time": "2018-04-16T16:08:19.253703Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.492540Z",
     "start_time": "2018-04-16T16:08:20.831618Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.638438Z",
     "start_time": "2018-04-16T16:08:21.494547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 29, 1, 40, 43, 31, 61, 2, 74, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_dat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.800874Z",
     "start_time": "2018-04-16T16:08:21.640443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40, 43, 31, 61,  2, 74,  2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:21.958322Z",
     "start_time": "2018-04-16T16:08:21.803882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.158868Z",
     "start_time": "2018-04-16T16:08:21.963337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.321815Z",
     "start_time": "2018-04-16T16:08:22.161878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a size for our hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:22.751514Z",
     "start_time": "2018-04-16T16:08:22.595075Z"
    }
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:23.229838Z",
     "start_time": "2018-04-16T16:08:23.074416Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:23.522651Z",
     "start_time": "2018-04-16T16:08:23.327119Z"
    }
   },
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:27.292423Z",
     "start_time": "2018-04-16T16:08:27.165101Z"
    }
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:48.425828Z",
     "start_time": "2018-04-15T11:53:41.563928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce 930M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:50.126428Z",
     "start_time": "2018-04-15T11:53:48.428856Z"
    }
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:53:50.604613Z",
     "start_time": "2018-04-15T11:53:50.128574Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:00.574650Z",
     "start_time": "2018-04-15T11:53:50.608823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac35f38d4b549df9fc3343ea47cce67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.073258   1.163918  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1639175415039062]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:01.004095Z",
     "start_time": "2018-04-15T11:54:00.577239Z"
    }
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:18.055368Z",
     "start_time": "2018-04-15T11:54:17.643725Z"
    }
   },
   "outputs": [],
   "source": [
    "??set_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:54:10.979726Z",
     "start_time": "2018-04-15T11:54:01.010111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f78a1783fd14111b0594417353e426a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.824655   0.631769  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6317691802978516]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:50.135680Z",
     "start_time": "2018-04-16T16:08:49.997305Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:08:54.148847Z",
     "start_time": "2018-04-16T16:08:50.483440Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NokChan\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce 930M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3569d09dd14a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y. '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-c90156cc3c5a>\u001b[0m in \u001b[0;36mget_next\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mVV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_np\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:03.223960Z",
     "start_time": "2018-04-15T11:56:02.771920Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('ppl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:07.111853Z",
     "start_time": "2018-04-15T11:56:06.665958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:56:09.197401Z",
     "start_time": "2018-04-15T11:56:08.761506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:07.868386Z",
     "start_time": "2018-04-16T16:09:07.742508Z"
    }
   },
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:12.824017Z",
     "start_time": "2018-04-16T16:09:11.191983Z"
    }
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:13.085723Z",
     "start_time": "2018-04-16T16:09:12.824017Z"
    }
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:15.554362Z",
     "start_time": "2018-04-16T16:09:13.465950Z"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:15.732853Z",
     "start_time": "2018-04-16T16:09:15.557372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, ..., 27, 29,  1],\n",
       "       [42, 29, 30, ..., 29,  1,  1],\n",
       "       [29, 30, 25, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [72, 62, 67, ..., 65, 67, 58],\n",
       "       [62, 67, 59, ..., 67, 58, 72],\n",
       "       [67, 59, 74, ..., 58, 72, 72]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:15.879248Z",
     "start_time": "2018-04-16T16:09:15.735861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600885, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:17.277565Z",
     "start_time": "2018-04-16T16:09:15.882257Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:17.441548Z",
     "start_time": "2018-04-16T16:09:17.277565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 43, ..., 72, 72, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:17.578916Z",
     "start_time": "2018-04-16T16:09:17.444555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
       "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
       "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
       "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
       "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
       "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:19.869886Z",
     "start_time": "2018-04-16T16:09:19.743446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:20.721141Z",
     "start_time": "2018-04-16T16:09:20.575831Z"
    }
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:21.206845Z",
     "start_time": "2018-04-16T16:09:21.021347Z"
    }
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:21.549765Z",
     "start_time": "2018-04-16T16:09:21.400855Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:22.288818Z",
     "start_time": "2018-04-16T16:09:22.144925Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:09:30.182422Z",
     "start_time": "2018-04-16T16:09:29.373050Z"
    }
   },
   "outputs": [],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:58:39.070256Z",
     "start_time": "2018-04-15T11:57:54.655244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc371984f434afb940cd30f69e044f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.007229   1.989802  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9898024265275085]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:58:39.575117Z",
     "start_time": "2018-04-15T11:58:39.075077Z"
    }
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T11:59:23.830603Z",
     "start_time": "2018-04-15T11:58:39.579629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ea8495c6e341bab8d1f6dcfa8a800c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.728301   1.714505  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7145047643787454]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:10:35.111474Z",
     "start_time": "2018-04-16T16:10:34.951537Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-99771947f5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bs' is not defined"
     ]
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:00.642963Z",
     "start_time": "2018-04-16T16:14:00.496566Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            print(h.size())\n",
    "            print(c.size())\n",
    "            print(self.e(c).size())\n",
    "            print(c)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:01.665675Z",
     "start_time": "2018-04-16T16:14:00.741015Z"
    }
   },
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T16:14:02.288537Z",
     "start_time": "2018-04-16T16:14:01.665675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      "  1\n",
      "  9\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 36\n",
      " 67\n",
      " 71\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 67\n",
      " 63\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 23\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 73\n",
      " 58\n",
      " 72\n",
      " 74\n",
      "  2\n",
      "  1\n",
      " 73\n",
      " 67\n",
      " 56\n",
      " 68\n",
      " 61\n",
      " 61\n",
      " 58\n",
      " 68\n",
      " 72\n",
      "  2\n",
      "  1\n",
      " 58\n",
      " 58\n",
      " 73\n",
      " 21\n",
      " 72\n",
      " 62\n",
      " 67\n",
      " 67\n",
      " 59\n",
      " 65\n",
      " 72\n",
      " 78\n",
      " 72\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 47\n",
      "  2\n",
      " 68\n",
      " 62\n",
      " 54\n",
      " 56\n",
      " 68\n",
      " 54\n",
      " 72\n",
      "  1\n",
      " 59\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 68\n",
      " 73\n",
      " 54\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 62\n",
      " 68\n",
      " 56\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 71\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 54\n",
      " 10\n",
      " 58\n",
      " 65\n",
      " 58\n",
      " 33\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 67\n",
      " 73\n",
      " 67\n",
      " 72\n",
      " 65\n",
      " 56\n",
      " 67\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 61\n",
      " 59\n",
      " 67\n",
      " 73\n",
      " 67\n",
      " 67\n",
      " 72\n",
      " 10\n",
      " 58\n",
      "  8\n",
      "  2\n",
      " 68\n",
      " 66\n",
      " 54\n",
      " 60\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 73\n",
      " 69\n",
      " 10\n",
      " 62\n",
      " 68\n",
      " 59\n",
      " 62\n",
      " 72\n",
      " 60\n",
      " 55\n",
      " 68\n",
      "  2\n",
      " 37\n",
      "  2\n",
      " 68\n",
      " 54\n",
      " 62\n",
      "  8\n",
      " 77\n",
      " 71\n",
      " 62\n",
      " 58\n",
      " 65\n",
      " 73\n",
      " 72\n",
      " 74\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 66\n",
      " 71\n",
      " 71\n",
      " 67\n",
      " 65\n",
      " 74\n",
      " 68\n",
      " 61\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 56\n",
      " 75\n",
      " 54\n",
      " 72\n",
      "  2\n",
      " 67\n",
      " 67\n",
      " 10\n",
      " 57\n",
      " 72\n",
      " 66\n",
      " 67\n",
      " 59\n",
      " 69\n",
      " 65\n",
      " 56\n",
      " 58\n",
      "  8\n",
      " 66\n",
      " 68\n",
      " 10\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 75\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 24\n",
      " 58\n",
      " 55\n",
      " 72\n",
      " 62\n",
      " 22\n",
      " 58\n",
      " 54\n",
      " 54\n",
      " 72\n",
      " 66\n",
      " 57\n",
      "  2\n",
      " 55\n",
      "  8\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 73\n",
      " 10\n",
      " 56\n",
      " 64\n",
      " 73\n",
      " 72\n",
      " 62\n",
      " 61\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 78\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 25\n",
      " 67\n",
      "  2\n",
      " 71\n",
      " 59\n",
      " 54\n",
      " 73\n",
      "  1\n",
      "  2\n",
      "  1\n",
      "  1\n",
      " 71\n",
      " 58\n",
      " 71\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 62\n",
      "  2\n",
      " 72\n",
      " 71\n",
      " 69\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 68\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 72\n",
      " 59\n",
      " 58\n",
      " 76\n",
      " 56\n",
      " 58\n",
      " 68\n",
      " 60\n",
      " 71\n",
      " 65\n",
      " 61\n",
      " 67\n",
      " 59\n",
      " 73\n",
      " 58\n",
      " 72\n",
      " 78\n",
      " 68\n",
      " 65\n",
      " 72\n",
      " 54\n",
      "  2\n",
      " 57\n",
      " 73\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 72\n",
      " 66\n",
      " 54\n",
      " 58\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 61\n",
      " 54\n",
      "  2\n",
      "  8\n",
      " 67\n",
      " 72\n",
      " 58\n",
      " 60\n",
      " 65\n",
      " 58\n",
      " 66\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 76\n",
      " 68\n",
      " 56\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 59\n",
      " 71\n",
      " 61\n",
      " 68\n",
      " 67\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 61\n",
      " 65\n",
      " 55\n",
      " 73\n",
      " 55\n",
      " 71\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 44\n",
      " 73\n",
      " 60\n",
      "  9\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 78\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 31\n",
      "  8\n",
      " 60\n",
      " 78\n",
      " 72\n",
      " 68\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 68\n",
      " 58\n",
      " 65\n",
      " 71\n",
      " 59\n",
      " 68\n",
      " 58\n",
      " 56\n",
      " 74\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 72\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 73\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 65\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 61\n",
      " 58\n",
      " 57\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 34\n",
      " 78\n",
      " 59\n",
      " 56\n",
      " 67\n",
      "  2\n",
      " 65\n",
      " 75\n",
      " 55\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 61\n",
      " 74\n",
      "  1\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 78\n",
      " 71\n",
      " 57\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 72\n",
      " 62\n",
      " 72\n",
      " 60\n",
      " 76\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 24\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 57\n",
      " 54\n",
      " 57\n",
      " 57\n",
      " 68\n",
      " 56\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 54\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 67\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 58\n",
      " 68\n",
      " 75\n",
      " 54\n",
      " 68\n",
      " 57\n",
      " 66\n",
      " 44\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 73\n",
      " 69\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 78\n",
      " 72\n",
      " 74\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  4\n",
      " 57\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 54\n",
      "  3\n",
      " 54\n",
      " 71\n",
      " 67\n",
      " 69\n",
      " 54\n",
      " 59\n",
      " 54\n",
      "  4\n",
      " 57\n",
      " 69\n",
      " 44\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 72\n",
      "  9\n",
      " 61\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 60\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 55\n",
      " 75\n",
      " 70\n",
      "  2\n",
      " 68\n",
      " 64\n",
      " 59\n",
      "  1\n",
      " 46\n",
      " 68\n",
      " 78\n",
      " 70\n",
      " 58\n",
      " 71\n",
      " 65\n",
      " 73\n",
      " 67\n",
      " 73\n",
      "  1\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 74\n",
      " 54\n",
      " 58\n",
      " 71\n",
      " 72\n",
      " 68\n",
      " 73\n",
      "  1\n",
      " 65\n",
      " 72\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 59\n",
      "  8\n",
      "  2\n",
      " 69\n",
      " 54\n",
      " 68\n",
      " 73\n",
      " 32\n",
      " 62\n",
      " 55\n",
      " 71\n",
      " 65\n",
      " 71\n",
      " 62\n",
      "  8\n",
      " 71\n",
      "  2\n",
      " 68\n",
      "  8\n",
      " 71\n",
      " 58\n",
      " 60\n",
      " 74\n",
      " 73\n",
      " 73\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 54\n",
      " 71\n",
      " 57\n",
      " 71\n",
      " 58\n",
      " 57\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 68\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 61\n",
      " 73\n",
      " 72\n",
      "  4\n",
      "  8\n",
      " 54\n",
      " 67\n",
      " 42\n",
      " 62\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 61\n",
      " 57\n",
      " 73\n",
      " 57\n",
      " 64\n",
      " 60\n",
      " 61\n",
      " 54\n",
      " 58\n",
      " 58\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 58\n",
      "  8\n",
      "  2\n",
      "  1\n",
      "  4\n",
      " 61\n",
      " 59\n",
      " 68\n",
      " 67\n",
      "  2\n",
      " 67\n",
      " 65\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 23\n",
      " 73\n",
      " 59\n",
      "  1\n",
      " 67\n",
      " 58\n",
      " 65\n",
      " 65\n",
      "  1\n",
      " 56\n",
      " 68\n",
      " 69\n",
      " 74\n",
      " 71\n",
      " 75\n",
      "  2\n",
      " 54\n",
      " 58\n",
      " 73\n",
      " 71\n",
      " 62\n",
      " 65\n",
      " 73\n",
      " 72\n",
      " 33\n",
      "  2\n",
      " 54\n",
      " 72\n",
      "  3\n",
      " 58\n",
      " 69\n",
      " 68\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 76\n",
      " 58\n",
      "  1\n",
      " 73\n",
      " 68\n",
      " 55\n",
      " 58\n",
      " 73\n",
      " 58\n",
      " 58\n",
      " 72\n",
      "  8\n",
      " 59\n",
      " 65\n",
      " 57\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 58\n",
      " 61\n",
      " 75\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 67\n",
      "  2\n",
      " 72\n",
      " 73\n",
      " 76\n",
      " 58\n",
      " 70\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 61\n",
      " 71\n",
      "  2\n",
      " 71\n",
      " 65\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 71\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 78\n",
      " 58\n",
      " 58\n",
      "  4\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  7\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 54\n",
      " 58\n",
      " 73\n",
      " 65\n",
      " 72\n",
      "  1\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 44\n",
      " 73\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 56\n",
      "  8\n",
      " 67\n",
      " 62\n",
      "  1\n",
      " 73\n",
      " 68\n",
      " 67\n",
      " 62\n",
      " 66\n",
      " 55\n",
      "  2\n",
      " 72\n",
      " 37\n",
      " 78\n",
      " 54\n",
      " 72\n",
      " 71\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 72\n",
      " 44\n",
      "  2\n",
      " 71\n",
      " 72\n",
      " 66\n",
      " 76\n",
      " 73\n",
      "  2\n",
      " 10\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 67\n",
      " 67\n",
      "  2\n",
      " 68\n",
      "  4\n",
      " 58\n",
      " 64\n",
      "  2\n",
      " 78\n",
      " 72\n",
      " 73\n",
      "  2\n",
      " 75\n",
      " 59\n",
      " 58\n",
      " 66\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 54\n",
      " 71\n",
      "  1\n",
      " 30\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 68\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 39\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 65\n",
      " 71\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 60\n",
      " 61\n",
      " 73\n",
      " 68\n",
      " 78\n",
      " 67\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 57\n",
      " 72\n",
      "  2\n",
      "  8\n",
      " 54\n",
      " 54\n",
      " 58\n",
      " 62\n",
      " 72\n",
      " 62\n",
      " 60\n",
      " 57\n",
      " 76\n",
      " 61\n",
      " 62\n",
      " 62\n",
      "  9\n",
      " 73\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 71\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 60\n",
      "  1\n",
      " 68\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 73\n",
      " 71\n",
      " 58\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 66\n",
      " 76\n",
      "  2\n",
      " 73\n",
      " 59\n",
      " 72\n",
      "  2\n",
      " 61\n",
      " 65\n",
      " 59\n",
      " 58\n",
      " 68\n",
      " 57\n",
      " 62\n",
      " 67\n",
      " 28\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 62\n",
      " 56\n",
      " 65\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 76\n",
      " 71\n",
      " 61\n",
      " 45\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 56\n",
      " 54\n",
      " 65\n",
      " 58\n",
      " 58\n",
      " 72\n",
      " 62\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 73\n",
      " 69\n",
      "  2\n",
      " 62\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 72\n",
      " 60\n",
      " 21\n",
      " 66\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      "  8\n",
      " 67\n",
      " 54\n",
      "  2\n",
      " 60\n",
      "  2\n",
      " 65\n",
      " 78\n",
      " 66\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 61\n",
      " 68\n",
      " 62\n",
      " 57\n",
      " 72\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 65\n",
      " 71\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 43\n",
      " 66\n",
      " 57\n",
      " 67\n",
      " 61\n",
      " 71\n",
      " 66\n",
      " 72\n",
      " 54\n",
      " 22\n",
      "  1\n",
      " 56\n",
      " 60\n",
      " 74\n",
      " 71\n",
      "  2\n",
      "  2\n",
      "  4\n",
      "  2\n",
      " 33\n",
      " 68\n",
      "  1\n",
      " 67\n",
      " 60\n",
      " 57\n",
      " 58\n",
      " 56\n",
      " 59\n",
      " 56\n",
      " 60\n",
      "  2\n",
      " 58\n",
      " 68\n",
      "  2\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 58\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 54\n",
      " 76\n",
      "  2\n",
      "  2\n",
      " 56\n",
      " 61\n",
      " 58\n",
      " 58\n",
      " 74\n",
      " 73\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 66\n",
      " 62\n",
      " 67\n",
      " 58\n",
      " 74\n",
      " 72\n",
      " 74\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  1\n",
      " 66\n",
      " 58\n",
      " 58\n",
      " 67\n",
      " 73\n",
      "  1\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 23\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 73\n",
      " 62\n",
      " 57\n",
      " 57\n",
      " 55\n",
      " 68\n",
      " 22\n",
      "  2\n",
      " 54\n",
      " 62\n",
      " 73\n",
      " 67\n",
      " 74\n",
      " 68\n",
      " 65\n",
      " 78\n",
      " 54\n",
      " 65\n",
      "  2\n",
      " 57\n",
      "  2\n",
      " 56\n",
      " 55\n",
      " 56\n",
      "  2\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 58\n",
      " 61\n",
      " 58\n",
      " 74\n",
      " 62\n",
      " 73\n",
      " 61\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 72\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 68\n",
      " 67\n",
      " 54\n",
      " 61\n",
      "  2\n",
      "  1\n",
      "  2\n",
      " 72\n",
      " 56\n",
      " 39\n",
      " 67\n",
      " 68\n",
      " 60\n",
      " 68\n",
      "  2\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 76\n",
      " 58\n",
      " 58\n",
      " 72\n",
      " 75\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 67\n",
      " 57\n",
      "  2\n",
      " 39\n",
      " 69\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 57\n",
      " 68\n",
      " 57\n",
      "  8\n",
      " 69\n",
      " 58\n",
      " 71\n",
      "  9\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 57\n",
      " 65\n",
      " 68\n",
      " 58\n",
      " 69\n",
      " 74\n",
      " 57\n",
      " 71\n",
      " 60\n",
      " 73\n",
      " 58\n",
      " 54\n",
      " 66\n",
      " 56\n",
      " 72\n",
      " 76\n",
      " 58\n",
      " 78\n",
      " 74\n",
      " 54\n",
      " 59\n",
      " 73\n",
      " 67\n",
      " 73\n",
      "  2\n",
      "  2\n",
      " 65\n",
      " 74\n",
      " 54\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 55\n",
      " 78\n",
      "  8\n",
      "  2\n",
      "  1\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 78\n",
      "  1\n",
      " 29\n",
      " 58\n",
      " 65\n",
      " 72\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 72\n",
      " 56\n",
      " 33\n",
      " 76\n",
      " 61\n",
      " 61\n",
      " 72\n",
      " 74\n",
      " 57\n",
      " 61\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 58\n",
      " 58\n",
      " 54\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 55\n",
      " 59\n",
      " 57\n",
      " 78\n",
      " 71\n",
      " 22\n",
      "  8\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 65\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 73\n",
      " 60\n",
      " 72\n",
      " 73\n",
      " 73\n",
      " 45\n",
      " 58\n",
      " 61\n",
      " 54\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 12\n",
      " 62\n",
      " 65\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 75\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 71\n",
      "  2\n",
      "  8\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 54\n",
      " 61\n",
      " 76\n",
      " 65\n",
      " 74\n",
      " 55\n",
      " 62\n",
      " 61\n",
      " 54\n",
      "  7\n",
      " 57\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 74\n",
      " 21\n",
      "  2\n",
      "  2\n",
      " 66\n",
      "  8\n",
      "  2\n",
      " 71\n",
      " 54\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 54\n",
      " 54\n",
      " 58\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 68\n",
      " 68\n",
      "  8\n",
      " 68\n",
      " 67\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 72\n",
      " 73\n",
      " 67\n",
      " 54\n",
      " 76\n",
      " 73\n",
      " 78\n",
      " 58\n",
      " 73\n",
      " 68\n",
      " 72\n",
      " 75\n",
      " 61\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 61\n",
      " 66\n",
      "  2\n",
      " 57\n",
      " 68\n",
      " 54\n",
      " 62\n",
      " 67\n",
      " 62\n",
      "  2\n",
      " 68\n",
      " 38\n",
      "  2\n",
      " 73\n",
      " 55\n",
      " 56\n",
      " 68\n",
      " 62\n",
      " 73\n",
      "  1\n",
      " 74\n",
      " 68\n",
      " 62\n",
      " 67\n",
      " 72\n",
      " 62\n",
      " 61\n",
      " 74\n",
      " 54\n",
      " 76\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 60\n",
      " 62\n",
      " 73\n",
      " 65\n",
      " 71\n",
      " 76\n",
      " 57\n",
      " 61\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 57\n",
      "  1\n",
      "  9\n",
      " 68\n",
      "  5\n",
      " 74\n",
      "  1\n",
      " 67\n",
      "  2\n",
      " 33\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 68\n",
      " 71\n",
      " 67\n",
      " 56\n",
      " 56\n",
      " 71\n",
      " 61\n",
      " 66\n",
      " 58\n",
      " 31\n",
      " 73\n",
      " 71\n",
      " 72\n",
      " 58\n",
      " 67\n",
      " 68\n",
      " 71\n",
      " 56\n",
      " 68\n",
      " 60\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 71\n",
      " 73\n",
      " 66\n",
      " 54\n",
      " 65\n",
      " 66\n",
      " 61\n",
      " 73\n",
      " 58\n",
      "  1\n",
      " 72\n",
      " 68\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 61\n",
      " 57\n",
      " 33\n",
      "  2\n",
      " 69\n",
      " 66\n",
      " 62\n",
      " 65\n",
      " 73\n",
      "  2\n",
      " 68\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 62\n",
      " 74\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 66\n",
      "  8\n",
      " 58\n",
      " 76\n",
      " 58\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 78\n",
      " 70\n",
      " 60\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 69\n",
      " 54\n",
      " 62\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 74\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 60\n",
      " 54\n",
      "  2\n",
      " 24\n",
      "  2\n",
      " 51\n",
      " 72\n",
      " 60\n",
      " 59\n",
      " 67\n",
      " 71\n",
      "  1\n",
      " 57\n",
      " 74\n",
      " 71\n",
      " 65\n",
      " 65\n",
      " 62\n",
      " 56\n",
      " 68\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 73\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 67\n",
      " 68\n",
      " 75\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 54\n",
      " 56\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 65\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 54\n",
      " 68\n",
      " 56\n",
      "  9\n",
      " 54\n",
      " 58\n",
      " 72\n",
      " 73\n",
      " 60\n",
      " 54\n",
      " 58\n",
      " 58\n",
      " 13\n",
      "  2\n",
      " 71\n",
      " 67\n",
      " 57\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 54\n",
      " 40\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 61\n",
      " 67\n",
      " 62\n",
      " 74\n",
      " 58\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 71\n",
      " 66\n",
      " 65\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 59\n",
      " 58\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 56\n",
      " 67\n",
      " 69\n",
      " 66\n",
      " 68\n",
      " 72\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 75\n",
      " 62\n",
      " 54\n",
      " 73\n",
      " 68\n",
      " 54\n",
      " 65\n",
      " 54\n",
      " 61\n",
      " 59\n",
      " 73\n",
      " 71\n",
      " 57\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 62\n",
      "  8\n",
      " 58\n",
      " 38\n",
      " 60\n",
      " 68\n",
      "  2\n",
      "  1\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 67\n",
      " 54\n",
      " 10\n",
      "  2\n",
      "  1\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 54\n",
      " 73\n",
      " 60\n",
      "  2\n",
      " 73\n",
      " 71\n",
      " 71\n",
      " 61\n",
      " 67\n",
      " 68\n",
      " 58\n",
      "  8\n",
      " 67\n",
      "  2\n",
      "  1\n",
      " 62\n",
      "  2\n",
      " 54\n",
      "  9\n",
      " 66\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 75\n",
      " 76\n",
      "  1\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 68\n",
      " 61\n",
      " 62\n",
      "  2\n",
      " 72\n",
      " 69\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 72\n",
      "  2\n",
      " 69\n",
      " 65\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 72\n",
      " 26\n",
      " 60\n",
      " 58\n",
      " 60\n",
      " 67\n",
      " 61\n",
      " 68\n",
      " 58\n",
      "  8\n",
      " 65\n",
      " 65\n",
      " 76\n",
      " 72\n",
      " 10\n",
      "  2\n",
      " 62\n",
      " 60\n",
      " 62\n",
      " 73\n",
      " 69\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 54\n",
      " 78\n",
      " 73\n",
      " 57\n",
      " 62\n",
      " 65\n",
      " 72\n",
      " 57\n",
      " 59\n",
      " 61\n",
      " 73\n",
      " 58\n",
      " 38\n",
      " 68\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 69\n",
      " 67\n",
      "  8\n",
      "  2\n",
      " 65\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 74\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 54\n",
      "  4\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 39\n",
      "  2\n",
      "  2\n",
      " 73\n",
      " 56\n",
      "  2\n",
      " 60\n",
      " 62\n",
      " 54\n",
      " 62\n",
      " 71\n",
      "  2\n",
      " 72\n",
      " 61\n",
      " 42\n",
      " 71\n",
      " 58\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 73\n",
      " 13\n",
      " 66\n",
      "  8\n",
      " 65\n",
      " 60\n",
      " 67\n",
      " 65\n",
      " 54\n",
      " 59\n",
      " 64\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 65\n",
      " 62\n",
      " 68\n",
      " 66\n",
      " 58\n",
      " 54\n",
      " 57\n",
      " 69\n",
      " 65\n",
      " 73\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 62\n",
      " 68\n",
      " 65\n",
      " 59\n",
      "  2\n",
      " 68\n",
      " 68\n",
      " 72\n",
      "  9\n",
      " 66\n",
      " 54\n",
      " 54\n",
      "  2\n",
      " 57\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 62\n",
      " 56\n",
      " 73\n",
      " 73\n",
      "  2\n",
      "  1\n",
      " 71\n",
      " 73\n",
      " 67\n",
      " 71\n",
      " 74\n",
      "  2\n",
      " 69\n",
      " 60\n",
      " 54\n",
      " 62\n",
      " 75\n",
      " 55\n",
      "  3\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 54\n",
      " 62\n",
      " 74\n",
      " 73\n",
      " 58\n",
      " 54\n",
      " 54\n",
      " 73\n",
      " 56\n",
      " 58\n",
      " 69\n",
      " 59\n",
      "  2\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 68\n",
      " 65\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 54\n",
      "  2\n",
      " 68\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 74\n",
      " 76\n",
      " 73\n",
      " 66\n",
      " 72\n",
      " 60\n",
      " 73\n",
      " 73\n",
      " 58\n",
      " 67\n",
      " 66\n",
      " 58\n",
      " 67\n",
      " 72\n",
      " 54\n",
      " 62\n",
      " 67\n",
      " 61\n",
      " 65\n",
      " 58\n",
      " 61\n",
      "  8\n",
      " 68\n",
      " 60\n",
      " 75\n",
      " 55\n",
      "  1\n",
      " 69\n",
      " 68\n",
      " 54\n",
      " 59\n",
      " 73\n",
      " 72\n",
      " 58\n",
      " 54\n",
      " 56\n",
      "  2\n",
      " 58\n",
      " 69\n",
      "  9\n",
      " 71\n",
      " 72\n",
      " 71\n",
      " 68\n",
      " 60\n",
      " 73\n",
      " 43\n",
      " 66\n",
      " 78\n",
      " 57\n",
      " 62\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 61\n",
      " 68\n",
      " 72\n",
      " 58\n",
      "  2\n",
      "  2\n",
      " 25\n",
      " 61\n",
      "  8\n",
      " 10\n",
      " 10\n",
      " 57\n",
      " 76\n",
      " 78\n",
      " 54\n",
      "  2\n",
      " 61\n",
      " 73\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 71\n",
      " 54\n",
      " 68\n",
      " 58\n",
      " 62\n",
      "  8\n",
      " 78\n",
      "  1\n",
      " 67\n",
      " 62\n",
      "  2\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 73\n",
      " 71\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 74\n",
      " 58\n",
      " 59\n",
      " 54\n",
      " 73\n",
      " 58\n",
      " 76\n",
      " 67\n",
      " 56\n",
      " 68\n",
      "  2\n",
      " 71\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 78\n",
      " 55\n",
      " 72\n",
      " 68\n",
      " 72\n",
      " 74\n",
      " 61\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 69\n",
      " 68\n",
      " 78\n",
      " 58\n",
      " 57\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 56\n",
      " 56\n",
      " 73\n",
      " 67\n",
      " 62\n",
      " 58\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 75\n",
      " 30\n",
      " 58\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 57\n",
      "  1\n",
      "  2\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 56\n",
      " 68\n",
      " 68\n",
      " 61\n",
      " 73\n",
      " 60\n",
      " 61\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 72\n",
      " 76\n",
      " 58\n",
      " 66\n",
      " 60\n",
      " 68\n",
      " 67\n",
      " 68\n",
      " 66\n",
      " 73\n",
      " 67\n",
      " 68\n",
      " 65\n",
      " 54\n",
      " 72\n",
      " 60\n",
      " 65\n",
      " 66\n",
      " 73\n",
      " 59\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 62\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 16\n",
      " 54\n",
      " 69\n",
      " 56\n",
      "  2\n",
      " 60\n",
      " 67\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 68\n",
      " 72\n",
      " 68\n",
      "  2\n",
      " 75\n",
      " 71\n",
      "  1\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 57\n",
      " 62\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 62\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 72\n",
      " 62\n",
      "  9\n",
      " 54\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 59\n",
      " 58\n",
      " 58\n",
      " 71\n",
      " 73\n",
      " 62\n",
      " 54\n",
      " 68\n",
      " 69\n",
      " 58\n",
      " 59\n",
      " 67\n",
      " 78\n",
      " 78\n",
      " 54\n",
      " 62\n",
      " 61\n",
      " 78\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 66\n",
      "  2\n",
      " 51\n",
      " 73\n",
      "  2\n",
      "  8\n",
      " 37\n",
      "  3\n",
      " 64\n",
      " 62\n",
      " 25\n",
      " 61\n",
      " 72\n",
      " 78\n",
      " 68\n",
      " 71\n",
      " 23\n",
      " 56\n",
      " 39\n",
      " 71\n",
      " 59\n",
      " 58\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 73\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 58\n",
      " 57\n",
      " 74\n",
      "  2\n",
      "  2\n",
      " 58\n",
      " 72\n",
      " 58\n",
      " 65\n",
      " 66\n",
      " 73\n",
      " 47\n",
      " 54\n",
      "  2\n",
      " 71\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 68\n",
      " 65\n",
      " 62\n",
      " 71\n",
      " 55\n",
      " 73\n",
      " 54\n",
      " 66\n",
      "  2\n",
      " 65\n",
      " 72\n",
      " 54\n",
      " 71\n",
      "  4\n",
      " 66\n",
      " 62\n",
      " 62\n",
      " 76\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 71\n",
      "  8\n",
      " 61\n",
      " 57\n",
      " 68\n",
      " 76\n",
      " 66\n",
      "  2\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 56\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 68\n",
      " 67\n",
      " 61\n",
      " 58\n",
      " 57\n",
      " 54\n",
      " 62\n",
      " 68\n",
      " 57\n",
      "  1\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 68\n",
      " 21\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 69\n",
      " 43\n",
      " 71\n",
      " 73\n",
      " 73\n",
      " 54\n",
      " 67\n",
      " 67\n",
      "  2\n",
      " 78\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 60\n",
      " 78\n",
      " 57\n",
      " 54\n",
      " 73\n",
      " 68\n",
      " 71\n",
      " 73\n",
      " 71\n",
      " 73\n",
      " 59\n",
      " 72\n",
      " 72\n",
      " 68\n",
      " 56\n",
      " 72\n",
      " 67\n",
      "  1\n",
      " 75\n",
      " 54\n",
      " 59\n",
      " 67\n",
      " 59\n",
      " 61\n",
      " 61\n",
      "  8\n",
      " 54\n",
      " 71\n",
      " 67\n",
      " 62\n",
      " 65\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 25\n",
      " 72\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 68\n",
      " 61\n",
      " 60\n",
      " 68\n",
      " 16\n",
      " 58\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 62\n",
      " 65\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 65\n",
      " 65\n",
      " 76\n",
      " 65\n",
      " 68\n",
      " 59\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 10\n",
      " 69\n",
      " 58\n",
      " 61\n",
      " 72\n",
      " 65\n",
      " 25\n",
      " 72\n",
      " 66\n",
      "  8\n",
      " 62\n",
      " 68\n",
      " 59\n",
      "  2\n",
      "  2\n",
      "  9\n",
      " 68\n",
      " 55\n",
      " 67\n",
      " 54\n",
      " 62\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 61\n",
      " 56\n",
      " 56\n",
      "  2\n",
      " 61\n",
      " 57\n",
      "  2\n",
      " 73\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 67\n",
      " 55\n",
      " 62\n",
      " 73\n",
      "  2\n",
      " 62\n",
      " 74\n",
      " 73\n",
      " 57\n",
      " 57\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 58\n",
      " 60\n",
      "  2\n",
      " 71\n",
      " 72\n",
      " 73\n",
      " 61\n",
      " 61\n",
      " 71\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 62\n",
      "  4\n",
      " 10\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 54\n",
      " 61\n",
      " 67\n",
      " 62\n",
      " 71\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 61\n",
      " 62\n",
      " 54\n",
      "  1\n",
      "  2\n",
      "  2\n",
      "  2\n",
      "  1\n",
      " 54\n",
      " 58\n",
      " 71\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 75\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 76\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 75\n",
      " 68\n",
      " 72\n",
      " 76\n",
      " 59\n",
      " 76\n",
      " 58\n",
      " 70\n",
      " 72\n",
      " 74\n",
      " 72\n",
      " 65\n",
      " 71\n",
      " 73\n",
      "  2\n",
      "  1\n",
      "  1\n",
      " 67\n",
      "  1\n",
      " 61\n",
      " 44\n",
      " 62\n",
      "  2\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 74\n",
      " 61\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 66\n",
      " 73\n",
      " 67\n",
      " 73\n",
      " 64\n",
      " 44\n",
      " 58\n",
      "  2\n",
      "  2\n",
      "  2\n",
      "  1\n",
      "  8\n",
      " 73\n",
      " 74\n",
      " 56\n",
      " 73\n",
      " 71\n",
      " 64\n",
      " 59\n",
      " 57\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 56\n",
      " 56\n",
      " 66\n",
      " 68\n",
      "  2\n",
      " 58\n",
      " 59\n",
      " 65\n",
      " 68\n",
      " 62\n",
      " 61\n",
      " 72\n",
      " 54\n",
      "  2\n",
      " 61\n",
      " 62\n",
      " 62\n",
      "  2\n",
      " 59\n",
      " 54\n",
      " 58\n",
      " 72\n",
      "  8\n",
      "  2\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 56\n",
      " 74\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 69\n",
      "  2\n",
      "  2\n",
      " 58\n",
      "  1\n",
      " 59\n",
      " 73\n",
      " 54\n",
      "  1\n",
      " 54\n",
      " 66\n",
      " 30\n",
      " 69\n",
      " 71\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 78\n",
      " 10\n",
      "  1\n",
      " 54\n",
      " 61\n",
      " 61\n",
      " 65\n",
      " 72\n",
      " 67\n",
      " 62\n",
      " 67\n",
      " 76\n",
      " 54\n",
      " 39\n",
      " 67\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 62\n",
      " 13\n",
      " 73\n",
      " 58\n",
      " 67\n",
      " 72\n",
      "  4\n",
      " 74\n",
      " 74\n",
      " 57\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 54\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 62\n",
      " 71\n",
      " 59\n",
      " 57\n",
      " 67\n",
      " 66\n",
      "  2\n",
      "  2\n",
      " 74\n",
      " 62\n",
      " 73\n",
      "  2\n",
      "  5\n",
      " 65\n",
      " 58\n",
      " 68\n",
      " 71\n",
      " 72\n",
      " 56\n",
      " 68\n",
      "  2\n",
      " 68\n",
      " 60\n",
      " 73\n",
      " 62\n",
      "  1\n",
      " 67\n",
      " 68\n",
      " 58\n",
      " 62\n",
      " 54\n",
      " 58\n",
      " 68\n",
      " 77\n",
      " 75\n",
      "  2\n",
      " 58\n",
      " 61\n",
      " 59\n",
      " 73\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 62\n",
      " 58\n",
      " 62\n",
      " 61\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 62\n",
      "  2\n",
      " 71\n",
      " 73\n",
      " 68\n",
      " 73\n",
      " 59\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 73\n",
      "  2\n",
      "  8\n",
      " 71\n",
      "  2\n",
      " 61\n",
      " 56\n",
      " 65\n",
      " 67\n",
      " 72\n",
      "  1\n",
      "  2\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 72\n",
      " 56\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 67\n",
      " 73\n",
      " 10\n",
      " 56\n",
      " 14\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 29\n",
      "  1\n",
      "  2\n",
      " 67\n",
      " 42\n",
      " 58\n",
      " 68\n",
      "  2\n",
      " 73\n",
      " 57\n",
      "  9\n",
      " 68\n",
      " 42\n",
      " 78\n",
      " 73\n",
      "  2\n",
      " 74\n",
      " 58\n",
      " 37\n",
      " 61\n",
      " 58\n",
      " 61\n",
      " 72\n",
      "  2\n",
      "  8\n",
      " 71\n",
      " 66\n",
      " 73\n",
      " 72\n",
      " 68\n",
      " 75\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 61\n",
      " 64\n",
      " 60\n",
      " 54\n",
      " 59\n",
      " 72\n",
      " 68\n",
      " 74\n",
      " 62\n",
      " 68\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 65\n",
      " 58\n",
      " 65\n",
      " 58\n",
      " 58\n",
      " 74\n",
      " 57\n",
      "  9\n",
      " 68\n",
      " 57\n",
      " 73\n",
      " 68\n",
      " 73\n",
      " 73\n",
      " 62\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 75\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 30\n",
      " 61\n",
      "  2\n",
      " 75\n",
      "  2\n",
      " 68\n",
      " 71\n",
      "  2\n",
      " 66\n",
      " 72\n",
      " 74\n",
      "  1\n",
      " 76\n",
      " 61\n",
      "  8\n",
      " 60\n",
      " 72\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 73\n",
      " 72\n",
      " 73\n",
      " 44\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 73\n",
      " 60\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 58\n",
      " 54\n",
      " 71\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 61\n",
      " 60\n",
      "  1\n",
      "  2\n",
      " 66\n",
      " 61\n",
      " 68\n",
      " 69\n",
      " 68\n",
      " 71\n",
      " 54\n",
      " 72\n",
      " 57\n",
      " 76\n",
      " 58\n",
      " 56\n",
      " 54\n",
      "  2\n",
      " 74\n",
      " 54\n",
      " 58\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 60\n",
      " 71\n",
      " 65\n",
      " 60\n",
      " 65\n",
      " 68\n",
      " 78\n",
      " 37\n",
      "  2\n",
      " 76\n",
      "  2\n",
      " 73\n",
      " 59\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 10\n",
      " 72\n",
      " 73\n",
      " 56\n",
      " 69\n",
      " 59\n",
      " 58\n",
      " 58\n",
      " 75\n",
      "  2\n",
      " 65\n",
      " 78\n",
      " 72\n",
      " 61\n",
      "  2\n",
      " 67\n",
      "  2\n",
      "  1\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 68\n",
      "  1\n",
      "  1\n",
      " 68\n",
      "  2\n",
      " 67\n",
      " 60\n",
      " 58\n",
      "  2\n",
      " 56\n",
      " 59\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 73\n",
      " 73\n",
      " 68\n",
      "  8\n",
      " 67\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 74\n",
      "  2\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 61\n",
      " 69\n",
      " 73\n",
      " 58\n",
      " 69\n",
      " 60\n",
      " 65\n",
      " 57\n",
      " 72\n",
      " 55\n",
      " 73\n",
      " 69\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 54\n",
      " 69\n",
      "  2\n",
      " 72\n",
      " 61\n",
      " 73\n",
      "  2\n",
      "  2\n",
      "  1\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 71\n",
      " 62\n",
      " 56\n",
      " 67\n",
      " 69\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 66\n",
      " 65\n",
      " 62\n",
      " 57\n",
      " 72\n",
      " 62\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 65\n",
      " 62\n",
      " 58\n",
      " 67\n",
      " 72\n",
      " 65\n",
      " 68\n",
      " 62\n",
      " 56\n",
      " 56\n",
      " 65\n",
      " 58\n",
      " 62\n",
      " 60\n",
      " 66\n",
      " 58\n",
      " 73\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 65\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 65\n",
      "  2\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 68\n",
      "  2\n",
      " 74\n",
      "  1\n",
      " 65\n",
      " 74\n",
      " 62\n",
      " 68\n",
      " 61\n",
      " 54\n",
      " 76\n",
      " 67\n",
      " 58\n",
      " 75\n",
      " 58\n",
      " 33\n",
      " 65\n",
      " 56\n",
      " 78\n",
      " 73\n",
      " 54\n",
      " 72\n",
      " 58\n",
      " 67\n",
      " 69\n",
      " 76\n",
      " 69\n",
      " 68\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 29\n",
      "  2\n",
      " 68\n",
      " 44\n",
      " 25\n",
      " 62\n",
      "  2\n",
      " 61\n",
      " 72\n",
      " 54\n",
      " 58\n",
      " 54\n",
      " 62\n",
      "  2\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 59\n",
      "  2\n",
      " 64\n",
      " 71\n",
      "  8\n",
      " 67\n",
      " 73\n",
      " 73\n",
      " 71\n",
      " 78\n",
      " 74\n",
      " 72\n",
      " 62\n",
      " 58\n",
      " 67\n",
      " 54\n",
      " 58\n",
      " 67\n",
      " 67\n",
      " 66\n",
      " 54\n",
      " 73\n",
      " 71\n",
      "  8\n",
      "  1\n",
      " 73\n",
      " 73\n",
      " 56\n",
      " 68\n",
      " 73\n",
      " 58\n",
      " 69\n",
      " 54\n",
      " 61\n",
      "  2\n",
      " 56\n",
      " 68\n",
      " 65\n",
      " 54\n",
      " 59\n",
      " 54\n",
      "  2\n",
      " 58\n",
      " 65\n",
      " 72\n",
      "  2\n",
      " 69\n",
      " 71\n",
      " 65\n",
      "  2\n",
      " 54\n",
      " 56\n",
      "  2\n",
      "  2\n",
      "  4\n",
      " 73\n",
      " 71\n",
      "  2\n",
      " 58\n",
      " 78\n",
      "  2\n",
      " 73\n",
      " 67\n",
      " 56\n",
      " 61\n",
      " 65\n",
      " 39\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 62\n",
      " 67\n",
      " 13\n",
      " 61\n",
      " 67\n",
      " 56\n",
      " 61\n",
      "  2\n",
      " 65\n",
      " 67\n",
      "  4\n",
      "  2\n",
      " 62\n",
      " 75\n",
      " 73\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      "  2\n",
      " 57\n",
      " 72\n",
      " 67\n",
      " 68\n",
      "  2\n",
      "  2\n",
      " 56\n",
      " 54\n",
      " 73\n",
      " 66\n",
      " 72\n",
      " 73\n",
      "  2\n",
      " 74\n",
      " 24\n",
      "  2\n",
      " 67\n",
      " 71\n",
      " 58\n",
      "  2\n",
      " 58\n",
      " 59\n",
      " 62\n",
      " 74\n",
      " 65\n",
      " 71\n",
      " 67\n",
      "  1\n",
      " 57\n",
      " 72\n",
      "  2\n",
      " 67\n",
      " 75\n",
      "  2\n",
      " 67\n",
      " 70\n",
      " 58\n",
      " 66\n",
      " 74\n",
      " 58\n",
      "  1\n",
      " 62\n",
      " 58\n",
      " 61\n",
      " 57\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 54\n",
      "  2\n",
      " 72\n",
      " 22\n",
      " 69\n",
      " 67\n",
      " 62\n",
      "  8\n",
      " 68\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 66\n",
      " 54\n",
      " 66\n",
      " 73\n",
      " 54\n",
      " 62\n",
      " 57\n",
      " 61\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 72\n",
      " 63\n",
      " 54\n",
      "  8\n",
      " 71\n",
      " 72\n",
      "  2\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 66\n",
      " 62\n",
      "  2\n",
      " 62\n",
      "  2\n",
      " 57\n",
      " 73\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 68\n",
      " 52\n",
      "  2\n",
      " 58\n",
      " 54\n",
      " 38\n",
      "  1\n",
      " 62\n",
      "  2\n",
      " 37\n",
      "  2\n",
      " 66\n",
      " 54\n",
      "  2\n",
      " 72\n",
      "  9\n",
      " 66\n",
      " 33\n",
      "  1\n",
      " 58\n",
      " 61\n",
      " 71\n",
      " 65\n",
      " 25\n",
      " 58\n",
      " 67\n",
      " 58\n",
      " 58\n",
      " 61\n",
      "  2\n",
      "  1\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 60\n",
      " 63\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 68\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 75\n",
      " 73\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 58\n",
      " 73\n",
      " 62\n",
      " 67\n",
      " 68\n",
      "  8\n",
      " 65\n",
      " 73\n",
      " 72\n",
      "  9\n",
      " 71\n",
      " 62\n",
      " 78\n",
      " 66\n",
      "  2\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 54\n",
      " 68\n",
      " 78\n",
      " 72\n",
      " 58\n",
      " 61\n",
      " 67\n",
      " 67\n",
      " 58\n",
      " 66\n",
      " 54\n",
      " 67\n",
      " 65\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 62\n",
      " 72\n",
      " 61\n",
      " 54\n",
      " 68\n",
      "  2\n",
      " 60\n",
      " 60\n",
      " 61\n",
      " 54\n",
      "  2\n",
      " 72\n",
      " 68\n",
      " 33\n",
      " 62\n",
      " 61\n",
      "  2\n",
      " 69\n",
      " 62\n",
      " 33\n",
      "  8\n",
      " 66\n",
      " 73\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 69\n",
      "  2\n",
      " 72\n",
      " 65\n",
      " 72\n",
      " 54\n",
      " 68\n",
      " 76\n",
      " 58\n",
      " 54\n",
      " 62\n",
      " 71\n",
      " 76\n",
      " 10\n",
      " 58\n",
      " 71\n",
      " 68\n",
      " 66\n",
      "  2\n",
      " 73\n",
      " 58\n",
      "  2\n",
      " 61\n",
      " 71\n",
      " 56\n",
      " 56\n",
      " 73\n",
      " 67\n",
      " 72\n",
      "  2\n",
      " 72\n",
      " 57\n",
      " 54\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 72\n",
      " 76\n",
      "  1\n",
      "  2\n",
      " 62\n",
      " 68\n",
      " 54\n",
      " 61\n",
      "  2\n",
      "  2\n",
      " 55\n",
      " 56\n",
      "  2\n",
      "  8\n",
      " 68\n",
      " 64\n",
      " 54\n",
      " 58\n",
      " 75\n",
      " 74\n",
      " 68\n",
      " 36\n",
      " 68\n",
      "  2\n",
      " 68\n",
      " 58\n",
      " 73\n",
      "  2\n",
      " 75\n",
      " 73\n",
      " 55\n",
      " 59\n",
      " 29\n",
      " 71\n",
      " 55\n",
      " 60\n",
      " 66\n",
      " 73\n",
      " 57\n",
      " 74\n",
      " 67\n",
      " 62\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 61\n",
      " 61\n",
      " 61\n",
      " 62\n",
      " 74\n",
      "  2\n",
      " 57\n",
      " 56\n",
      "  4\n",
      " 70\n",
      " 58\n",
      " 54\n",
      " 71\n",
      " 68\n",
      " 71\n",
      " 71\n",
      " 66\n",
      " 59\n",
      "  2\n",
      " 66\n",
      " 58\n",
      " 68\n",
      " 71\n",
      " 65\n",
      " 61\n",
      " 58\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 74\n",
      " 72\n",
      " 68\n",
      " 58\n",
      " 73\n",
      " 78\n",
      " 72\n",
      " 69\n",
      " 72\n",
      "  1\n",
      "  8\n",
      " 61\n",
      " 54\n",
      " 67\n",
      " 69\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 62\n",
      " 58\n",
      " 68\n",
      " 54\n",
      " 61\n",
      " 39\n",
      " 67\n",
      " 73\n",
      " 58\n",
      " 62\n",
      " 65\n",
      "  2\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 66\n",
      " 54\n",
      " 62\n",
      " 56\n",
      " 72\n",
      "  2\n",
      " 78\n",
      " 62\n",
      " 59\n",
      " 72\n",
      " 68\n",
      " 56\n",
      " 78\n",
      "  2\n",
      " 66\n",
      " 74\n",
      "  9\n",
      "  2\n",
      " 62\n",
      " 60\n",
      " 62\n",
      " 58\n",
      " 58\n",
      " 67\n",
      " 56\n",
      " 72\n",
      " 75\n",
      " 66\n",
      " 71\n",
      " 67\n",
      "  2\n",
      " 64\n",
      " 56\n",
      "  2\n",
      " 69\n",
      " 62\n",
      " 62\n",
      " 73\n",
      " 71\n",
      " 56\n",
      " 69\n",
      " 58\n",
      " 60\n",
      " 61\n",
      " 54\n",
      " 72\n",
      " 68\n",
      " 62\n",
      " 38\n",
      " 62\n",
      " 54\n",
      " 21\n",
      " 58\n",
      " 71\n",
      "  2\n",
      " 54\n",
      "  2\n",
      " 73\n",
      " 58\n",
      " 65\n",
      " 68\n",
      " 54\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 56\n",
      " 67\n",
      " 61\n",
      " 67\n",
      " 71\n",
      " 58\n",
      " 62\n",
      " 58\n",
      " 65\n",
      " 67\n",
      " 78\n",
      " 67\n",
      " 73\n",
      "  2\n",
      " 67\n",
      " 65\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 61\n",
      "  2\n",
      " 68\n",
      "  2\n",
      " 72\n",
      "  2\n",
      " 67\n",
      "  2\n",
      " 57\n",
      " 56\n",
      "  2\n",
      " 60\n",
      "  2\n",
      " 54\n",
      " 66\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 59\n",
      " 71\n",
      " 68\n",
      " 68\n",
      " 59\n",
      " 61\n",
      "  2\n",
      " 78\n",
      " 65\n",
      " 58\n",
      " 54\n",
      " 61\n",
      " 71\n",
      " 58\n",
      " 60\n",
      " 68\n",
      " 73\n",
      " 72\n",
      " 66\n",
      " 62\n",
      " 56\n",
      " 69\n",
      " 74\n",
      " 58\n",
      " 62\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 54\n",
      " 25\n",
      "  2\n",
      " 61\n",
      " 62\n",
      " 65\n",
      "  1\n",
      "  8\n",
      " 61\n",
      " 62\n",
      " 60\n",
      " 58\n",
      " 54\n",
      " 74\n",
      " 44\n",
      " 62\n",
      "  4\n",
      " 73\n",
      " 56\n",
      " 54\n",
      " 20\n",
      " 74\n",
      " 73\n",
      " 58\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 73\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 58\n",
      "  2\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n",
      "\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 42])\n",
      "Variable containing:\n",
      " 68\n",
      " 54\n",
      " 74\n",
      " 57\n",
      " 72\n",
      " 73\n",
      " 69\n",
      " 58\n",
      " 67\n",
      " 61\n",
      " 54\n",
      "  2\n",
      " 78\n",
      " 61\n",
      " 69\n",
      "  1\n",
      " 42\n",
      " 73\n",
      " 78\n",
      " 58\n",
      " 76\n",
      " 72\n",
      "  2\n",
      " 72\n",
      " 72\n",
      " 54\n",
      " 54\n",
      " 73\n",
      " 23\n",
      "  2\n",
      " 62\n",
      " 69\n",
      "  2\n",
      " 58\n",
      " 76\n",
      "  1\n",
      " 74\n",
      "  2\n",
      " 68\n",
      " 66\n",
      "  1\n",
      " 45\n",
      " 67\n",
      "  2\n",
      " 58\n",
      " 74\n",
      " 60\n",
      " 73\n",
      "  2\n",
      " 73\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 69\n",
      "  2\n",
      " 72\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 58\n",
      " 58\n",
      "  2\n",
      " 72\n",
      " 54\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 68\n",
      " 58\n",
      " 69\n",
      " 61\n",
      " 73\n",
      "  8\n",
      " 74\n",
      " 67\n",
      "  2\n",
      " 78\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 61\n",
      " 72\n",
      " 54\n",
      " 67\n",
      " 72\n",
      " 54\n",
      " 59\n",
      " 58\n",
      " 78\n",
      " 76\n",
      " 58\n",
      " 35\n",
      " 67\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 71\n",
      " 44\n",
      " 38\n",
      " 67\n",
      " 73\n",
      " 26\n",
      " 69\n",
      " 58\n",
      " 67\n",
      " 55\n",
      "  8\n",
      " 27\n",
      " 66\n",
      " 29\n",
      " 72\n",
      " 67\n",
      " 58\n",
      " 58\n",
      " 59\n",
      " 38\n",
      "  2\n",
      "  8\n",
      "  2\n",
      " 67\n",
      " 54\n",
      " 62\n",
      " 76\n",
      " 67\n",
      " 58\n",
      " 65\n",
      " 73\n",
      " 71\n",
      " 74\n",
      " 68\n",
      " 68\n",
      " 58\n",
      " 72\n",
      " 57\n",
      " 72\n",
      " 72\n",
      " 68\n",
      " 58\n",
      " 55\n",
      " 62\n",
      " 62\n",
      " 69\n",
      " 66\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 75\n",
      "  2\n",
      " 78\n",
      " 61\n",
      "  2\n",
      " 54\n",
      " 54\n",
      " 73\n",
      "  2\n",
      " 54\n",
      " 68\n",
      " 58\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 74\n",
      "  2\n",
      " 78\n",
      "  2\n",
      " 54\n",
      " 73\n",
      " 57\n",
      "  2\n",
      " 54\n",
      " 71\n",
      " 58\n",
      " 54\n",
      "  1\n",
      " 74\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 54\n",
      "  2\n",
      " 67\n",
      " 55\n",
      " 61\n",
      " 68\n",
      " 58\n",
      " 75\n",
      " 68\n",
      "  2\n",
      " 69\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 62\n",
      " 62\n",
      " 68\n",
      " 38\n",
      "  1\n",
      " 54\n",
      " 61\n",
      "  2\n",
      " 61\n",
      " 73\n",
      " 58\n",
      " 68\n",
      " 58\n",
      " 65\n",
      "  2\n",
      " 67\n",
      " 69\n",
      " 61\n",
      "  2\n",
      " 73\n",
      " 56\n",
      " 58\n",
      " 62\n",
      "  1\n",
      "  2\n",
      "  2\n",
      " 67\n",
      " 58\n",
      " 69\n",
      " 62\n",
      " 67\n",
      " 56\n",
      " 62\n",
      " 58\n",
      " 74\n",
      " 58\n",
      " 61\n",
      " 56\n",
      "  2\n",
      " 72\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 70\n",
      "  3\n",
      " 73\n",
      " 71\n",
      " 68\n",
      " 67\n",
      " 76\n",
      " 29\n",
      " 67\n",
      " 71\n",
      " 65\n",
      " 54\n",
      " 73\n",
      " 73\n",
      " 68\n",
      " 68\n",
      " 47\n",
      "  2\n",
      "  2\n",
      " 62\n",
      " 72\n",
      " 72\n",
      " 58\n",
      " 71\n",
      " 71\n",
      " 62\n",
      " 60\n",
      " 59\n",
      "  2\n",
      " 67\n",
      " 61\n",
      " 68\n",
      " 62\n",
      " 62\n",
      " 63\n",
      " 54\n",
      " 75\n",
      " 73\n",
      " 68\n",
      " 65\n",
      " 58\n",
      " 61\n",
      "  2\n",
      " 62\n",
      " 73\n",
      " 67\n",
      " 57\n",
      " 54\n",
      " 61\n",
      " 58\n",
      " 71\n",
      " 62\n",
      " 75\n",
      " 73\n",
      " 76\n",
      "  2\n",
      " 68\n",
      "  3\n",
      " 74\n",
      "  5\n",
      "  2\n",
      " 72\n",
      " 59\n",
      "  2\n",
      " 73\n",
      " 69\n",
      "  2\n",
      "  4\n",
      " 68\n",
      "  2\n",
      " 72\n",
      " 54\n",
      " 58\n",
      " 62\n",
      " 66\n",
      "  8\n",
      " 67\n",
      " 73\n",
      " 73\n",
      " 58\n",
      " 67\n",
      "  2\n",
      " 61\n",
      " 72\n",
      " 72\n",
      " 71\n",
      " 73\n",
      " 76\n",
      "  2\n",
      " 58\n",
      " 67\n",
      " 68\n",
      " 71\n",
      "  2\n",
      " 73\n",
      " 56\n",
      " 72\n",
      " 67\n",
      " 67\n",
      " 73\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 68\n",
      " 72\n",
      " 73\n",
      " 62\n",
      " 56\n",
      " 56\n",
      " 74\n",
      " 68\n",
      " 68\n",
      " 72\n",
      " 73\n",
      " 61\n",
      "  4\n",
      " 72\n",
      " 66\n",
      " 60\n",
      "  2\n",
      "  2\n",
      " 66\n",
      " 74\n",
      "  8\n",
      " 55\n",
      " 58\n",
      " 62\n",
      "  9\n",
      " 62\n",
      " 67\n",
      " 68\n",
      " 72\n",
      " 72\n",
      "  2\n",
      " 57\n",
      " 54\n",
      " 68\n",
      " 62\n",
      " 58\n",
      " 78\n",
      " 73\n",
      " 76\n",
      " 58\n",
      "  9\n",
      " 58\n",
      " 71\n",
      " 71\n",
      " 67\n",
      " 62\n",
      " 69\n",
      " 54\n",
      " 68\n",
      " 71\n",
      " 58\n",
      " 68\n",
      " 73\n",
      "  2\n",
      " 65\n",
      " 71\n",
      " 27\n",
      " 54\n",
      " 65\n",
      "  2\n",
      " 71\n",
      " 78\n",
      " 68\n",
      " 71\n",
      " 55\n",
      " 62\n",
      "  1\n",
      " 58\n",
      " 57\n",
      "  2\n",
      "  2\n",
      " 76\n",
      " 73\n",
      " 61\n",
      "  2\n",
      " 58\n",
      " 57\n",
      " 71\n",
      " 75\n",
      " 67\n",
      "  2\n",
      " 65\n",
      " 58\n",
      "  2\n",
      " 57\n",
      " 61\n",
      " 62\n",
      " 73\n",
      " 62\n",
      " 68\n",
      " 58\n",
      " 68\n",
      " 73\n",
      " 61\n",
      " 76\n",
      " 58\n",
      " 58\n",
      " 66\n",
      " 73\n",
      "  2\n",
      " 71\n",
      " 60\n",
      " 56\n",
      "  2\n",
      " 73\n",
      " 72\n",
      "  2\n",
      " 54\n",
      " 78\n",
      " 62\n",
      " 76\n",
      " 62\n",
      " 61\n",
      " 54\n",
      " 74\n",
      " 60\n",
      " 74\n",
      "  2\n",
      "  2\n",
      " 54\n",
      "  2\n",
      "  2\n",
      "  2\n",
      " 71\n",
      "  2\n",
      " 73\n",
      " 54\n",
      " 71\n",
      " 71\n",
      "  2\n",
      " 58\n",
      "  2\n",
      " 73\n",
      " 62\n",
      " 65\n",
      " 65\n",
      " 67\n",
      " 58\n",
      " 72\n",
      " 58\n",
      " 71\n",
      "  2\n",
      " 36\n",
      " 30\n",
      " 58\n",
      " 68\n",
      " 68\n",
      " 62\n",
      "  2\n",
      " 58\n",
      " 74\n",
      "  2\n",
      " 71\n",
      " 73\n",
      " 58\n",
      " 38\n",
      " 73\n",
      "  1\n",
      "  2\n",
      " 64\n",
      " 71\n",
      " 10\n",
      " 72\n",
      " 10\n",
      "  9\n",
      " 57\n",
      " 67\n",
      "  2\n",
      "  2\n",
      " 68\n",
      " 67\n",
      " 72\n",
      "  2\n",
      " 59\n",
      "[torch.cuda.LongTensor of size 512 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b3572e787441d8b2e5d80317245596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81654  1.78501]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa67fbb4a2f42509dbe7753bc86d9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.69008  1.69936]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RNN with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497078d15ec348149442681039df2e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.86065  1.84255]                                 \n",
      "[ 1.       1.68014  1.67387]                                 \n",
      "[ 2.       1.58828  1.59169]                                 \n",
      "[ 3.       1.52989  1.54942]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2f7bedaa34de2a40296a07387c1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46841  1.50966]                                 \n",
      "[ 1.       1.46482  1.5039 ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those the same the same the same the same th'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take non-overlapping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then create the exact same thing, offset by 1, as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
       "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
       "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
       "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
       "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
       "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
       "       [ 2, 73, 61, 58, 71, 58,  2, 67]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
       "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
       "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
       "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
       "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
       "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
       "       [73, 61, 58, 71, 58,  2, 67, 68]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725ca331d28b482e9c7a4f83f741498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.59241  2.40251]                                \n",
      "[ 1.       2.28474  2.19859]                                \n",
      "[ 2.       2.13883  2.08836]                                \n",
      "[ 3.       2.04892  2.01564]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb9aa22524d4bfd8b001d2efd10dbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.99819  2.00106]                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ‚ã±          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e141251f24d4083a6e8b2fa15dea724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.39428  2.21111]                                \n",
      "[ 1.       2.10381  2.03275]                                \n",
      "[ 2.       1.99451  1.96393]                               \n",
      "[ 3.       1.93492  1.91763]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf833e8b7ec4a3aa29dd271911f76ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.84035  1.85742]                                \n",
      "[ 1.       1.82896  1.84887]                                \n",
      "[ 2.       1.81879  1.84281]                               \n",
      "[ 3.       1.81337  1.83801]                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  nietzsche.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH='data/nietzsche/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 56, 1, 493747)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e0a39ef174c72bac575be7e20579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81983  1.81247]                                 \n",
      "[ 1.       1.63097  1.66228]                                 \n",
      "[ 2.       1.54433  1.57824]                                 \n",
      "[ 3.       1.48563  1.54505]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b15bf8bcc7445e694dbcb3beb658b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.4187   1.50374]                                 \n",
      "[ 1.       1.41492  1.49391]                                 \n",
      "[ 2.       1.41001  1.49339]                                 \n",
      "[ 3.       1.40756  1.486  ]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46f24bfa194e1ba9d73e22283ca6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.81013  1.7969 ]                                 \n",
      "[ 1.       1.62515  1.65346]                                 \n",
      "[ 2.       1.53913  1.58065]                                 \n",
      "[ 3.       1.48698  1.54217]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    gi = F.linear(input, w_ih, b_ih)\n",
    "    gh = F.linear(hidden, w_hh, b_hh)\n",
    "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "    resetgate = F.sigmoid(i_r + h_r)\n",
    "    inputgate = F.sigmoid(i_i + h_i)\n",
    "    newgate = F.tanh(i_n + resetgate * h_n)\n",
    "    return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518384d71c345a8b145b35d4ee894fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.68409  1.67784]                                 \n",
      "[ 1.       1.49813  1.52661]                                 \n",
      "[ 2.       1.41674  1.46769]                                 \n",
      "[ 3.       1.36359  1.43818]                                 \n",
      "[ 4.       1.33223  1.41777]                                 \n",
      "[ 5.       1.30217  1.40511]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be385370c27f4b788920caf48f90aeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.22708  1.36926]                                 \n",
      "[ 1.       1.21948  1.3696 ]                                 \n",
      "[ 2.       1.22541  1.36969]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6943ca600bbf4a49a0020b2467c2ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.72032  1.64016]                                 \n",
      "[ 1.       1.62891  1.58176]                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765d0d78da6647d48276a638f70aeec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.47969  1.4472 ]                                 \n",
      "[ 1.       1.51411  1.46612]                                 \n",
      "[ 2.       1.412    1.39909]                                 \n",
      "[ 3.       1.53689  1.48337]                                 \n",
      "[ 4.       1.47375  1.43169]                                 \n",
      "[ 5.       1.39828  1.37963]                                 \n",
      "[ 6.       1.34546  1.35795]                                 \n",
      "[ 7.       1.51999  1.47165]                                 \n",
      "[ 8.       1.48992  1.46146]                                 \n",
      "[ 9.       1.45492  1.42829]                                 \n",
      "[ 10.        1.42027   1.39028]                              \n",
      "[ 11.        1.3814    1.36539]                              \n",
      "[ 12.        1.33895   1.34178]                              \n",
      "[ 13.        1.30737   1.32871]                              \n",
      "[ 14.        1.28244   1.31518]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4394818ec37f4b419397628b7cc8b815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.46053  1.43462]                                 \n",
      "[ 1.       1.51537  1.47747]                                 \n",
      "[ 2.       1.39208  1.38293]                                 \n",
      "[ 3.       1.53056  1.49371]                                 \n",
      "[ 4.       1.46812  1.43389]                                 \n",
      "[ 5.       1.37624  1.37523]                                 \n",
      "[ 6.       1.3173   1.34022]                                 \n",
      "[ 7.       1.51783  1.47554]                                 \n",
      "[ 8.       1.4921   1.45785]                                 \n",
      "[ 9.       1.44843  1.42215]                                 \n",
      "[ 10.        1.40948   1.40858]                              \n",
      "[ 11.        1.37098   1.36648]                              \n",
      "[ 12.        1.32255   1.33842]                              \n",
      "[ 13.        1.28243   1.31106]                              \n",
      "[ 14.        1.25031   1.2918 ]                              \n",
      "[ 15.        1.49236   1.45316]                              \n",
      "[ 16.        1.46041   1.43622]                              \n",
      "[ 17.        1.45043   1.4498 ]                              \n",
      "[ 18.        1.43331   1.41297]                              \n",
      "[ 19.        1.43841   1.41704]                              \n",
      "[ 20.        1.41536   1.40521]                              \n",
      "[ 21.        1.39829   1.37656]                              \n",
      "[ 22.        1.37001   1.36891]                              \n",
      "[ 23.        1.35469   1.35909]                              \n",
      "[ 24.        1.32202   1.34228]                              \n",
      "[ 25.        1.29972   1.32256]                              \n",
      "[ 26.        1.28007   1.30903]                              \n",
      "[ 27.        1.24503   1.29125]                              \n",
      "[ 28.        1.22261   1.28316]                              \n",
      "[ 29.        1.20563   1.27397]                              \n",
      "[ 30.        1.18764   1.27178]                              \n",
      "[ 31.        1.18114   1.26694]                              \n",
      "[ 32.        1.44344   1.42405]                              \n",
      "[ 33.        1.43344   1.41616]                              \n",
      "[ 34.        1.4346    1.40442]                              \n",
      "[ 35.        1.42152   1.41359]                              \n",
      "[ 36.        1.42072   1.40835]                              \n",
      "[ 37.        1.41732   1.40498]                              \n",
      "[ 38.        1.41268   1.395  ]                              \n",
      "[ 39.        1.40725   1.39433]                              \n",
      "[ 40.        1.40181   1.39864]                              \n",
      "[ 41.        1.38621   1.37549]                              \n",
      "[ 42.        1.3838    1.38587]                              \n",
      "[ 43.        1.37644   1.37118]                              \n",
      "[ 44.        1.36287   1.36211]                              \n",
      "[ 45.        1.35942   1.36145]                              \n",
      "[ 46.        1.34712   1.34924]                              \n",
      "[ 47.        1.32994   1.34884]                              \n",
      "[ 48.        1.32788   1.33387]                              \n",
      "[ 49.        1.31553   1.342  ]                              \n",
      "[ 50.        1.30088   1.32435]                              \n",
      "[ 51.        1.28446   1.31166]                              \n",
      "[ 52.        1.27058   1.30807]                              \n",
      "[ 53.        1.26271   1.29935]                              \n",
      "[ 54.        1.24351   1.28942]                              \n",
      "[ 55.        1.23119   1.2838 ]                              \n",
      "[ 56.        1.2086    1.28364]                              \n",
      "[ 57.        1.19742   1.27375]                              \n",
      "[ 58.        1.18127   1.26758]                              \n",
      "[ 59.        1.17475   1.26858]                              \n",
      "[ 60.        1.15349   1.25999]                              \n",
      "[ 61.        1.14718   1.25779]                              \n",
      "[ 62.        1.13174   1.2524 ]                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those the skemps), or\n",
      "imaginates, though they deceives. it should so each ourselvess and new\n",
      "present, step absolutely for the\n",
      "science.\" the contradity and\n",
      "measuring, \n",
      "the whole!\n",
      "\n",
      "293. perhaps, that every life a values of blood\n",
      "of\n",
      "intercourse when it senses there is unscrupulus, his very rights, and still impulse, love?\n",
      "just after that thereby how made with the way anything, and set for harmless philos\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
